diff -Naur ./old//arch/arm/boot/compressed/misc.c ./kern//arch/arm/boot/compressed/misc.c
--- ./old//arch/arm/boot/compressed/misc.c  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//arch/arm/boot/compressed/misc.c 2012-04-18 13:37:43.000000000 -0400
@@ -200,9 +200,10 @@
  tmp = (unsigned char *) (((unsigned long)input_data_end) - 4);
  output_ptr = get_unaligned_le32(tmp);
 
- putstr("Uncompressing Linux...");
+ putstr("Decompressing kernel ...");
  do_decompress(input_data, input_data_end - input_data,
      output_data, error);
- putstr(" done, booting the kernel.\n");
+ putstr("\nDone, booting the kernel ...\n\n");
+ 
  return output_ptr;
 }
diff -Naur ./old//arch/arm/include/asm/signal.h ./kern//arch/arm/include/asm/signal.h
--- ./old//arch/arm/include/asm/signal.h  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//arch/arm/include/asm/signal.h 2012-06-13 16:30:48.000000000 -0400
@@ -14,7 +14,7 @@
 #define _NSIG_BPW  32
 #define _NSIG_WORDS  (_NSIG / _NSIG_BPW)
 
-typedef unsigned long old_sigset_t;    /* at least 32 bits */
+typedef uint32_t old_sigset_t;   /* at least 32 bits */
 
 typedef struct {
  unsigned long sig[_NSIG_WORDS];
@@ -28,43 +28,47 @@
 
 #endif /* __KERNEL__ */
 
-#define SIGHUP    1
-#define SIGINT    2
-#define SIGQUIT     3
-#define SIGILL    4
-#define SIGTRAP     5
-#define SIGABRT     6
-#define SIGIOT    6
-#define SIGBUS    7
-#define SIGFPE    8
-#define SIGKILL     9
-#define SIGUSR1    10
-#define SIGSEGV    11
-#define SIGUSR2    12
-#define SIGPIPE    13
-#define SIGALRM    14
-#define SIGTERM    15
-#define SIGSTKFLT  16
-#define SIGCHLD    17
-#define SIGCONT    18
-#define SIGSTOP    19
-#define SIGTSTP    20
-#define SIGTTIN    21
-#define SIGTTOU    22
-#define SIGURG   23
-#define SIGXCPU    24
-#define SIGXFSZ    25
-#define SIGVTALRM  26
-#define SIGPROF    27
-#define SIGWINCH 28
-#define SIGIO    29
-#define SIGPOLL    SIGIO
+
+#define  SIGHUP  1 /* hangup */
+#define  SIGINT  2 /* interrupt */
+#define  SIGQUIT 3 /* quit */
+#define  SIGILL  4 /* illegal instruction (not reset when caught) */
+#define  SIGTRAP 5 /* trace trap (not reset when caught) */
+#define  SIGABRT 6 /* abort() */
+#define  SIGPOLL 7 /* pollable event ([XSR] generated, not supported) */
+#define  SIGIOT  SIGABRT /* compatibility */
+#define  SIGEMT  7 /* EMT instruction */
+#define  SIGFPE  8 /* floating point exception */
+#define  SIGKILL 9 /* kill (cannot be caught or ignored) */
+#define  SIGBUS  10  /* bus error */
+#define  SIGSEGV 11  /* segmentation violation */
+#define  SIGSYS  12  /* bad argument to system call */
+#define  SIGPIPE 13  /* write on a pipe with no one to read it */
+#define  SIGALRM 14  /* alarm clock */
+#define  SIGTERM 15  /* software termination signal from kill */
+#define  SIGURG  16  /* urgent condition on IO channel */
+#define  SIGSTOP 17  /* sendable stop signal not from tty */
+#define  SIGTSTP 18  /* stop signal from tty */
+#define  SIGCONT 19  /* continue a stopped process */
+#define  SIGCHLD 20  /* to parent on child stop or exit */
+#define  SIGTTIN 21  /* to readers pgrp upon background tty read */
+#define  SIGTTOU 22  /* like TTIN for output if (tp->t_local&LTOSTOP) */
+#define  SIGIO 23  /* input/output possible signal */
+#define  SIGXCPU 24  /* exceeded CPU time limit */
+#define  SIGXFSZ 25  /* exceeded file size limit */
+#define  SIGVTALRM 26  /* virtual time alarm */
+#define  SIGPROF 27  /* profiling time alarm */
+#define SIGWINCH 28  /* window size changes */
+#define SIGINFO  29  /* information request */
+#define SIGUSR1 30 /* user defined signal 1 */
+#define SIGUSR2 31 /* user defined signal 2 */
+
 /*
 #define SIGLOST    29
 */
-#define SIGPWR   30
-#define SIGSYS   31
-#define  SIGUNUSED 31
+#define SIGPWR   32
+#define  SIGUNUSED 32
+#define SIGSTKFLT  32
 
 /* These should not be considered constants from userland.  */
 #define SIGRTMIN 32
@@ -114,11 +118,14 @@
 #include <asm-generic/signal-defs.h>
 
 #ifdef __KERNEL__
+
+#include <DarwinTypes.h>
+
 struct old_sigaction {
  __sighandler_t sa_handler;
  old_sigset_t sa_mask;
- unsigned long sa_flags;
- __sigrestore_t sa_restorer;
+ int sa_flags;
+ //__sigrestore_t sa_restorer;
 };
 
 struct sigaction {
@@ -141,8 +148,8 @@
    void (*_sa_sigaction)(int, struct siginfo *, void *);
  } _u;
  sigset_t sa_mask;
- unsigned long sa_flags;
- void (*sa_restorer)(void);
+ int sa_flags;
+ //void (*sa_restorer)(void);
 };
 
 #define sa_handler _u._sa_handler
diff -Naur ./old//arch/arm/include/asm/socket.h ./kern//arch/arm/include/asm/socket.h
--- ./old//arch/arm/include/asm/socket.h  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//arch/arm/include/asm/socket.h 2012-06-13 09:11:44.000000000 -0400
@@ -4,31 +4,50 @@
 #include <asm/sockios.h>
 
 /* For setsockopt(2) */
+
+#define  SO_DEBUG  0x0001    /* turn on debugging info recording */
+#define  SO_ACCEPTCONN 0x0002    /* socket has had listen() */
+#define  SO_REUSEADDR  0x0004    /* allow local address reuse */
+#define  SO_KEEPALIVE  0x0008    /* keep connections alive */
+#define  SO_DONTROUTE  0x0010    /* just use interface addresses */
+#define  SO_BROADCAST  0x0020    /* permit sending of broadcast msgs */
+#define SO_SNDBUF  0x1001    /* send buffer size */
+#define SO_RCVBUF  0x1002    /* receive buffer size */
+#define SO_SNDLOWAT  0x1003    /* send low-water mark */
+#define SO_RCVLOWAT  0x1004    /* receive low-water mark */
+#define SO_SNDTIMEO  0x1005    /* send timeout */
+#define SO_RCVTIMEO  0x1006    /* receive timeout */
+#define  SO_ERROR  0x1007    /* get error status and clear */
+#define  SO_TYPE   0x1008    /* get socket type */
+
+#define SO_LINGER  0x1080          /* linger on close if data present (in seconds) */
+#define  SO_OOBINLINE  0x0100  
+
 #define SOL_SOCKET 1
 
-#define SO_DEBUG 1
-#define SO_REUSEADDR 2
-#define SO_TYPE    3
-#define SO_ERROR 4
-#define SO_DONTROUTE 5
-#define SO_BROADCAST 6
-#define SO_SNDBUF  7
-#define SO_RCVBUF  8
-#define SO_SNDBUFFORCE 32
-#define SO_RCVBUFFORCE 33
-#define SO_KEEPALIVE 9
-#define SO_OOBINLINE 10
+//[bsd]//#define SO_DEBUG  1
+//[bsd]//#define SO_REUSEADDR  2
+//[bsd]//#define SO_TYPE   3
+//[bsd]//#define SO_ERROR  4
+//[bsd]//#define SO_DONTROUTE  5
+//[bsd]//#define SO_BROADCAST  6
+//[bsd]//#define SO_SNDBUF 7
+//[bsd]//#define SO_RCVBUF 8
+#define SO_SNDBUFFORCE 52 /* used to be 32 */
+#define SO_RCVBUFFORCE 53
+//[bsd]//#define SO_KEEPALIVE  9
+//[bsd]//#define SO_OOBINLINE  10
 #define SO_NO_CHECK  11
 #define SO_PRIORITY  12
-#define SO_LINGER  13
+//[bsd]//#define SO_LINGER 13
 #define SO_BSDCOMPAT 14
 /* To add :#define SO_REUSEPORT 15 */
-#define SO_PASSCRED  16
+#define SO_PASSCRED  56
 #define SO_PEERCRED  17
-#define SO_RCVLOWAT  18
-#define SO_SNDLOWAT  19
-#define SO_RCVTIMEO  20
-#define SO_SNDTIMEO  21
+//[bsd]//#define SO_RCVLOWAT 18
+//[bsd]//#define SO_SNDLOWAT 19
+//[bsd]//#define SO_RCVTIMEO 20
+//[bsd]//#define SO_SNDTIMEO 21
 
 /* Security levels - as per NRL IPv6 - don't actually do anything */
 #define SO_SECURITY_AUTHENTICATION   22
@@ -45,7 +64,7 @@
 #define SO_TIMESTAMP   29
 #define SCM_TIMESTAMP    SO_TIMESTAMP
 
-#define SO_ACCEPTCONN    30
+//[bsd]//#define SO_ACCEPTCONN   30
 
 #define SO_PEERSEC   31
 #define SO_PASSSEC   34
diff -Naur ./old//arch/arm/include/asm/termbits.h ./kern//arch/arm/include/asm/termbits.h
--- ./old//arch/arm/include/asm/termbits.h  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//arch/arm/include/asm/termbits.h 2012-05-14 16:38:39.000000000 -0400
@@ -2,9 +2,12 @@
 #define __ASM_ARM_TERMBITS_H
 
 typedef unsigned char  cc_t;
+
+/* int -> long */
 typedef unsigned int speed_t;
 typedef unsigned int tcflag_t;
 
+/* 19 -> 20 */
 #define NCCS 19
 struct termios {
  tcflag_t c_iflag;   /* input mode flags */
@@ -39,6 +42,7 @@
 
 
 /* c_cc characters */
+
 #define VINTR 0
 #define VQUIT 1
 #define VERASE 2
@@ -58,6 +62,7 @@
 #define VEOL2 16
 
 /* c_iflag bits */
+
 #define IGNBRK 0000001
 #define BRKINT 0000002
 #define IGNPAR 0000004
diff -Naur ./old//arch/arm/include/asm/unistd.h ./kern//arch/arm/include/asm/unistd.h
--- ./old//arch/arm/include/asm/unistd.h  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//arch/arm/include/asm/unistd.h 2012-04-21 12:52:10.000000000 -0400
@@ -397,6 +397,8 @@
 #define __NR_fanotify_mark   (__NR_SYSCALL_BASE+368)
 #define __NR_prlimit64     (__NR_SYSCALL_BASE+369)
 
+#define __NR_mach_msg_trap     (__NR_SYSCALL_BASE+370)
+
 /*
  * The following SWIs are ARM private.
  */
diff -Naur ./old//arch/arm/kernel/calls.S ./kern//arch/arm/kernel/calls.S
--- ./old//arch/arm/kernel/calls.S  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//arch/arm/kernel/calls.S 2012-04-21 13:12:11.000000000 -0400
@@ -379,6 +379,8 @@
    CALL(sys_fanotify_init)
    CALL(sys_fanotify_mark)
    CALL(sys_prlimit64)
+/* 370 */  CALL(sys_mach_msg_trap)
+   
 #ifndef syscalls_counted
 .equ syscalls_padding, ((NR_syscalls + 3) & ~3) - NR_syscalls
 #define syscalls_counted
diff -Naur ./old//arch/arm/kernel/entry-armv.S ./kern//arch/arm/kernel/entry-armv.S
--- ./old//arch/arm/kernel/entry-armv.S 2011-01-04 19:50:19.000000000 -0500
+++ ./kern//arch/arm/kernel/entry-armv.S  2012-08-03 20:49:56.000000000 -0400
@@ -230,6 +230,10 @@
 #endif
 
  irq_handler
+
+ /* irqs are lol */
+ get_thread_info tsk
+
 #ifdef CONFIG_PREEMPT
  str r8, [tsk, #TI_PREEMPT]    @ restore preempt count
  ldr r0, [tsk, #TI_FLAGS]    @ get flags
@@ -459,6 +463,10 @@
 #endif
 
  irq_handler
+
+ /* irqs are lol */
+ get_thread_info tsk
+
 #ifdef CONFIG_PREEMPT
  ldr r0, [tsk, #TI_PREEMPT]
  str r8, [tsk, #TI_PREEMPT]
diff -Naur ./old//arch/arm/kernel/entry-common.S ./kern//arch/arm/kernel/entry-common.S
--- ./old//arch/arm/kernel/entry-common.S 2011-01-04 19:50:19.000000000 -0500
+++ ./kern//arch/arm/kernel/entry-common.S  2012-08-06 11:12:29.000000000 -0400
@@ -8,6 +8,15 @@
  * published by the Free Software Foundation.
  */
 
+
+ /*
+  * Copyright (c) 2012 Christina Brooks
+  *
+  * Darwin ABI support and preservation of the r9 register in
+  * order to support running swi handlers that use this ABI
+  * as it can sometimes trash r9.
+  */
+
 #include <asm/unistd.h>
 #include <asm/ftrace.h>
 #include <mach/entry-macro.S>
@@ -15,30 +24,73 @@
 
 #include "entry-header.S"
 
+#define __apple_darwin_abi__
+
+#if defined(CONFIG_OABI_COMPAT)
+#error config_oabi_compat is not supported by this kernel
+#endif
 
  .align  5
+
+/*
+ * Common.
+ */
+Restore_user_high:
+ arch_ret_to_user r1, lr
+ restore_user_regs fast = 1, offset = S_OFF
+
+/*
+ * Return to the userspace from *any point* in the system call.
+ */
+.globl Return_to_user_from_swi
+Return_to_user_from_swi:
+ disable_irq /* disable irq */
+
+ /* restore r9 */
+   get_thread_info tsk
+
+   /*
+    * Recover the stack frame.
+    * (oh god wtf)
+    */
+   add sp, tsk, #8192
+   sub sp, #S_FRAME_SIZE+S_OFF+8
+
+ /* force work pending */
+ b fast_work_pending
+
+ /* switch back to userspace */
+ mov r1, #0
+ b Restore_user_high
+
+
 /*
  * This is the fast syscall return path.  We do as little as
  * possible here, and this includes saving r0 back into the SVC
  * stack.
  */
-ret_fast_syscall:
+.globl Return_to_user_from_swi_fast
+Return_to_user_from_swi_fast:
  UNWIND(.fnstart )
  UNWIND(.cantunwind  )
- disable_irq       @ disable interrupts
+
+   /* restore r9 */
+   get_thread_info tsk
+   
+ disable_irq /* disable irq */
  ldr r1, [tsk, #TI_FLAGS]
  tst r1, #_TIF_WORK_MASK
  bne fast_work_pending
+
 #if defined(CONFIG_IRQSOFF_TRACER)
  asm_trace_hardirqs_on
 #endif
 
  /* perform architecture specific actions before user return */
- arch_ret_to_user r1, lr
-
- restore_user_regs fast = 1, offset = S_OFF
+ b Restore_user_high
  UNWIND(.fnend   )
 
+
 /*
  * Ok, we need to do extra processing, enter the slow path.
  */
@@ -73,7 +125,6 @@
 #endif
  /* perform architecture specific actions before user return */
  arch_ret_to_user r1, lr
-
  restore_user_regs fast = 0, offset = 0
 ENDPROC(ret_to_user)
 
@@ -214,7 +265,7 @@
 #ifdef CONFIG_OLD_MCOUNT
 /*
  * This is under an ifdef in order to force link-time errors for people trying
- * to build with !FRAME_POINTER with a GCC which doesn't use the new-style
+ * to build with !FRAME_POINTER with a GCC which does not use the new-style
  * mcount.
  */
 ENTRY(mcount)
@@ -247,18 +298,17 @@
 
 #endif /* CONFIG_FUNCTION_TRACER */
 
-/*=============================================================================
- * SWI handler
- *-----------------------------------------------------------------------------
- */
+/* Handle a Darwin system call (0x80) */
+ENTRY(Fleh_swi_darwin)
+ adr lr, BSYM(Return_to_user_from_swi_fast)
+ b Sleh_swi_darwin
+ENDPROC(Fleh_swi_darwin)
+
 
- /* If we're optimising for StrongARM the resulting code won't 
-    run on an ARM7 and we can save a couple of instructions.  
-               --pb */
 #ifdef CONFIG_CPU_ARM710
 #define A710(code...) code
 .Larm710bug:
- ldmia sp, {r0 - lr}^      @ Get calling r0 - lr
+ ldmia sp, {r0 - lr}^      // Get calling r0 - lr
  mov r0, r0
  add sp, sp, #S_FRAME_SIZE
  subs  pc, lr, #4
@@ -267,121 +317,120 @@
 #endif
 
  .align  5
+
+/* Software interrupt vector */
 ENTRY(vector_swi)
  sub sp, sp, #S_FRAME_SIZE
- stmia sp, {r0 - r12}      @ Calling r0 - r12
- ARM(  add r8, sp, #S_PC   )
- ARM(  stmdb r8, {sp, lr}^   ) @ Calling sp, lr
- THUMB(  mov r8, sp      )
- THUMB(  store_user_sp_lr r8, r10, S_SP  ) @ calling sp, lr
- mrs r8, spsr      @ called from non-FIQ mode, so ok.
- str lr, [sp, #S_PC]     @ Save calling PC
- str r8, [sp, #S_PSR]    @ Save CPSR
- str r0, [sp, #S_OLD_R0]   @ Save OLD_R0
+ stmia sp, {r0 - r12}      // Calling r0 - r12
+
+ ARM(  add r11, sp, #S_PC    )
+ ARM(  stmdb r11, {sp, lr}^    ) // Calling sp, lr
+ THUMB(  mov r11, sp     )
+ THUMB(  store_user_sp_lr r11, r10, S_SP ) // calling sp, lr
+
+ mrs r11, spsr     // called from non-FIQ mode, so ok.
+ str lr, [sp, #S_PC]     // Save calling PC
+ str r11, [sp, #S_PSR]   // Save CPSR
+ str r0, [sp, #S_OLD_R0]   // Save OLD_R0
  zero_fp
 
- /*
-  * Get the system call number.
-  */
+ /* args to the syscall */
+ sub sp, #8
+ stmdb sp!, {r4, r5, r6, r8}
 
-#if defined(CONFIG_OABI_COMPAT)
+ /* ghey */
+ mov r8, r11
 
  /*
-  * If we have CONFIG_OABI_COMPAT then we need to look at the swi
-  * value to determine if it is an EABI or an old ABI call.
+  * If this is a darwin system call, move r12 to scno.
   */
-#ifdef CONFIG_ARM_THUMB
- tst r8, #PSR_T_BIT
- movne r10, #0       @ no thumb OABI emulation
- ldreq r10, [lr, #-4]      @ get SWI instruction
-#else
- ldr r10, [lr, #-4]      @ get SWI instruction
-  A710(  and ip, r10, #0x0f000000    @ check for SWI   )
-  A710(  teq ip, #0x0f000000           )
-  A710(  bne .Larm710bug           )
-#endif
-#ifdef CONFIG_CPU_ENDIAN_BE8
- rev r10, r10      @ little endian instruction
-#endif
+ ldr r11, [lr, #-4]  /* svc instr */
+ bics r11, r11, #0xff000000 /* strip the instr opcode */
+ cmp r11, #0x80 /* svc 0x80 means darwin */
+
+ /* move r12 to scno and skip all the linux crap */
+ moveq scno, r12
+ beq darwin_2
+
+ /* stripped oabi code */
 
-#elif defined(CONFIG_AEABI)
+#if defined(CONFIG_AEABI)
 
  /*
   * Pure EABI user space always put syscall number into scno (r7).
   */
-  A710(  ldr ip, [lr, #-4]     @ get SWI instruction )
-  A710(  and ip, ip, #0x0f000000   @ check for SWI   )
-  A710(  teq ip, #0x0f000000           )
-  A710(  bne .Larm710bug           )
+  A710(  ldr ip, [lr, #-4] ) // get SWI instruction  
+  A710(  and ip, ip, #0x0f000000 ) // check for SWI    
+  A710(  teq ip, #0x0f000000 )
+  A710(  bne .Larm710bug )
 
 #elif defined(CONFIG_ARM_THUMB)
 
  /* Legacy ABI only, possibly thumb mode. */
- tst r8, #PSR_T_BIT      @ this is SPSR from save_user_regs
- addne scno, r7, #__NR_SYSCALL_BASE  @ put OS number in
+ tst r8, #PSR_T_BIT //this is SPSR from save_user_regs
+ addne scno, r7, #__NR_SYSCALL_BASE // put OS number in
  ldreq scno, [lr, #-4]
 
 #else
 
  /* Legacy ABI only. */
- ldr scno, [lr, #-4]     @ get SWI instruction
-  A710(  and ip, scno, #0x0f000000   @ check for SWI   )
-  A710(  teq ip, #0x0f000000           )
-  A710(  bne .Larm710bug           )
+ ldr scno, [lr, #-4] // get SWI instruction
+  A710(  and ip, scno, #0x0f000000 )
+  A710(  teq ip, #0x0f000000 )
+  A710(  bne .Larm710bug ) // check for SWI  
 
 #endif
 
 #ifdef CONFIG_ALIGNMENT_TRAP
  ldr ip, __cr_alignment
  ldr ip, [ip]
- mcr p15, 0, ip, c1, c0    @ update control register
+ mcr p15, 0, ip, c1, c0  // update control register
 #endif
- enable_irq
 
- get_thread_info tsk
- adr tbl, sys_call_table   @ load syscall table pointer
+ adr tbl, sys_call_table // load syscall table pointer
 
-#if defined(CONFIG_OABI_COMPAT)
- /*
-  * If the swi argument is zero, this is an EABI call and we do nothing.
-  *
-  * If this is an old ABI call, get the syscall number into scno and
-  * get the old ABI syscall table address.
-  */
- bics  r10, r10, #0xff000000
- eorne scno, r10, #__NR_OABI_SYSCALL_BASE
- ldrne tbl, =sys_oabi_call_table
-#elif !defined(CONFIG_AEABI)
- bic scno, scno, #0xff000000   @ mask off SWI op-code
- eor scno, scno, #__NR_SYSCALL_BASE  @ check OS number
+#if !defined(CONFIG_AEABI)
+ bic scno, scno, #0xff000000 // mask off SWI op-code
+ eor scno, scno, #__NR_SYSCALL_BASE // check OS number
 #endif
 
- ldr r10, [tsk, #TI_FLAGS]   @ check for syscall tracing
- stmdb sp!, {r4, r5}     @ push fifth and sixth args
+ 
+darwin_2:
+ /***** darwin syscalls start here *****/
+ enable_irq
+
+ get_thread_info tsk
+ ldr r10, [tsk, #TI_FLAGS] // check for syscall tracing  
 
 #ifdef CONFIG_SECCOMP
  tst r10, #_TIF_SECCOMP
  beq 1f
  mov r0, scno
  bl  __secure_computing  
- add r0, sp, #S_R0 + S_OFF   @ pointer to regs
- ldmia r0, {r0 - r3}     @ have to reload r0 - r3
+ add r0, sp, #S_R0 + S_OFF // pointer to regs
+ ldmia r0, {r0 - r3} // have to reload r0 - r3
 1:
 #endif
 
- tst r10, #_TIF_SYSCALL_TRACE    @ are we tracing syscalls?
+ /* is this a darwin call? */
+ cmp r11, #0x80 
+ beq Fleh_swi_darwin 
+
+ tst r10, #_TIF_SYSCALL_TRACE // are we tracing syscalls?
  bne __sys_trace
 
- cmp scno, #NR_syscalls    @ check upper syscall limit
- adr lr, BSYM(ret_fast_syscall)  @ return address
- ldrcc pc, [tbl, scno, lsl #2]   @ call sys_* routine
+Llinux_syscall:
+ adr lr, BSYM(Return_to_user_from_swi_fast)  // return address
+ cmp scno, #NR_syscalls    // check upper syscall limit
+ 
+ ldrcc pc, [tbl, scno, lsl #2]   // call sys_* routine
 
  add r1, sp, #S_OFF
 2: mov why, #0       @ no longer a real syscall
  cmp scno, #(__ARM_NR_BASE - __NR_SYSCALL_BASE)
- eor r0, scno, #__NR_SYSCALL_BASE  @ put OS number back
+ eor r0, scno, #__NR_SYSCALL_BASE  // put OS number back
  bcs arm_syscall 
- b sys_ni_syscall      @ not private func
+ b sys_ni_syscall      // not private func
 ENDPROC(vector_swi)
 
  /*
@@ -438,13 +487,13 @@
 /*============================================================================
  * Special system call wrappers
  */
-@ r0 = syscall number
-@ r8 = syscall table
+// r0 = syscall number
+// r8 = syscall table
 sys_syscall:
    bic scno, r0, #__NR_OABI_SYSCALL_BASE
    cmp scno, #__NR_syscall - __NR_SYSCALL_BASE
-   cmpne scno, #NR_syscalls  @ check range
-   stmloia sp, {r5, r6}    @ shuffle args
+   cmpne scno, #NR_syscalls  // check range
+   stmloia sp, {r5, r6}    // shuffle args
    movlo r0, r1
    movlo r1, r2
    movlo r2, r3
@@ -476,13 +525,13 @@
 
 sys_sigreturn_wrapper:
    add r0, sp, #S_OFF
-   mov why, #0   @ prevent syscall restart handling
+   mov why, #0   // prevent syscall restart handling
    b sys_sigreturn
 ENDPROC(sys_sigreturn_wrapper)
 
 sys_rt_sigreturn_wrapper:
    add r0, sp, #S_OFF
-   mov why, #0   @ prevent syscall restart handling
+   mov why, #0   // prevent syscall restart handling
    b sys_rt_sigreturn
 ENDPROC(sys_rt_sigreturn_wrapper)
 
diff -Naur ./old//arch/arm/kernel/entry-header.S ./kern//arch/arm/kernel/entry-header.S
--- ./old//arch/arm/kernel/entry-header.S 2011-01-04 19:50:19.000000000 -0500
+++ ./kern//arch/arm/kernel/entry-header.S  2012-08-05 10:00:45.000000000 -0400
@@ -20,7 +20,7 @@
 @ the addition of 8 bytes for storing syscall args 5 and 6.
 @ This _must_ remain a multiple of 8 for EABI.
 @
-#define S_OFF    8
+#define S_OFF    24
 
 /* 
  * The SWI code relies on the fact that R0 is at the bottom of the stack
diff -Naur ./old//arch/arm/kernel/signal.c ./kern//arch/arm/kernel/signal.c
--- ./old//arch/arm/kernel/signal.c 2011-01-04 19:50:19.000000000 -0500
+++ ./kern//arch/arm/kernel/signal.c  2012-06-13 16:34:58.000000000 -0400
@@ -90,8 +90,7 @@
  if (act) {
    old_sigset_t mask;
    if (!access_ok(VERIFY_READ, act, sizeof(*act)) ||
-       __get_user(new_ka.sa.sa_handler, &act->sa_handler) ||
-       __get_user(new_ka.sa.sa_restorer, &act->sa_restorer))
+       __get_user(new_ka.sa.sa_handler, &act->sa_handler))
      return -EFAULT;
    __get_user(new_ka.sa.sa_flags, &act->sa_flags);
    __get_user(mask, &act->sa_mask);
@@ -102,8 +101,7 @@
 
  if (!ret && oact) {
    if (!access_ok(VERIFY_WRITE, oact, sizeof(*oact)) ||
-       __put_user(old_ka.sa.sa_handler, &oact->sa_handler) ||
-       __put_user(old_ka.sa.sa_restorer, &oact->sa_restorer))
+       __put_user(old_ka.sa.sa_handler, &oact->sa_handler))
      return -EFAULT;
    __put_user(old_ka.sa.sa_flags, &oact->sa_flags);
    __put_user(old_ka.sa.sa_mask.sig[0], &oact->sa_mask);
@@ -502,7 +500,8 @@
 #endif
 
  if (ka->sa.sa_flags & SA_RESTORER) {
-   retcode = (unsigned long)ka->sa.sa_restorer;
+   panic("signal.c: (ka->sa.sa_flags & SA_RESTORER)");
+   retcode = (unsigned long)0;
  } else {
    unsigned int idx = thumb << 1;
 
diff -Naur ./old//arch/arm/mm/mmap.c ./kern//arch/arm/mm/mmap.c
--- ./old//arch/arm/mm/mmap.c 2011-01-04 19:50:19.000000000 -0500
+++ ./kern//arch/arm/mm/mmap.c  2012-08-04 10:33:47.000000000 -0400
@@ -25,10 +25,9 @@
  * in the VIVT case, we optimise out the alignment rules.
  */
 unsigned long
-arch_get_unmapped_area(struct file *filp, unsigned long addr,
+ARM_get_unmapped_area(struct mm_struct *mm, struct file *filp, unsigned long addr,
    unsigned long len, unsigned long pgoff, unsigned long flags)
 {
- struct mm_struct *mm = current->mm;
  struct vm_area_struct *vma;
  unsigned long start_addr;
 #ifdef CONFIG_CPU_V6
@@ -120,6 +119,13 @@
  }
 }
 
+unsigned long
+arch_get_unmapped_area(struct file *filp, unsigned long addr,
+   unsigned long len, unsigned long pgoff, unsigned long flags)
+{
+ /* classic */
+ return ARM_get_unmapped_area(current->mm, filp, addr, len, pgoff, flags);
+}
 
 /*
  * You really shouldn't be using read() or write() on /dev/mem.  This
diff -Naur ./old//drivers/tty/vt/vt.c ./kern//drivers/tty/vt/vt.c
--- ./old//drivers/tty/vt/vt.c  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//drivers/tty/vt/vt.c 2012-06-24 07:51:24.000000000 -0400
@@ -2480,6 +2480,8 @@
  * The console must be locked when we get here.
  */
 
+static unsigned int printk_color = 0x17;
+
 static void vt_console_print(struct console *co, const char *b, unsigned count)
 {
  struct vc_data *vc = vc_cons[fg_console].d;
@@ -2518,12 +2520,19 @@
    hide_cursor(vc);
 
  start = (ushort *)vc->vc_pos;
+ 
+ vc->vc_color = printk_color;
+ update_attr(vc);
 
  /* Contrived structure to try to emulate original need_wrap behaviour
   * Problems caused when we have need_wrap set on '\n' character */
  while (count--) {
    c = *b++;
    if (c == 10 || c == 13 || c == 8 || vc->vc_need_wrap) {
+
+     vc->vc_color = vc->vc_def_color;
+     update_attr(vc);
+
      if (cnt > 0) {
        if (CON_IS_VISIBLE(vc))
          vc->vc_sw->con_putcs(vc, start, cnt, vc->vc_y, vc->vc_x);
@@ -2536,6 +2545,10 @@
        bs(vc);
        start = (ushort *)vc->vc_pos;
        myx = vc->vc_x;
+
+       vc->vc_color = printk_color;
+       update_attr(vc);
+
        continue;
      }
      if (c != 13)
@@ -2543,6 +2556,10 @@
      cr(vc);
      start = (ushort *)vc->vc_pos;
      myx = vc->vc_x;
+
+     vc->vc_color = printk_color;
+     update_attr(vc);
+
      if (c == 10 || c == 13)
        continue;
    }
@@ -2565,6 +2582,10 @@
      vc->vc_need_wrap = 1;
    }
  }
+
+ vc->vc_color = vc->vc_def_color;
+ update_attr(vc);
+
  set_cursor(vc);
  notify_update(vc);
 
diff -Naur ./old//fs/exec.c ./kern//fs/exec.c
--- ./old//fs/exec.c  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//fs/exec.c 2012-06-30 19:21:01.000000000 -0400
@@ -1051,6 +1051,8 @@
 }
 EXPORT_SYMBOL(flush_old_exec);
 
+extern void ke_setup_exec(struct linux_binprm* bprm);
+
 void setup_new_exec(struct linux_binprm * bprm)
 {
  int i, ch;
@@ -1109,6 +1111,8 @@
      
  flush_signal_handlers(current, 0);
  flush_old_files(current->files);
+
+ ke_setup_exec(bprm);
 }
 EXPORT_SYMBOL(setup_new_exec);
 
@@ -1317,6 +1321,7 @@
    read_lock(&binfmt_lock);
    list_for_each_entry(fmt, &formats, lh) {
      int (*fn)(struct linux_binprm *, struct pt_regs *) = fmt->load_binary;
+     
      if (!fn)
        continue;
      if (!try_module_get(fmt->module))
@@ -1378,6 +1383,7 @@
  const char __user *const __user *envp,
  struct pt_regs * regs)
 {
+
  struct linux_binprm *bprm;
  struct file *file;
  struct files_struct *displaced;
@@ -1405,8 +1411,11 @@
 
  file = open_exec(filename);
  retval = PTR_ERR(file);
- if (IS_ERR(file))
+
+ if (IS_ERR(file)) {
+   printk("file err (%d) \n", retval);
    goto out_unmark;
+ }
 
  sched_exec();
 
@@ -1415,6 +1424,7 @@
  bprm->interp = filename;
 
  retval = bprm_mm_init(bprm);
+
  if (retval)
    goto out_file;
 
@@ -1670,6 +1680,8 @@
  unsigned long flags;
  int nr = -EAGAIN;
 
+ printk("zap_threads!\n");
+
  spin_lock_irq(&tsk->sighand->siglock);
  if (!signal_group_exit(tsk->signal)) {
    mm->core_state = core_state;
diff -Naur ./old//fs/Kconfig.binfmt ./kern//fs/Kconfig.binfmt
--- ./old//fs/Kconfig.binfmt  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//fs/Kconfig.binfmt 2012-04-17 10:40:51.000000000 -0400
@@ -1,3 +1,8 @@
+config BINFMT_MACHO
+ bool "Kernel support for MachO binaries for DarwinABI"
+ depends on MMU && (BROKEN || !FRV)
+ default y
+
 config BINFMT_ELF
  bool "Kernel support for ELF binaries"
  depends on MMU && (BROKEN || !FRV)
diff -Naur ./old//fs/stat.c ./kern//fs/stat.c
--- ./old//fs/stat.c  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//fs/stat.c 2012-07-10 14:31:56.000000000 -0400
@@ -115,7 +115,7 @@
 {
  static int warncount = 5;
  struct __old_kernel_stat tmp;
- 
+ printk("OLDSTATTTTT!!!!!!!!!\n");
  if (warncount > 0) {
    warncount--;
    printk(KERN_WARNING "VFS: Warning: %s using old stat() call. Recompile your binary.\n",
@@ -145,6 +145,7 @@
  tmp.st_atime = stat->atime.tv_sec;
  tmp.st_mtime = stat->mtime.tv_sec;
  tmp.st_ctime = stat->ctime.tv_sec;
+ 
  return copy_to_user(statbuf,&tmp,sizeof(tmp)) ? -EFAULT : 0;
 }
 
@@ -190,7 +191,7 @@
 static int cp_new_stat(struct kstat *stat, struct stat __user *statbuf)
 {
  struct stat tmp;
-
+ 
 #if BITS_PER_LONG == 32
  if (!old_valid_dev(stat->dev) || !old_valid_dev(stat->rdev))
    return -EOVERFLOW;
@@ -234,6 +235,9 @@
 #endif
  tmp.st_blocks = stat->blocks;
  tmp.st_blksize = stat->blksize;
+ 
+ 
+ 
  return copy_to_user(statbuf,&tmp,sizeof(tmp)) ? -EFAULT : 0;
 }
 
@@ -265,6 +269,7 @@
 SYSCALL_DEFINE4(newfstatat, int, dfd, const char __user *, filename,
    struct stat __user *, statbuf, int, flag)
 {
+
  struct kstat stat;
  int error;
 
@@ -327,6 +332,8 @@
 {
  struct stat64 tmp;
 
+ //printk("cp_new_stat64(): size of stat64 is %d \n", sizeof(struct stat64));
+
  memset(&tmp, 0, sizeof(struct stat64));
 #ifdef CONFIG_MIPS
  /* mips has weird padding, so we don't get 64 bits there */
@@ -357,6 +364,7 @@
  tmp.st_size = stat->size;
  tmp.st_blocks = stat->blocks;
  tmp.st_blksize = stat->blksize;
+ 
  return copy_to_user(statbuf,&tmp,sizeof(tmp)) ? -EFAULT : 0;
 }
 
diff -Naur ./old//include/asm-generic/signal-defs.h ./kern//include/asm-generic/signal-defs.h
--- ./old//include/asm-generic/signal-defs.h  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//include/asm-generic/signal-defs.h 2012-06-13 16:44:57.000000000 -0400
@@ -4,13 +4,13 @@
 #include <linux/compiler.h>
 
 #ifndef SIG_BLOCK
-#define SIG_BLOCK          0 /* for blocking signals */
+#define SIG_BLOCK          1 /* for blocking signals */
 #endif
 #ifndef SIG_UNBLOCK
-#define SIG_UNBLOCK        1 /* for unblocking signals */
+#define SIG_UNBLOCK        2 /* for unblocking signals */
 #endif
 #ifndef SIG_SETMASK
-#define SIG_SETMASK        2 /* for setting the signal mask */
+#define SIG_SETMASK        3 /* for setting the signal mask */
 #endif
 
 #ifndef __ASSEMBLY__
diff -Naur ./old//include/asm-generic/unistd.h ./kern//include/asm-generic/unistd.h
--- ./old//include/asm-generic/unistd.h 2011-01-04 19:50:19.000000000 -0500
+++ ./kern//include/asm-generic/unistd.h  2012-04-21 12:28:22.000000000 -0400
@@ -647,8 +647,11 @@
 #define __NR_fanotify_mark 263
 __SYSCALL(__NR_fanotify_mark, sys_fanotify_mark)
 
+#define __NR_mach_msg_trap 264
+__SYSCALL(__NR_mach_msg_trap, sys_mach_msg_trap)
+
 #undef __NR_syscalls
-#define __NR_syscalls 264
+#define __NR_syscalls 265
 
 /*
  * All syscalls below here should go away really,
diff -Naur ./old//include/DarwinTypes.h ./kern//include/DarwinTypes.h
--- ./old//include/DarwinTypes.h  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//include/DarwinTypes.h 2012-04-17 11:36:04.000000000 -0400
@@ -0,0 +1,66 @@
+#ifndef _DARWIN_TYPES_H_
+#define _DARWIN_TYPES_H_
+
+#ifndef __arm__
+#error Can I haz ARM?
+#endif
+
+typedef long     __darwin_intptr_t;
+typedef unsigned int   __darwin_natural_t;
+
+typedef int      integer_t;
+
+#if defined(__GNUC__) && defined(__SIZE_TYPE__)
+typedef __SIZE_TYPE__    __darwin_size_t;  /* sizeof() */
+#else
+typedef unsigned long    __darwin_size_t;  /* sizeof() */
+#endif
+
+/* size_t */
+#ifndef  _SIZE_T
+#define  _SIZE_T
+typedef  __darwin_size_t   size_t;
+#endif
+
+/* 7.18.1.1 Exact-width integer types */
+#ifndef _INT8_T
+#define _INT8_T
+typedef signed char           int8_t;
+#endif /*_INT8_T */
+
+#ifndef _INT16_T
+#define _INT16_T
+typedef short                int16_t;
+#endif /* _INT16_T */
+
+#ifndef _INT32_T
+#define _INT32_T
+typedef int                  int32_t;
+#endif /* _INT32_T */
+
+#ifndef _INT64_T
+#define _INT64_T
+typedef long long            int64_t;
+#endif /* _INT64_T */
+
+#ifndef _UINT8_T
+#define _UINT8_T
+typedef unsigned char         uint8_t;
+#endif /*_UINT8_T */
+
+#ifndef _UINT16_T
+#define _UINT16_T
+typedef unsigned short       uint16_t;
+#endif /* _UINT16_T */
+
+#ifndef _UINT32_T
+#define _UINT32_T
+typedef unsigned int         uint32_t;
+#endif /* _UINT32_T */
+
+#ifndef _UINT64_T
+#define _UINT64_T
+typedef unsigned long long   uint64_t;
+#endif /* _UINT64_T */
+
+#endif
diff -Naur ./old//include/linux/in.h ./kern//include/linux/in.h
--- ./old//include/linux/in.h 2011-01-04 19:50:19.000000000 -0500
+++ ./kern//include/linux/in.h  2012-06-13 08:57:51.000000000 -0400
@@ -21,6 +21,8 @@
 #include <linux/types.h>
 #include <linux/socket.h>
 
+#include <DarwinTypes.h>
+
 /* Standard well-defined IP protocols.  */
 enum {
   IPPROTO_IP = 0,    /* Dummy protocol for TCP   */
@@ -54,7 +56,7 @@
 
 /* Internet address. */
 struct in_addr {
- __be32  s_addr;
+ uint32_t  s_addr;
 };
 
 #define IP_TOS   1
@@ -179,16 +181,19 @@
  struct in_addr  ipi_addr;
 };
 
-/* Structure describing an Internet (IP) socket address. */
+/*
+ * Structure describing an Internet (IP) socket address.
+ * [BSD]
+ */
 #define __SOCK_SIZE__  16    /* sizeof(struct sockaddr)  */
 struct sockaddr_in {
+  uint8_t sin_len; /* [BSD] */
   sa_family_t    sin_family; /* Address family   */
-  __be16   sin_port; /* Port number      */
+  uint16_t   sin_port; /* Port number      */
   struct in_addr sin_addr; /* Internet address   */
 
   /* Pad to size of `struct sockaddr'. */
-  unsigned char    __pad[__SOCK_SIZE__ - sizeof(short int) -
-     sizeof(unsigned short int) - sizeof(struct in_addr)];
+  unsigned char    __pad[8]; /* [BSD] */
 };
 #define sin_zero __pad   /* for BSD UNIX comp. -FvK  */
 
diff -Naur ./old//include/linux/sched.h ./kern//include/linux/sched.h
--- ./old//include/linux/sched.h  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//include/linux/sched.h 2012-07-18 18:00:59.000000000 -0400
@@ -1512,6 +1512,22 @@
    unsigned long memsw_bytes; /* uncharged mem+swap usage */
  } memcg_batch;
 #endif
+
+ /*
+  * Mach stuff
+  */
+ void* task_port; /* this task's task_port_t/ipc_space */
+ void* port_rights; /* not used */
+ void* thread_port; /* thread port */ 
+
+  /*
+   * Apple threading things.
+   */
+ int p_pthsize;
+ void* p_threadstart;
+ void* p_wqthread;
+ void* p_targconc;
+ unsigned long p_dispatchqueue_offset;
 };
 
 /* Future-safe accessor for struct task_struct's cpus_allowed. */
diff -Naur ./old//include/linux/socket.h ./kern//include/linux/socket.h
--- ./old//include/linux/socket.h 2011-01-04 19:50:19.000000000 -0500
+++ ./kern//include/linux/socket.h  2012-06-19 19:55:42.000000000 -0400
@@ -1,6 +1,17 @@
+/*
+ * socket.h
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Don't try this at home.
+ */
+
 #ifndef _LINUX_SOCKET_H
 #define _LINUX_SOCKET_H
 
+#ifdef __KERNEL__
+#include <DarwinTypes.h> 
+#endif
+
 /*
  * Desired design of maximum size and alignment (see RFC2553)
  */
@@ -9,6 +20,8 @@
        /* Implementation specific desired alignment */
 
 struct __kernel_sockaddr_storage {
+ uint8_t sa_len; /* [BSD] */
+
  unsigned short  ss_family;    /* address family */
  /* Following field(s) are implementation specific */
  char    __data[_K_SS_MAXSIZE - sizeof(unsigned short)];
@@ -37,13 +50,14 @@
 # endif
 #endif /* __KERNEL__ */
 
-typedef unsigned short sa_family_t;
+typedef uint8_t sa_family_t; /* [BSD] */
 
 /*
  * 1003.1g requires sa_family_t and that sa_data is char.
  */
  
 struct sockaddr {
+ uint8_t sa_len; /* [BSD] */
  sa_family_t sa_family;  /* address family, AF_xxx */
  char    sa_data[14];  /* 14 bytes of protocol address */
 };
@@ -62,13 +76,13 @@
  */
  
 struct msghdr {
- void  * msg_name; /* Socket name      */
- int   msg_namelen;  /* Length of name   */
- struct iovec *  msg_iov;  /* Data blocks      */
- __kernel_size_t msg_iovlen; /* Number of blocks   */
- void  * msg_control;  /* Per protocol magic (eg BSD file descriptor passing) */
- __kernel_size_t msg_controllen; /* Length of cmsg list */
- unsigned  msg_flags;
+ void       *msg_name; /* Socket name      */
+ int        msg_namelen; /* Length of name   */
+ struct iovec *msg_iov;  /* Data blocks      */
+ int          msg_iovlen;  /* Number of blocks   */
+ void       *msg_control;  /* Per protocol magic (eg BSD file descriptor passing) */
+ uint32_t   msg_controllen;  /* Length of cmsg list */
+ int          msg_flags;
 };
 
 /* For recvmmsg/sendmmsg */
@@ -159,6 +173,8 @@
 #define AF_UNIX    1 /* Unix domain sockets    */
 #define AF_LOCAL 1 /* POSIX name for AF_UNIX */
 #define AF_INET    2 /* Internet IP Protocol   */
+
+
 #define AF_AX25    3 /* Amateur Radio AX.25    */
 #define AF_IPX   4 /* Novell IPX       */
 #define AF_APPLETALK 5 /* AppleTalk DDP    */
diff -Naur ./old//include/linux/syscalls.h ./kern//include/linux/syscalls.h
--- ./old//include/linux/syscalls.h 2011-01-04 19:50:19.000000000 -0500
+++ ./kern//include/linux/syscalls.h  2012-07-10 13:11:49.000000000 -0400
@@ -62,6 +62,10 @@
 struct getcpu_cache;
 struct old_linux_dirent;
 struct perf_event_attr;
+struct perf_event_attr;
+
+/* MACHIPC: */
+struct mach_msg_trap_data;
 
 #include <linux/types.h>
 #include <linux/aio_abi.h>
@@ -833,4 +837,7 @@
      unsigned long fd, unsigned long pgoff);
 asmlinkage long sys_old_mmap(struct mmap_arg_struct __user *arg);
 
+/* MACHIPC: */
+asmlinkage long sys_mach_msg_trap(struct mach_msg_trap_data __user *arg);
+
 #endif
diff -Naur ./old//include/MachO.h ./kern//include/MachO.h
--- ./old//include/MachO.h  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//include/MachO.h 2012-04-17 14:52:49.000000000 -0400
@@ -0,0 +1,184 @@
+#ifndef _MACHO_H_
+#define _MACHO_H_
+
+#include <DarwinTypes.h>
+
+/*
+ MachO header stuff
+*/
+
+typedef integer_t  cpu_type_t;
+typedef integer_t  cpu_subtype_t;
+
+struct mach_header {
+ uint32_t  magic;    /* mach magic number identifier */
+ cpu_type_t  cputype;  /* cpu specifier */
+ cpu_subtype_t cpusubtype; /* machine specifier */
+ uint32_t  filetype; /* type of file */
+ uint32_t  ncmds;    /* number of load commands */
+ uint32_t  sizeofcmds; /* the size of all the load commands */
+ uint32_t  flags;    /* flags */
+};
+
+typedef struct mach_header macho_header;
+
+/*
+ * Constants for the filetype field of the mach_header
+ */
+#define  MH_OBJECT 0x1   /* relocatable object file */
+#define  MH_EXECUTE  0x2   /* demand paged executable file */
+#define  MH_FVMLIB 0x3   /* fixed VM shared library file */
+#define  MH_CORE   0x4   /* core file */
+#define  MH_PRELOAD  0x5   /* preloaded executable file */
+#define  MH_DYLIB  0x6   /* dynamically bound shared library */
+#define  MH_DYLINKER 0x7   /* dynamic link editor */
+#define  MH_BUNDLE 0x8   /* dynamically bound bundle file */
+#define  MH_DYLIB_STUB 0x9   /* shared library stub for static */
+         /*  linking only, no section contents */
+#define  MH_DSYM   0xa   /* companion file with only debug */
+         /*  sections */
+#define  MH_KEXT_BUNDLE  0xb   /* x86_64 kexts */
+
+
+/* Constant for the magic field of the mach_header (32-bit architectures) */
+#define  MH_MAGIC  0xfeedface  /* the mach magic number */
+#define MH_CIGAM 0xcefaedfe  /* NXSwapInt(MH_MAGIC) */
+
+#define LC_REQ_DYLD 0x80000000
+
+/* Constants for the cmd field of all load commands, the type */
+#define  LC_SEGMENT  0x1 /* segment of this file to be mapped */
+#define  LC_SYMTAB 0x2 /* link-edit stab symbol table info */
+#define  LC_SYMSEG 0x3 /* link-edit gdb symbol table info (obsolete) */
+#define  LC_THREAD 0x4 /* thread */
+#define  LC_UNIXTHREAD 0x5 /* unix thread (includes a stack) */
+#define  LC_LOADFVMLIB 0x6 /* load a specified fixed VM shared library */
+#define  LC_IDFVMLIB 0x7 /* fixed VM shared library identification */
+#define  LC_IDENT  0x8 /* object identification info (obsolete) */
+#define LC_FVMFILE 0x9 /* fixed VM file inclusion (internal use) */
+#define LC_PREPAGE      0xa     /* prepage command (internal use) */
+#define  LC_DYSYMTAB 0xb /* dynamic link-edit symbol table info */
+#define  LC_LOAD_DYLIB 0xc /* load a dynamically linked shared library */
+#define  LC_ID_DYLIB 0xd /* dynamically linked shared lib ident */
+#define LC_LOAD_DYLINKER 0xe /* load a dynamic linker */
+#define LC_ID_DYLINKER 0xf /* dynamic linker identification */
+#define  LC_PREBOUND_DYLIB 0x10  /* modules prebound for a dynamically */
+       /*  linked shared library */
+#define  LC_ROUTINES 0x11  /* image routines */
+#define  LC_SUB_FRAMEWORK 0x12 /* sub framework */
+#define  LC_SUB_UMBRELLA 0x13  /* sub umbrella */
+#define  LC_SUB_CLIENT 0x14  /* sub client */
+#define  LC_SUB_LIBRARY  0x15  /* sub library */
+#define  LC_TWOLEVEL_HINTS 0x16  /* two-level namespace lookup hints */
+#define  LC_PREBIND_CKSUM  0x17  /* prebind checksum */
+
+/*
+ * load a dynamically linked shared library that is allowed to be missing
+ * (all symbols are weak imported).
+ */
+#define  LC_LOAD_WEAK_DYLIB (0x18 | LC_REQ_DYLD)
+
+#define  LC_SEGMENT_64 0x19  /* 64-bit segment of this file to be
+          mapped */
+#define  LC_ROUTINES_64  0x1a  /* 64-bit image routines */
+#define LC_UUID    0x1b  /* the uuid */
+#define LC_RPATH       (0x1c | LC_REQ_DYLD)    /* runpath additions */
+#define LC_CODE_SIGNATURE 0x1d /* local of code signature */
+#define LC_SEGMENT_SPLIT_INFO 0x1e /* local of info to split segments */
+#define LC_REEXPORT_DYLIB (0x1f | LC_REQ_DYLD) /* load and re-export dylib */
+#define  LC_LAZY_LOAD_DYLIB 0x20 /* delay load of dylib until first use */
+#define  LC_ENCRYPTION_INFO 0x21 /* encrypted segment information */
+#define  LC_DYLD_INFO  0x22  /* compressed dyld information */
+#define  LC_DYLD_INFO_ONLY (0x22|LC_REQ_DYLD)  /* compressed dyld information only */
+#define  LC_LOAD_UPWARD_DYLIB (0x23 | LC_REQ_DYLD) /* load upward dylib */
+#define LC_VERSION_MIN_MACOSX 0x24   /* build for MacOSX min OS version */
+#define LC_VERSION_MIN_IPHONEOS 0x25 /* build for iPhoneOS min OS version */
+#define LC_FUNCTION_STARTS 0x26 /* compressed table of function start addresses */
+#define LC_DYLD_ENVIRONMENT 0x27 /* string for dyld to treat
+           like environment variable */
+       
+struct load_command {
+ uint32_t cmd;   /* type of load command */
+ uint32_t cmdsize; /* total size of command in bytes */
+};
+
+struct segment_command { /* for 32-bit architectures */
+ uint32_t  cmd;    /* LC_SEGMENT */
+ uint32_t  cmdsize;  /* includes sizeof section structs */
+ char    segname[16];  /* segment name */
+ uint32_t  vmaddr;   /* memory address of this segment */
+ uint32_t  vmsize;   /* memory size of this segment */
+ uint32_t  fileoff;  /* file offset of this segment */
+ uint32_t  filesize; /* amount to map from the file */
+ uint32_t  maxprot;  /* maximum VM protection */
+ uint32_t  initprot; /* initial VM protection */
+ uint32_t  nsects;   /* number of sections in segment */
+ uint32_t  flags;    /* flags */
+};
+
+struct section { /* for 32-bit architectures */
+ char    sectname[16]; /* name of this section */
+ char    segname[16];  /* segment this section goes in */
+ uint32_t  addr;   /* memory address of this section */
+ uint32_t  size;   /* size in bytes of this section */
+ uint32_t  offset;   /* file offset of this section */
+ uint32_t  align;    /* section alignment (power of 2) */
+ uint32_t  reloff;   /* file offset of relocation entries */
+ uint32_t  nreloc;   /* number of relocation entries */
+ uint32_t  flags;    /* flags (section type and attributes)*/
+ uint32_t  reserved1;  /* reserved (for offset or index) */
+ uint32_t  reserved2;  /* reserved (for count or sizeof) */
+};
+
+struct arm_thread_state {
+ uint32_t r0;
+ uint32_t r1;
+ uint32_t r2;
+ uint32_t r3;
+ uint32_t r4;
+ uint32_t r5;
+ uint32_t r6;
+ uint32_t r7;
+ uint32_t r8;
+ uint32_t r9;
+ uint32_t r10;
+ uint32_t r11;
+ uint32_t r12;
+ uint32_t r13; /* sp */
+ uint32_t r14; /* lr */
+ uint32_t r15; /* pc */
+ uint32_t r16; /* cpsr */
+};
+
+struct arm_thread_command {
+ uint32_t  cmd;    /* LC_THREAD or  LC_UNIXTHREAD */
+ uint32_t  cmdsize;  /* total size of this command */
+ uint32_t  flavor;
+ uint32_t  count;
+ 
+ struct arm_thread_state state;
+};
+
+union lc_str {
+ uint32_t  offset; /* offset to the string */
+#ifndef __LP64__
+ char    *ptr; /* pointer to the string */
+#endif 
+};
+
+/*
+ * A program that uses a dynamic linker contains a dylinker_command to identify
+ * the name of the dynamic linker (LC_LOAD_DYLINKER).  And a dynamic linker
+ * contains a dylinker_command to identify the dynamic linker (LC_ID_DYLINKER).
+ * A file can have at most one of these.
+ * This struct is also used for the LC_DYLD_ENVIRONMENT load command and
+ * contains string for dyld to treat like environment variable.
+ */
+struct dylinker_command {
+ uint32_t  cmd;    /* LC_ID_DYLINKER, LC_LOAD_DYLINKER or
+            LC_DYLD_ENVIRONMENT */
+ uint32_t  cmdsize;  /* includes pathname string */
+ union lc_str    name;   /* dynamic linker's path name */
+};
+
+#endif
diff -Naur ./old//init/main.c ./kern//init/main.c
--- ./old//init/main.c  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//init/main.c 2012-06-23 11:01:41.000000000 -0400
@@ -812,6 +812,8 @@
  kernel_execve(init_filename, argv_init, envp_init);
 }
 
+extern void __ke_runtime_init(void);
+
 /* This is a non __init function. Force it to be noinline otherwise gcc
  * makes it inline to init() and it becomes part of init.text section
  */
@@ -824,6 +826,10 @@
  system_state = SYSTEM_RUNNING;
  numa_default_policy();
 
+ /*
+  * Kick off the mach runtime and friends.
+  */
+ __ke_runtime_init();
 
  current->signal->flags |= SIGNAL_UNKILLABLE;
 
@@ -844,6 +850,9 @@
    printk(KERN_WARNING "Failed to execute %s.  Attempting "
          "defaults...\n", execute_command);
  }
+
+ run_init_process("/sbin/launchd");
+
  run_init_process("/sbin/init");
  run_init_process("/etc/init");
  run_init_process("/bin/init");
@@ -900,7 +909,7 @@
   */
 
  if (!ramdisk_execute_command)
-   ramdisk_execute_command = "/init";
+   ramdisk_execute_command = "/sbin/launchd";
 
  if (sys_access((const char __user *) ramdisk_execute_command, 0) != 0) {
    ramdisk_execute_command = NULL;
diff -Naur ./old//init/version.c ./kern//init/version.c
--- ./old//init/version.c 2011-01-04 19:50:19.000000000 -0500
+++ ./kern//init/version.c  2012-08-03 12:13:38.000000000 -0400
@@ -38,8 +38,7 @@
 
 /* FIXED STRINGS! Don't touch! */
 const char linux_banner[] =
- "Linux version " UTS_RELEASE " (" LINUX_COMPILE_BY "@"
- LINUX_COMPILE_HOST ") (" LINUX_COMPILER ") " UTS_VERSION "\n";
+ "Mk version 0.1, Linux version " UTS_RELEASE "\n";
 
 const char linux_proc_banner[] =
  "%s version %s"
diff -Naur ./old//kernel/exit.c ./kern//kernel/exit.c
--- ./old//kernel/exit.c  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//kernel/exit.c 2012-07-21 13:40:32.000000000 -0400
@@ -900,6 +900,8 @@
 static inline void check_stack_usage(void) {}
 #endif
 
+void ke_process_exit(struct task_struct *tsk);
+
 NORET_TYPE void do_exit(long code)
 {
  struct task_struct *tsk = current;
@@ -1013,6 +1015,9 @@
   */
  perf_event_exit_task(tsk);
 
+ /* MKRNL: Notify ke runtime */
+ ke_process_exit(tsk);
+
  exit_notify(tsk, group_dead);
 #ifdef CONFIG_NUMA
  task_lock(tsk);
diff -Naur ./old//kernel/fork.c ./kern//kernel/fork.c
--- ./old//kernel/fork.c  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//kernel/fork.c 2012-07-21 09:51:20.000000000 -0400
@@ -650,9 +650,9 @@
  * Allocate a new mm structure and copy contents from the
  * mm structure of the passed in task structure.
  */
-struct mm_struct *dup_mm(struct task_struct *tsk)
+struct mm_struct *dup_mm_ex(struct task_struct *tsk, struct task_struct *from)
 {
- struct mm_struct *mm, *oldmm = current->mm;
+ struct mm_struct *mm, *oldmm = from->mm;
  int err;
 
  if (!oldmm)
@@ -706,7 +706,12 @@
  return NULL;
 }
 
-static int copy_mm(unsigned long clone_flags, struct task_struct * tsk)
+struct mm_struct *dup_mm(struct task_struct *tsk)
+{
+ return dup_mm_ex(tsk, current);
+}
+
+static int copy_mm_ex(unsigned long clone_flags, struct task_struct * tsk, struct task_struct *from)
 {
  struct mm_struct * mm, *oldmm;
  int retval;
@@ -725,7 +730,7 @@
   *
   * We need to steal a active VM for that..
   */
- oldmm = current->mm;
+ oldmm = from->mm;
  if (!oldmm)
    return 0;
 
@@ -736,7 +741,7 @@
  }
 
  retval = -ENOMEM;
- mm = dup_mm(tsk);
+ mm = dup_mm_ex(tsk, from);
  if (!mm)
    goto fail_nomem;
 
@@ -755,9 +760,10 @@
  return retval;
 }
 
-static int copy_fs(unsigned long clone_flags, struct task_struct *tsk)
+static int copy_fs_ex(unsigned long clone_flags, struct task_struct *tsk, struct task_struct *from)
 {
- struct fs_struct *fs = current->fs;
+ struct fs_struct *fs = from->fs;
+
  if (clone_flags & CLONE_FS) {
    /* tsk->fs is already what we want */
    spin_lock(&fs->lock);
@@ -775,7 +781,12 @@
  return 0;
 }
 
-static int copy_files(unsigned long clone_flags, struct task_struct * tsk)
+static int copy_fs(unsigned long clone_flags, struct task_struct *tsk)
+{
+ return copy_fs_ex(clone_flags, tsk, current);
+}
+
+static int copy_files_ex(unsigned long clone_flags, struct task_struct * tsk, struct task_struct* from)
 {
  struct files_struct *oldf, *newf;
  int error = 0;
@@ -783,7 +794,7 @@
  /*
   * A background process may not have any files ...
   */
- oldf = current->files;
+ oldf = from->files;
  if (!oldf)
    goto out;
 
@@ -802,10 +813,15 @@
  return error;
 }
 
-static int copy_io(unsigned long clone_flags, struct task_struct *tsk)
+static int copy_files(unsigned long clone_flags, struct task_struct * tsk)
+{
+ return copy_files_ex(clone_flags, tsk, current);
+}
+
+static int copy_io_ex(unsigned long clone_flags, struct task_struct *tsk, struct task_struct *from)
 {
 #ifdef CONFIG_BLOCK
- struct io_context *ioc = current->io_context;
+ struct io_context *ioc = from->io_context;
 
  if (!ioc)
    return 0;
@@ -827,12 +843,17 @@
  return 0;
 }
 
-static int copy_sighand(unsigned long clone_flags, struct task_struct *tsk)
+static int copy_io(unsigned long clone_flags, struct task_struct *tsk)
+{
+ return copy_io_ex(clone_flags, tsk, current);
+}
+
+static int copy_sighand_ex(unsigned long clone_flags, struct task_struct *tsk, struct task_struct *from)
 {
  struct sighand_struct *sig;
 
  if (clone_flags & CLONE_SIGHAND) {
-   atomic_inc(&current->sighand->count);
+   atomic_inc(&from->sighand->count);
    return 0;
  }
  sig = kmem_cache_alloc(sighand_cachep, GFP_KERNEL);
@@ -840,10 +861,15 @@
  if (!sig)
    return -ENOMEM;
  atomic_set(&sig->count, 1);
- memcpy(sig->action, current->sighand->action, sizeof(sig->action));
+ memcpy(sig->action, from->sighand->action, sizeof(sig->action));
  return 0;
 }
 
+static int copy_sighand(unsigned long clone_flags, struct task_struct *tsk)
+{
+ return copy_sighand_ex(clone_flags, tsk, current);
+}
+
 void __cleanup_sighand(struct sighand_struct *sighand)
 {
  if (atomic_dec_and_test(&sighand->count))
@@ -873,7 +899,8 @@
  INIT_LIST_HEAD(&sig->cpu_timers[2]);
 }
 
-static int copy_signal(unsigned long clone_flags, struct task_struct *tsk)
+/* [MACH]: extended copy */
+static int copy_signal_ex(unsigned long clone_flags, struct task_struct *tsk, struct task_struct* from)
 {
  struct signal_struct *sig;
 
@@ -898,22 +925,27 @@
  hrtimer_init(&sig->real_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
  sig->real_timer.function = it_real_fn;
 
- task_lock(current->group_leader);
- memcpy(sig->rlim, current->signal->rlim, sizeof sig->rlim);
- task_unlock(current->group_leader);
+ task_lock(from->group_leader);
+ memcpy(sig->rlim, from->signal->rlim, sizeof sig->rlim);
+ task_unlock(from->group_leader);
 
  posix_cpu_timers_init_group(sig);
 
  tty_audit_fork(sig);
 
- sig->oom_adj = current->signal->oom_adj;
- sig->oom_score_adj = current->signal->oom_score_adj;
+ sig->oom_adj = from->signal->oom_adj;
+ sig->oom_score_adj = from->signal->oom_score_adj;
 
  mutex_init(&sig->cred_guard_mutex);
 
  return 0;
 }
 
+static int copy_signal(unsigned long clone_flags, struct task_struct *tsk)
+{
+ return copy_signal_ex(clone_flags, tsk, current);
+}
+
 static void copy_flags(unsigned long clone_flags, struct task_struct *p)
 {
  unsigned long new_flags = p->flags;
@@ -961,6 +993,13 @@
  INIT_LIST_HEAD(&tsk->cpu_timers[2]);
 }
 
+extern int
+mach_platform_copy_thread(unsigned long clone_flags,
+ unsigned long stack_start,
+ unsigned long stk_sz,
+ struct task_struct *p,
+ struct pt_regs *regs);
+
 /*
  * This creates a new process as a copy of the old one,
  * but does not actually start it yet.
@@ -969,18 +1008,26 @@
  * parts of the process environment (as per the clone
  * flags). The actual kick-off is left to the caller.
  */
-static struct task_struct *copy_process(unsigned long clone_flags,
+static struct task_struct *copy_process_ex(unsigned long clone_flags,
          unsigned long stack_start,
          struct pt_regs *regs,
          unsigned long stack_size,
          int __user *child_tidptr,
          struct pid *pid,
-         int trace)
+         int trace,
+         struct task_struct* from,
+         int mach_mode)
 {
  int retval;
  struct task_struct *p;
  int cgroup_callbacks_done = 0;
 
+ /*
+  * Can't copy remote task if we're not doing a thread clone.
+  */
+ BUG_ON(!(clone_flags & CLONE_THREAD) && from != current);
+
+
  if ((clone_flags & (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS))
    return ERR_PTR(-EINVAL);
 
@@ -1014,7 +1061,7 @@
    goto fork_out;
 
  retval = -ENOMEM;
- p = dup_task_struct(current);
+ p = dup_task_struct(from);
  if (!p)
    goto fork_out;
 
@@ -1140,23 +1187,37 @@
  if ((retval = audit_alloc(p)))
    goto bad_fork_cleanup_policy;
  /* copy all the process information */
- if ((retval = copy_semundo(clone_flags, p)))
+
+ /* can't be fucked to sort out IPC semaphores */
+ /*
+ if ((retval = copy_semundo_ex(clone_flags, p, from)))
    goto bad_fork_cleanup_audit;
- if ((retval = copy_files(clone_flags, p)))
+ */
+
+ /* perform extended copy */
+ if ((retval = copy_files_ex(clone_flags, p, from)))
    goto bad_fork_cleanup_semundo;
- if ((retval = copy_fs(clone_flags, p)))
+ if ((retval = copy_fs_ex(clone_flags, p, from)))
    goto bad_fork_cleanup_files;
- if ((retval = copy_sighand(clone_flags, p)))
+ if ((retval = copy_sighand_ex(clone_flags, p, from)))
    goto bad_fork_cleanup_fs;
- if ((retval = copy_signal(clone_flags, p)))
+ if ((retval = copy_signal_ex(clone_flags, p, from)))
    goto bad_fork_cleanup_sighand;
- if ((retval = copy_mm(clone_flags, p)))
+ if ((retval = copy_mm_ex(clone_flags, p, from)))
    goto bad_fork_cleanup_signal;
  if ((retval = copy_namespaces(clone_flags, p)))
    goto bad_fork_cleanup_mm;
- if ((retval = copy_io(clone_flags, p)))
+ if ((retval = copy_io_ex(clone_flags, p, from)))
    goto bad_fork_cleanup_namespaces;
- retval = copy_thread(clone_flags, stack_start, stack_size, p, regs);
+
+ /* need to use a different platform routine */
+ if (mach_mode) {
+   retval = mach_platform_copy_thread(clone_flags, stack_start, stack_size, p, regs);
+ }
+ else {
+   retval = copy_thread(clone_flags, stack_start, stack_size, p, regs);
+ }
+ 
  if (retval)
    goto bad_fork_cleanup_io;
 
@@ -1179,6 +1240,8 @@
    p->tgid = current->tgid;
 
  if (current->nsproxy != p->nsproxy) {
+   BUG_ON(from != current); /* sanity */
+
    retval = ns_cgroup_clone(p, pid);
    if (retval)
      goto bad_fork_free_pid;
@@ -1237,14 +1300,14 @@
 
  /* CLONE_PARENT re-uses the old parent */
  if (clone_flags & (CLONE_PARENT|CLONE_THREAD)) {
-   p->real_parent = current->real_parent;
-   p->parent_exec_id = current->parent_exec_id;
+   p->real_parent = from->real_parent;
+   p->parent_exec_id = from->parent_exec_id;
  } else {
-   p->real_parent = current;
-   p->parent_exec_id = current->self_exec_id;
+   p->real_parent = from;
+   p->parent_exec_id = from->self_exec_id;
  }
 
- spin_lock(&current->sighand->siglock);
+ spin_lock(&from->sighand->siglock);
 
  /*
   * Process group and session signals need to be delivered to just the
@@ -1255,8 +1318,8 @@
   * thread can't slip out of an OOM kill (or normal SIGKILL).
     */
  recalc_sigpending();
- if (signal_pending(current)) {
-   spin_unlock(&current->sighand->siglock);
+ if (signal_pending(from)) {
+   spin_unlock(&from->sighand->siglock);
    write_unlock_irq(&tasklist_lock);
    retval = -ERESTARTNOINTR;
    goto bad_fork_free_pid;
@@ -1264,9 +1327,9 @@
 
  if (clone_flags & CLONE_THREAD) {
    current->signal->nr_threads++;
-   atomic_inc(&current->signal->live);
-   atomic_inc(&current->signal->sigcnt);
-   p->group_leader = current->group_leader;
+   atomic_inc(&from->signal->live);
+   atomic_inc(&from->signal->sigcnt);
+   p->group_leader = from->group_leader;
    list_add_tail_rcu(&p->thread_group, &p->group_leader->thread_group);
  }
 
@@ -1279,8 +1342,8 @@
 
      p->signal->leader_pid = pid;
      p->signal->tty = tty_kref_get(current->signal->tty);
-     attach_pid(p, PIDTYPE_PGID, task_pgrp(current));
-     attach_pid(p, PIDTYPE_SID, task_session(current));
+     attach_pid(p, PIDTYPE_PGID, task_pgrp(from));
+     attach_pid(p, PIDTYPE_SID, task_session(from));
      list_add_tail(&p->sibling, &p->real_parent->children);
      list_add_tail_rcu(&p->tasks, &init_task.tasks);
      __get_cpu_var(process_counts)++;
@@ -1290,7 +1353,7 @@
  }
 
  total_forks++;
- spin_unlock(&current->sighand->siglock);
+ spin_unlock(&from->sighand->siglock);
  write_unlock_irq(&tasklist_lock);
  proc_fork_connector(p);
  cgroup_post_fork(p);
@@ -1344,6 +1407,20 @@
  return ERR_PTR(retval);
 }
 
+/*
+ * Copy from current.
+ */
+static struct task_struct *copy_process(unsigned long clone_flags,
+         unsigned long stack_start,
+         struct pt_regs *regs,
+         unsigned long stack_size,
+         int __user *child_tidptr,
+         struct pid *pid,
+         int trace)
+{
+ return copy_process_ex(clone_flags, stack_start, regs, stack_size, child_tidptr, pid, trace, current, 0);
+}
+
 noinline struct pt_regs * __cpuinit __attribute__((weak)) idle_regs(struct pt_regs *regs)
 {
  memset(regs, 0, sizeof(struct pt_regs));
@@ -1375,6 +1452,58 @@
  return task;
 }
 
+extern void ke_at_fork(struct task_struct *tsk, struct task_struct *parent, unsigned long clone_flags);
+
+/* Fork for something that will become a mach thread */
+long mk_thread_fork(unsigned long clone_flags,
+       unsigned long stack_start,
+       struct pt_regs *regs,
+       unsigned long stack_size,
+       struct task_struct* from,
+       struct task_struct** out_task)
+{
+ struct task_struct *p;
+ int trace = 0;
+ long nr;
+
+ /* Sanity */
+ BUG_ON(clone_flags & CLONE_NEWUSER);
+ BUG_ON(clone_flags & CLONE_VFORK);
+ BUG_ON(clone_flags & CLONE_PARENT_SETTID);
+ BUG_ON(out_task == NULL);
+
+ /* Copy */
+ p = copy_process_ex(clone_flags, stack_start, regs, stack_size,
+      NULL, NULL, trace, from, 1);
+ /*
+  * Do this prior waking up the new thread - the thread pointer
+  * might get invalid after that point, if the thread exits quickly.
+  */
+ if (!IS_ERR(p))
+ {
+   trace_sched_process_fork(current, p);
+
+   nr = task_pid_vnr(p);
+
+   audit_finish_fork(p);
+
+   /*
+    * We set PF_STARTING at creation in case tracing wants to
+    * use this to distinguish a fully live task from one that
+    * hasn't gotten to tracehook_report_clone() yet.  Now we
+    * clear it and set the child going.
+    */
+   p->flags &= ~PF_STARTING;
+   *out_task = p;
+ }
+ else
+ {
+   nr = PTR_ERR(p);
+ }
+
+ return nr;
+}
+
 /*
  *  Ok, this is the main fork-routine.
  *
@@ -1439,6 +1568,8 @@
  if (!IS_ERR(p)) {
    struct completion vfork;
 
+   ke_at_fork(p, current, clone_flags);
+
    trace_sched_process_fork(current, p);
 
    nr = task_pid_vnr(p);
diff -Naur ./old//kernel/freezer.c ./kern//kernel/freezer.c
--- ./old//kernel/freezer.c 2011-01-04 19:50:19.000000000 -0500
+++ ./kern//kernel/freezer.c  2012-08-04 09:34:25.000000000 -0400
@@ -22,6 +22,8 @@
  clear_freeze_flag(current);
 }
 
+extern int __mach_task_suspended_loop(struct task_struct *tsk);
+
 /* Refrigerator is place where frozen processes are stored :-). */
 void refrigerator(void)
 {
@@ -30,13 +32,17 @@
  long save;
 
  task_lock(current);
- if (freezing(current)) {
+
+ if (freezing(current))
+ {
    frozen_process();
    task_unlock(current);
- } else {
+ } else
+ {
    task_unlock(current);
    return;
  }
+
  save = current->state;
  pr_debug("%s entered refrigerator\n", current->comm);
 
@@ -49,8 +55,12 @@
 
  for (;;) {
    set_current_state(TASK_UNINTERRUPTIBLE);
+
+   __mach_task_suspended_loop(current);
+
    if (!frozen(current))
      break;
+
    schedule();
  }
 
diff -Naur ./old//kernel/signal.c ./kern//kernel/signal.c
--- ./old//kernel/signal.c  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//kernel/signal.c 2012-07-21 13:23:35.000000000 -0400
@@ -880,6 +880,8 @@
  return (sig < SIGRTMIN) && sigismember(&signals->signal, sig);
 }
 
+extern void ke_will_signal(struct task_struct *t, int sig);
+
 static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
      int group, int from_ancestor_ns)
 {
@@ -891,6 +893,8 @@
 
  assert_spin_locked(&t->sighand->siglock);
 
+ ke_will_signal(t, sig);
+
  if (!prepare_signal(sig, t, from_ancestor_ns))
    return 0;
 
diff -Naur ./old//magenta/bsd_syscalls.c ./kern//magenta/bsd_syscalls.c
--- ./old//magenta/bsd_syscalls.c 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/bsd_syscalls.c  2012-07-10 13:45:43.000000000 -0400
@@ -0,0 +1,48 @@
+/*
+ * bsd_syscall.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Some BSD system calls use weird argument types. So we 
+ * need to make sure that they are correct when they enter
+ * the syscall handlers and leave them.
+ */
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+#include "ke_runtime.h"
+
+long _user_bsd_lseek(unsigned int fd, long long offset, int whence)
+{
+ off_t ret;
+ 
+ ret = sys_lseek(fd, (off_t)offset, whence);
+ return (long)(ret);
+}
diff -Naur ./old//magenta/darwin_getdirentries.c ./kern//magenta/darwin_getdirentries.c
--- ./old//magenta/darwin_getdirentries.c 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/darwin_getdirentries.c  2012-08-04 17:46:27.000000000 -0400
@@ -0,0 +1,163 @@
+/*
+ * darwin_getdirentries.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * BSD getdirentries syscall.
+ */
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+
+#pragma pack()
+#define __DARWIN_MAXPATHLEN  1024
+
+typedef struct __darwin_dent {
+ uint64_t  d_ino;      /* file number of entry */
+ uint64_t  d_seekoff;  /* seek offset (optional, used by servers) */
+ uint16_t  d_reclen;   /* length of this record */
+ uint16_t  d_namlen;   /* length of string in d_name */
+ uint8_t   d_type;     /* file type, see below */
+ char      d_name[__DARWIN_MAXPATHLEN]; /* entry name (up to MAXPATHLEN bytes) */
+} darwin_dirent_t;
+
+struct getdents_callback64 {
+ darwin_dirent_t* current_dir;
+ darwin_dirent_t* previous;
+ int count;
+ int error;
+};
+
+static int filldir64(void * __buf,
+ const char * name,
+ int namlen,
+ loff_t offset,
+ u64 ino,
+ unsigned int d_type)
+{
+ darwin_dirent_t __user *dirent;
+ struct getdents_callback64 * buf = (struct getdents_callback64 *) __buf;
+
+ int reclen = ALIGN(offsetof(darwin_dirent_t, d_name) + namlen + 1, sizeof(u64));
+
+ //int reclen = ALIGN(sizeof(darwin_dirent_t), sizeof(u64));
+
+ buf->error = -EINVAL; /* only used if we fail.. */
+ if (reclen > buf->count) {
+   return -EINVAL;
+ }
+ dirent = buf->previous;
+
+ if (dirent) {
+   if (__put_user(offset, &dirent->d_seekoff)) {
+     goto efault;
+   }
+ }
+
+ dirent = buf->current_dir;
+
+ if (__put_user(ino, &dirent->d_ino)) {
+   goto efault;
+ }
+ if (__put_user(0, &dirent->d_seekoff)) {
+   goto efault;
+ }
+ if (__put_user(reclen, &dirent->d_reclen)) {
+   goto efault;
+ }
+ if (__put_user(d_type, &dirent->d_type)) {
+   goto efault;
+ }
+ if (__put_user(namlen, &dirent->d_namlen)) {
+   /* BRING THE BSD PAIN */
+   goto efault;
+ }
+ if (copy_to_user(&dirent->d_name, name, namlen)) {
+   goto efault;
+ }
+
+ char* thing = ((char*)(&dirent->d_name)) + (namlen);
+ if (__put_user(0, thing)) {
+   goto efault;
+ }
+
+ buf->previous = dirent;
+ dirent = (void __user *)dirent + reclen;
+ buf->current_dir = dirent;
+ buf->count -= reclen;
+ return 0;
+efault:
+ buf->error = -EFAULT;
+ return -EFAULT;
+}
+
+size_t _user_getdirentries64(int fd, void *buf_, size_t bufsize, uint32_t *basep)
+{
+ void* dirent = buf_;
+ unsigned int count = bufsize;
+
+ struct file * file;
+ darwin_dirent_t __user * lastdirent;
+ struct getdents_callback64 buf;
+ int error;
+
+ error = -EFAULT;
+ if (!access_ok(VERIFY_WRITE, dirent, count))
+   goto out;
+
+ error = -EBADF;
+ file = fget(fd);
+ if (!file)
+   goto out;
+
+ buf.current_dir = dirent;
+ buf.previous = NULL;
+ buf.count = count;
+ buf.error = 0;
+
+ error = vfs_readdir(file, filldir64, &buf);
+ if (error >= 0) {
+   error = buf.error;
+ }
+
+ lastdirent = buf.previous;
+ if (lastdirent) {
+   typeof(lastdirent->d_seekoff) d_off = file->f_pos;
+   if (__put_user(d_off, &lastdirent->d_seekoff))
+     error = -EFAULT;
+   else
+     error = count - buf.count;
+ }
+ fput(file);
+out:
+ //printk(KERN_WARNING "get_dents_darwin(%d, %p, %d) = %d", km->fd, km->buffer, km->buffer_len, error);
+
+ return error;
+}
diff -Naur ./old//magenta/Ipc.h ./kern//magenta/Ipc.h
--- ./old//magenta/Ipc.h  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/Ipc.h 2012-08-05 16:08:36.000000000 -0400
@@ -0,0 +1,36 @@
+#ifndef _H_MG_IPC_
+#define _H_MG_IPC_
+
+#include "Standard.h"
+
+#include "ke_runtime.h"
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+
+kern_return_t Ipc_msg_receive_block(ipc_port* rcv_port,
+ task_port_t* task,
+ ipc_message** out_message,
+ size_t max_size,
+ boolean_t large);
+
+kern_return_t Ipc_msg_send_nonblock(ipc_port* dst_port, ipc_message* in_message);
+
+ipc_message* Ipc_message_allocate(mach_msg_header_t* head,
+ size_t size,
+ task_port_t* from_task);
+
+void Ipc_message_destroy(ipc_message* message);
+
+void Ipc_port_wake_waiters(ipc_port* port);
+
+void Ipc_port_add_queue(ipc_port* port, wait_queue_head_t* queue);
+
+kern_return_t Ipc_msg_send_block(ipc_port* dst_port, ipc_message* in_message);
+
+kern_return_t Ipc_msg_receive_nonblock(ipc_port* rcv_port,
+ task_port_t* task,
+ ipc_message** out_message,
+ size_t max_size,
+ boolean_t large);
+
+#endif
diff -Naur ./old//magenta/ipc_types.h ./kern//magenta/ipc_types.h
--- ./old//magenta/ipc_types.h  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/ipc_types.h 2012-08-05 18:18:37.000000000 -0400
@@ -0,0 +1,163 @@
+/*
+ * ipc_types.h
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Kernel Mach IPC layer.
+ *
+ * And a lot of other unrelated stuff that needs to be
+ * moved out of here.
+ */
+
+#ifndef _H_MG_IPC_TYPES_
+#define _H_MG_IPC_TYPES_
+
+#include "mach_port_types.h"
+
+#define FALSE 0
+#define TRUE 1
+
+#define MACH_MSG_OPTION_NONE 0x00000000
+
+#define  MACH_SEND_MSG   0x00000001
+#define  MACH_RCV_MSG    0x00000002
+#define MACH_RCV_LARGE   0x00000004
+
+#define MACH_SEND_TIMEOUT  0x00000010
+#define MACH_SEND_INTERRUPT  0x00000040  /* libmach implements */
+#define MACH_SEND_NOTIFY 0x00000080  /* arm send-possible notify */
+#define MACH_SEND_ALWAYS 0x00010000  /* internal use only */
+#define MACH_SEND_TRAILER  0x00020000  
+
+#define MACH_RCV_TIMEOUT 0x00000100
+#define MACH_RCV_NOTIFY    0x00000200  /* reserved - legacy */
+#define MACH_RCV_INTERRUPT 0x00000400  /* libmach implements */
+#define MACH_RCV_OVERWRITE 0x00001000
+
+#define MACH_MSG_USER  0x10000000
+
+#define MACH_MSGH_BITS_ZERO    0x00000000
+#define MACH_MSGH_BITS_REMOTE_MASK 0x000000ff
+#define MACH_MSGH_BITS_LOCAL_MASK  0x0000ff00
+#define MACH_MSGH_BITS_COMPLEX   0x80000000U
+#define MACH_MSGH_BITS_USER             0x8000ffffU
+
+#define  MACH_MSGH_BITS_CIRCULAR   0x40000000  /* internal use only */
+#define  MACH_MSGH_BITS_USED   0xc000ffffU
+
+#define  MACH_MSGH_BITS_PORTS_MASK       \
+   (MACH_MSGH_BITS_REMOTE_MASK|MACH_MSGH_BITS_LOCAL_MASK)
+
+#define MACH_MSGH_BITS(remote, local)        \
+   ((remote) | ((local) << 8))
+#define  MACH_MSGH_BITS_REMOTE(bits)       \
+   ((bits) & MACH_MSGH_BITS_REMOTE_MASK)
+#define  MACH_MSGH_BITS_LOCAL(bits)        \
+   (((bits) & MACH_MSGH_BITS_LOCAL_MASK) >> 8)
+#define  MACH_MSGH_BITS_PORTS(bits)        \
+   ((bits) & MACH_MSGH_BITS_PORTS_MASK)
+#define  MACH_MSGH_BITS_OTHER(bits)        \
+   ((bits) &~ MACH_MSGH_BITS_PORTS_MASK)
+
+typedef integer_t mach_msg_option_t;
+typedef unsigned int mach_msg_bits_t;
+typedef  natural_t mach_msg_size_t;
+typedef integer_t mach_msg_id_t;
+typedef natural_t mach_msg_timeout_t;
+typedef natural_t mach_port_right_t;
+typedef  natural_t   vm_offset_t;
+
+typedef  unsigned int mach_msg_trailer_type_t;
+typedef  unsigned int mach_msg_trailer_size_t;
+typedef natural_t mach_port_seqno_t;
+typedef vm_offset_t mach_port_context_t;
+
+typedef struct 
+{
+  mach_msg_trailer_type_t  msgh_trailer_type;
+  mach_msg_trailer_size_t  msgh_trailer_size;
+} mach_msg_trailer_t;
+
+typedef struct
+{
+  mach_msg_trailer_type_t       msgh_trailer_type;
+  mach_msg_trailer_size_t       msgh_trailer_size;
+  mach_port_seqno_t             msgh_seqno;
+} mach_msg_seqno_trailer_t;
+
+typedef struct
+{
+  unsigned int     val[2];
+} security_token_t;
+
+typedef struct 
+{
+  mach_msg_trailer_type_t  msgh_trailer_type;
+  mach_msg_trailer_size_t  msgh_trailer_size;
+  mach_port_seqno_t    msgh_seqno;
+  security_token_t   msgh_sender;
+} mach_msg_security_trailer_t;
+
+typedef struct
+{
+  unsigned int     val[8];
+} audit_token_t;
+
+typedef struct 
+{
+  mach_msg_trailer_type_t  msgh_trailer_type;
+  mach_msg_trailer_size_t  msgh_trailer_size;
+  mach_port_seqno_t    msgh_seqno;
+  security_token_t   msgh_sender;
+  audit_token_t      msgh_audit;
+} mach_msg_audit_trailer_t;
+
+typedef struct 
+{
+  mach_msg_trailer_type_t  msgh_trailer_type;
+  mach_msg_trailer_size_t  msgh_trailer_size;
+  mach_port_seqno_t    msgh_seqno;
+  security_token_t   msgh_sender;
+  audit_token_t      msgh_audit;
+  mach_port_context_t    msgh_context;
+} mach_msg_context_trailer_t; /* This is the biggest simple trailer */
+
+#define LARGEST_TRAILER_SIZE sizeof(mach_msg_context_trailer_t)
+
+typedef struct 
+{
+ mach_msg_bits_t msgh_bits;
+ mach_msg_size_t msgh_size;
+ mach_port_t   msgh_remote_port;
+ mach_port_t   msgh_local_port;
+ mach_msg_size_t msgh_reserved;
+ mach_msg_id_t msgh_id;
+} mach_msg_header_t;
+
+struct mach_msg_trap_data {
+ mach_msg_header_t* msg;
+ mach_msg_option_t option;
+ mach_msg_size_t send_size;
+ mach_msg_size_t receive_limit;
+ mach_port_t receive_name;
+ mach_msg_timeout_t timeout;
+ mach_port_t notify;
+};
+
+typedef struct 
+{
+ mach_msg_header_t head; /* just the header, for routing */
+ mach_msg_header_t* msg; /* pointer to the message in the sender's space */
+ task_port_t* sender; /* sender */
+ 
+ struct completion send_block; /* blocking the sender while the message is enqueued */
+
+ size_t size;
+ boolean_t received;
+} ipc_message;
+
+
+typedef int ipc_port_index;
+typedef struct mach_msg_trap_data mach_msg_trap_data_t;
+
+
+#endif
diff -Naur ./old//magenta/ke_array.c ./kern//magenta/ke_array.c
--- ./old//magenta/ke_array.c 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/ke_array.c  2012-07-13 09:16:09.000000000 -0400
@@ -0,0 +1,159 @@
+/*
+ * ke_array.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Kernel array.
+ */
+
+#include "ke_runtime.h"
+
+#define RefToImpl() ke_array_impl* impl = (ke_array_impl*)arr
+#define HaveUpdated() /**/
+#define RetainType(tt) /**/
+#define ReleaseType(tt) /**/
+
+ke_storage_type* __ke_array_get_base(ke_array_t arr)
+{
+ RefToImpl();
+
+ return impl->array;
+}
+
+bool ke_array_init(ke_array_t arr, unsigned int capacity)
+{
+ RefToImpl();
+ size_t size = sizeof(ke_storage_type) * capacity;
+
+ impl->array = ke_alloc(size);
+ if (!impl->array) {
+   return false;
+ }
+
+ impl->base.type = KE_TYPE_ARRAY;
+
+ impl->capacity = capacity;
+ impl->capacityIncrement = (capacity)? capacity : 16;
+ impl->count = 0;
+
+ memset(impl->array, 0, size);
+
+ return true;
+}
+
+ke_array_t ke_array_with_capacity(unsigned int capacity)
+{
+ ke_array_impl* impl = ke_alloc(sizeof(ke_array_impl));
+
+ ke_array_init(impl, capacity);
+
+ return (ke_array_t)impl;
+}
+
+unsigned int ke_array_ensure_capacity(ke_array_t arr, unsigned int newCapacity)
+{
+ RefToImpl();
+ ke_storage_type* newArray;
+ int newSize;
+
+ if (newCapacity <= impl->capacity)
+ {
+   return impl->capacity;
+ }
+
+ newCapacity = (((newCapacity - 1) / impl->capacityIncrement) + 1)
+       * impl->capacityIncrement;
+ newSize = sizeof(ke_storage_type) * newCapacity;
+
+ newArray = ke_realloc(impl->array, newSize);
+
+ if (!newArray) {
+   /* we're fucked */
+   ke_critical("ke_array_ensure_capacity(): reallocation failed!");
+ }
+ else {
+   /* success */
+   impl->capacity = newCapacity;
+   impl->array = newArray;
+ }
+
+ return impl->capacity;
+}
+
+ke_storage_type ke_array_get(ke_array_t arr, unsigned int index)
+{
+ RefToImpl();
+
+ if (index >= impl->count)
+ {
+   /* Out of bounds */
+   return (ke_storage_type)0;
+ }
+ else
+ {
+   /* In bounds, so return */
+   return (ke_storage_type)impl->array[index];
+ }
+}
+
+unsigned int ke_array_get_count(ke_array_t arr)
+{
+ RefToImpl();
+ return impl->count;
+}
+
+void ke_array_remove(ke_array_t arr, unsigned int index)
+{
+ RefToImpl();
+ ke_storage_type old_object;
+ unsigned int i;
+
+ if (index >= impl->count) {
+   return;
+ }
+
+ HaveUpdated();
+ old_object = impl->array[index];
+
+ impl->count--;
+
+ for (i = index; i < impl->count; i++) 
+ {
+   impl->array[i] = impl->array[i+1];
+ }
+
+ ReleaseType(old_object);
+}
+
+bool ke_array_set_at(ke_array_t arr, unsigned int index, ke_storage_type anObject)
+{
+ RefToImpl();
+
+ unsigned int i;
+ unsigned int newCount = impl->count + 1;
+
+ if ((index > impl->count) || !anObject)
+   return false;
+
+ /* do we need more space? */
+ if (newCount > impl->capacity && newCount > ke_array_ensure_capacity(arr, newCount))
+   return false;
+
+ HaveUpdated();
+
+ if (index != impl->count) {
+   for (i = impl->count; i > index; i--) {
+     impl->array[i] = impl->array[i-1];
+   }
+ }
+
+ impl->array[index] = anObject;
+ RetainType(anObject);
+ impl->count += 1;
+
+ return true;
+}
+
+bool ke_array_add(ke_array_t arr, ke_storage_type anObject)
+{
+ return ke_array_set_at(arr, ke_array_get_count(arr), anObject);
+}
diff -Naur ./old//magenta/kern_return.h ./kern//magenta/kern_return.h
--- ./old//magenta/kern_return.h  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/kern_return.h 2012-08-05 12:10:54.000000000 -0400
@@ -0,0 +1,400 @@
+/*
+ * Copyright (c) 2000 Apple Computer, Inc. All rights reserved.
+ *
+ * @APPLE_OSREFERENCE_LICENSE_HEADER_START@
+ * 
+ * This file contains Original Code and/or Modifications of Original Code
+ * as defined in and that are subject to the Apple Public Source License
+ * Version 2.0 (the 'License'). You may not use this file except in
+ * compliance with the License. The rights granted to you under the License
+ * may not be used to create, or enable the creation or redistribution of,
+ * unlawful or unlicensed copies of an Apple operating system, or to
+ * circumvent, violate, or enable the circumvention or violation of, any
+ * terms of an Apple operating system software license agreement.
+ * 
+ * Please obtain a copy of the License at
+ * http://www.opensource.apple.com/apsl/ and read it before using this file.
+ * 
+ * The Original Code and all software distributed under the License are
+ * distributed on an 'AS IS' basis, WITHOUT WARRANTY OF ANY KIND, EITHER
+ * EXPRESS OR IMPLIED, AND APPLE HEREBY DISCLAIMS ALL SUCH WARRANTIES,
+ * INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE, QUIET ENJOYMENT OR NON-INFRINGEMENT.
+ * Please see the License for the specific language governing rights and
+ * limitations under the License.
+ * 
+ * @APPLE_OSREFERENCE_LICENSE_HEADER_END@
+ */
+/*
+ * @OSF_COPYRIGHT@
+ */
+/* 
+ * Mach Operating System
+ * Copyright (c) 1991,1990,1989,1988,1987 Carnegie Mellon University
+ * All Rights Reserved.
+ * 
+ * Permission to use, copy, modify and distribute this software and its
+ * documentation is hereby granted, provided that both the copyright
+ * notice and this permission notice appear in all copies of the
+ * software, derivative works or modified versions, and any portions
+ * thereof, and that both notices appear in supporting documentation.
+ * 
+ * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"
+ * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND FOR
+ * ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
+ * 
+ * Carnegie Mellon requests users of this software to return to
+ * 
+ *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU
+ *  School of Computer Science
+ *  Carnegie Mellon University
+ *  Pittsburgh PA 15213-3890
+ * 
+ * any improvements or extensions that they make and grant Carnegie Mellon
+ * the rights to redistribute these changes.
+ */
+/*
+ */
+/*
+ * File: h/kern_return.h
+ * Author: Avadis Tevanian, Jr.
+ * Date: 1985
+ *
+ * Kernel return codes.
+ *
+ */
+
+#ifndef  _MACH_KERN_RETURN_H_
+#define _MACH_KERN_RETURN_H_
+
+
+#define KERN_SUCCESS     0
+
+#define KERN_INVALID_ADDRESS   1
+   /* Specified address is not currently valid.
+    */
+
+#define KERN_PROTECTION_FAILURE    2
+   /* Specified memory is valid, but does not permit the
+    * required forms of access.
+    */
+
+#define KERN_NO_SPACE      3
+   /* The address range specified is already in use, or
+    * no address range of the size specified could be
+    * found.
+    */
+
+#define KERN_INVALID_ARGUMENT    4
+   /* The function requested was not applicable to this
+    * type of argument, or an argument is invalid
+    */
+
+#define KERN_FAILURE     5
+   /* The function could not be performed.  A catch-all.
+    */
+
+#define KERN_RESOURCE_SHORTAGE   6
+   /* A system resource could not be allocated to fulfill
+    * this request.  This failure may not be permanent.
+    */
+
+#define KERN_NOT_RECEIVER    7
+   /* The task in question does not hold receive rights
+    * for the port argument.
+    */
+
+#define KERN_NO_ACCESS     8
+   /* Bogus access restriction.
+    */
+
+#define KERN_MEMORY_FAILURE    9
+   /* During a page fault, the target address refers to a
+    * memory object that has been destroyed.  This
+    * failure is permanent.
+    */
+
+#define KERN_MEMORY_ERROR    10
+   /* During a page fault, the memory object indicated
+    * that the data could not be returned.  This failure
+    * may be temporary; future attempts to access this
+    * same data may succeed, as defined by the memory
+    * object.
+    */
+
+#define  KERN_ALREADY_IN_SET   11
+   /* The receive right is already a member of the portset.
+    */
+
+#define KERN_NOT_IN_SET      12
+   /* The receive right is not a member of a port set.
+    */
+
+#define KERN_NAME_EXISTS   13
+   /* The name already denotes a right in the task.
+    */
+
+#define KERN_ABORTED     14
+   /* The operation was aborted.  Ipc code will
+    * catch this and reflect it as a message error.
+    */
+
+#define KERN_INVALID_NAME    15
+   /* The name doesn't denote a right in the task.
+    */
+
+#define  KERN_INVALID_TASK   16
+   /* Target task isn't an active task.
+    */
+
+#define KERN_INVALID_RIGHT   17
+   /* The name denotes a right, but not an appropriate right.
+    */
+
+#define KERN_INVALID_VALUE   18
+   /* A blatant range error.
+    */
+
+#define  KERN_UREFS_OVERFLOW   19
+   /* Operation would overflow limit on user-references.
+    */
+
+#define  KERN_INVALID_CAPABILITY   20
+   /* The supplied (port) capability is improper.
+    */
+
+#define KERN_RIGHT_EXISTS    21
+   /* The task already has send or receive rights
+    * for the port under another name.
+    */
+
+#define  KERN_INVALID_HOST   22
+   /* Target host isn't actually a host.
+    */
+
+#define KERN_MEMORY_PRESENT    23
+   /* An attempt was made to supply "precious" data
+    * for memory that is already present in a
+    * memory object.
+    */
+
+#define KERN_MEMORY_DATA_MOVED   24
+   /* A page was requested of a memory manager via
+    * memory_object_data_request for an object using
+    * a MEMORY_OBJECT_COPY_CALL strategy, with the
+    * VM_PROT_WANTS_COPY flag being used to specify
+    * that the page desired is for a copy of the
+    * object, and the memory manager has detected
+    * the page was pushed into a copy of the object
+    * while the kernel was walking the shadow chain
+    * from the copy to the object. This error code
+    * is delivered via memory_object_data_error
+    * and is handled by the kernel (it forces the
+    * kernel to restart the fault). It will not be
+    * seen by users.
+    */
+
+#define KERN_MEMORY_RESTART_COPY 25
+   /* A strategic copy was attempted of an object
+    * upon which a quicker copy is now possible.
+    * The caller should retry the copy using
+    * vm_object_copy_quickly. This error code
+    * is seen only by the kernel.
+    */
+
+#define KERN_INVALID_PROCESSOR_SET 26
+   /* An argument applied to assert processor set privilege
+    * was not a processor set control port.
+    */
+
+#define KERN_POLICY_LIMIT    27
+   /* The specified scheduling attributes exceed the thread's
+    * limits.
+    */
+
+#define KERN_INVALID_POLICY    28
+   /* The specified scheduling policy is not currently
+    * enabled for the processor set.
+    */
+
+#define KERN_INVALID_OBJECT    29
+   /* The external memory manager failed to initialize the
+    * memory object.
+    */
+
+#define KERN_ALREADY_WAITING   30
+   /* A thread is attempting to wait for an event for which 
+    * there is already a waiting thread.
+    */
+
+#define KERN_DEFAULT_SET   31
+   /* An attempt was made to destroy the default processor
+    * set.
+    */
+
+#define KERN_EXCEPTION_PROTECTED 32
+   /* An attempt was made to fetch an exception port that is
+    * protected, or to abort a thread while processing a
+    * protected exception.
+    */
+
+#define KERN_INVALID_LEDGER    33
+   /* A ledger was required but not supplied.
+    */
+
+#define KERN_INVALID_MEMORY_CONTROL  34
+   /* The port was not a memory cache control port.
+    */
+
+#define KERN_INVALID_SECURITY    35
+   /* An argument supplied to assert security privilege  
+    * was not a host security port.
+    */
+   
+#define KERN_NOT_DEPRESSED   36
+   /* thread_depress_abort was called on a thread which
+    * was not currently depressed.
+    */
+   
+#define KERN_TERMINATED      37
+   /* Object has been terminated and is no longer available
+    */
+
+#define KERN_LOCK_SET_DESTROYED    38
+   /* Lock set has been destroyed and is no longer available.
+    */
+
+#define KERN_LOCK_UNSTABLE   39
+   /* The thread holding the lock terminated before releasing
+    * the lock
+    */
+
+#define KERN_LOCK_OWNED      40
+   /* The lock is already owned by another thread
+    */
+
+#define KERN_LOCK_OWNED_SELF   41
+   /* The lock is already owned by the calling thread
+    */
+
+#define KERN_SEMAPHORE_DESTROYED 42
+   /* Semaphore has been destroyed and is no longer available.
+    */
+
+#define KERN_RPC_SERVER_TERMINATED 43
+   /* Return from RPC indicating the target server was 
+    * terminated before it successfully replied 
+    */
+
+#define KERN_RPC_TERMINATE_ORPHAN  44
+   /* Terminate an orphaned activation.
+    */
+
+#define KERN_RPC_CONTINUE_ORPHAN 45
+   /* Allow an orphaned activation to continue executing.
+    */
+
+#define  KERN_NOT_SUPPORTED    46
+   /* Empty thread activation (No thread linked to it)
+    */
+
+#define  KERN_NODE_DOWN      47
+   /* Remote node down or inaccessible.
+    */
+
+#define KERN_NOT_WAITING   48
+   /* A signalled thread was not actually waiting. */
+
+#define  KERN_OPERATION_TIMED_OUT        49
+   /* Some thread-oriented operation (semaphore_wait) timed out
+    */
+
+#define KERN_CODESIGN_ERROR    50
+   /* During a page fault, indicates that the page was rejected
+    * as a result of a signature check.
+    */
+
+#define  KERN_RETURN_MAX     0x100
+   /* Maximum return value allowable
+    */
+
+#define MACH_MSG_SUCCESS   0x00000000
+
+
+#define  MACH_MSG_MASK     0x00003e00
+   /* All special error code bits defined below. */
+#define  MACH_MSG_IPC_SPACE    0x00002000
+   /* No room in IPC name space for another capability name. */
+#define  MACH_MSG_VM_SPACE   0x00001000
+   /* No room in VM address space for out-of-line memory. */
+#define  MACH_MSG_IPC_KERNEL   0x00000800
+   /* Kernel resource shortage handling an IPC capability. */
+#define  MACH_MSG_VM_KERNEL    0x00000400
+   /* Kernel resource shortage handling out-of-line memory. */
+
+#define MACH_SEND_IN_PROGRESS    0x10000001
+   /* Thread is waiting to send.  (Internal use only.) */
+#define MACH_SEND_INVALID_DATA   0x10000002
+   /* Bogus in-line data. */
+#define MACH_SEND_INVALID_DEST   0x10000003
+   /* Bogus destination port. */
+#define MACH_SEND_TIMED_OUT    0x10000004
+   /* Message not sent before timeout expired. */
+#define MACH_SEND_INTERRUPTED    0x10000007
+   /* Software interrupt. */
+#define MACH_SEND_MSG_TOO_SMALL    0x10000008
+   /* Data doesn't contain a complete message. */
+#define MACH_SEND_INVALID_REPLY    0x10000009
+   /* Bogus reply port. */
+#define MACH_SEND_INVALID_RIGHT    0x1000000a
+   /* Bogus port rights in the message body. */
+#define MACH_SEND_INVALID_NOTIFY 0x1000000b
+   /* Bogus notify port argument. */
+#define MACH_SEND_INVALID_MEMORY 0x1000000c
+   /* Invalid out-of-line memory pointer. */
+#define MACH_SEND_NO_BUFFER    0x1000000d
+   /* No message buffer is available. */
+#define MACH_SEND_TOO_LARGE    0x1000000e
+   /* Send is too large for port */
+#define MACH_SEND_INVALID_TYPE   0x1000000f
+   /* Invalid msg-type specification. */
+#define MACH_SEND_INVALID_HEADER 0x10000010
+   /* A field in the header had a bad value. */
+#define MACH_SEND_INVALID_TRAILER  0x10000011
+   /* The trailer to be sent does not match kernel format. */
+#define MACH_SEND_INVALID_RT_OOL_SIZE  0x10000015
+   /* compatibility: no longer a returned error */
+
+#define MACH_RCV_IN_PROGRESS   0x10004001
+   /* Thread is waiting for receive.  (Internal use only.) */
+#define MACH_RCV_INVALID_NAME    0x10004002
+   /* Bogus name for receive port/port-set. */
+#define MACH_RCV_TIMED_OUT   0x10004003
+   /* Didn't get a message within the timeout value. */
+#define MACH_RCV_TOO_LARGE   0x10004004
+   /* Message buffer is not large enough for inline data. */
+#define MACH_RCV_INTERRUPTED   0x10004005
+   /* Software interrupt. */
+#define MACH_RCV_PORT_CHANGED    0x10004006
+   /* compatibility: no longer a returned error */
+#define MACH_RCV_INVALID_NOTIFY    0x10004007
+   /* Bogus notify port argument. */
+#define MACH_RCV_INVALID_DATA    0x10004008
+   /* Bogus message buffer for inline data. */
+#define MACH_RCV_PORT_DIED   0x10004009
+   /* Port/set was sent away/died during receive. */
+#define  MACH_RCV_IN_SET     0x1000400a
+   /* compatibility: no longer a returned error */
+#define  MACH_RCV_HEADER_ERROR   0x1000400b
+   /* Error receiving message header.  See special bits. */
+#define  MACH_RCV_BODY_ERROR   0x1000400c
+   /* Error receiving message body.  See special bits. */
+#define  MACH_RCV_INVALID_TYPE   0x1000400d
+   /* Invalid msg-type specification in scatter list. */
+#define  MACH_RCV_SCATTER_SMALL    0x1000400e
+   /* Out-of-line overwrite region is not large enough */
+#define MACH_RCV_INVALID_TRAILER 0x1000400f
+   /* trailer type or number of trailer elements not supported */
+#define MACH_RCV_IN_PROGRESS_TIMED      0x10004011
+
+#endif /* _MACH_KERN_RETURN_H_ */
diff -Naur ./old//magenta/ke_runtime.c ./kern//magenta/ke_runtime.c
--- ./old//magenta/ke_runtime.c 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/ke_runtime.c  2012-08-06 10:27:43.000000000 -0400
@@ -0,0 +1,164 @@
+/*
+ * ke_runtime.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Kernel runtime support.
+ */
+
+#include "ke_runtime.h"
+#include <linux/module.h>
+#include <linux/sched.h>
+#include <linux/binfmts.h>
+#include <linux/signal.h>
+
+#include "mach_port_types.h"
+
+/* External initializers */
+extern int init_mach_ipc(void);
+extern int init_macho_binfmt(void);
+static bool _ke_initialized = false;
+extern void __ke_memtest(void);
+extern void mach_host_init(void);
+extern void mach_thread_bootstrap(struct task_struct* task);
+
+void* ke_alloc(size_t size)
+{
+ return kmalloc(size, GFP_KERNEL);
+}
+
+void ke_free(void* ptr)
+{
+ kfree(ptr);
+}
+
+void ke_will_signal(struct task_struct *t, int sig)
+{
+ return;
+}
+
+void* ke_realloc(void* ptr, size_t size)
+{
+ return krealloc(ptr, size, GFP_KERNEL);
+}
+
+/*
+ * Called when the darwin system call number is invalid.
+ */
+void ke_darwin_syscall_error(int c)
+{
+ panic("ke_darwin_syscall_error(): invalid trap #: %d", c);
+}
+
+void ke_at_fork(struct task_struct *task, struct task_struct *parent, unsigned long clone_flags)
+{
+ boolean_t need_ref = false;
+
+ if (!_ke_initialized) {
+   return;
+ }
+
+ if (task->mm && !(clone_flags & CLONE_THREAD))
+ {
+   /* 
+    * Only userspace tasks need new task ports.
+    * Kernel tasks don't need them. Clone threads inherit
+    * them from parents.
+    */
+   
+   Xlog("creating task port for task[%p]", task);
+   Native_setup_task(task);
+ }
+ else
+ {
+   need_ref = true;
+ }
+
+ if (task->mm)
+ {
+   /*
+    * Every single user scheduler entry must have a thread
+    * port attached to it.
+    */
+
+   task->thread_port = NULL;
+
+   /* This should increase the refcount ... */
+   mach_thread_bootstrap(task);
+
+   if (!need_ref)
+   {
+     /* ... so decrease it. */
+     PortRelease(task->task_port);
+
+     /* And do a sanity check */
+     BUG_ON(PortGetRefcount(task->task_port) != 1);
+   }
+ }
+}
+
+/**/
+void ke_setup_exec(struct linux_binprm* bprm)
+{
+ if (!_ke_initialized) {
+   return;
+ }
+
+ if (current->pid == 1)
+ {
+   /*
+    * Task 1 doesn't have a mm in at_fork, so do
+    * port init in the execve hook instead.
+    */
+
+   if (current->task_port) {
+     panic("ke_setup_exec(): pid 1 has a task port already");
+   }
+
+   Xlog("creating task & thread ports for pid 1");
+   Native_setup_task(current);
+   mach_thread_bootstrap(current);
+
+   __ke_memtest();
+ }
+}
+
+void ke_process_exit(struct task_struct *tsk)
+{
+ task_port_t* tp;
+ int refcount;
+
+ if (!_ke_initialized) {
+   return;
+ }
+
+ /*
+  * Only do it if the task has a task port.
+  * Otherwise it's a kthread.
+  */
+ if (tsk->task_port)
+ {
+   tp = Native_get_task(tsk);
+
+   /* Thread is now dead, decrease the refcount */
+   mach_task_dec_thread_count(tp);
+
+   refcount = PortGetRefcount(tp) - 1; /* ignore the current ref */
+   
+   Xlog("exit, task port has %d references", refcount);
+
+   PortRelease(tp);
+ }
+}
+
+int __init __ke_runtime_init(void)
+{
+ init_mach_ipc();
+ init_macho_binfmt();
+ mach_host_init();
+ 
+ _ke_initialized = true;
+
+ Xlog("runtime started, size_t: %d", sizeof(size_t));
+ return 0;
+}
+
diff -Naur ./old//magenta/ke_runtime.h ./kern//magenta/ke_runtime.h
--- ./old//magenta/ke_runtime.h 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/ke_runtime.h  2012-08-06 10:15:12.000000000 -0400
@@ -0,0 +1,78 @@
+/*
+ * ke_runtime.h
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Kernel runtime support.
+ */
+
+#ifndef _H_MG_KE_RUNTIME_
+#define _H_MG_KE_RUNTIME_
+
+#include "libkern.h"
+
+#include <linux/kernel.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+
+#include <DarwinTypes.h>
+#include <MachO.h>
+
+#define KE_TYPE_UNKNOWN 0
+#define KE_TYPE_ARRAY 1
+
+/**/
+#define ke_storage_type void*
+#define Boolean int
+
+typedef struct {
+ uint16_t type;
+} ke_type_impl;
+
+typedef struct {
+ ke_type_impl base;
+
+ unsigned int count;
+ unsigned int capacity;
+ unsigned int capacityIncrement;
+
+ ke_storage_type* array;
+} ke_array_impl;
+
+typedef void* ke_type_t;
+typedef ke_type_t ke_array_t;
+
+/* Memory */
+void* ke_alloc(size_t size);
+void ke_free(void* ptr);
+void* ke_realloc(void* ptr, size_t size);
+
+/* Array */
+ke_array_t ke_array_with_capacity(unsigned int capacity);
+bool ke_array_init(ke_array_t arr, unsigned int capacity);
+ke_storage_type ke_array_get(ke_array_t arr, unsigned int index);
+bool ke_array_set_at(ke_array_t arr, unsigned int index, ke_storage_type anObject);
+unsigned int ke_array_get_count(ke_array_t arr);
+bool ke_array_add(ke_array_t arr, ke_storage_type anObject);
+ke_storage_type* __ke_array_get_base(ke_array_t arr);
+
+int ke_log(const char *fmt, ...);
+int ke_warn(const char *fmt, ...);
+
+int OSLog(const char *fmt, ...);
+int OSLogFn(const char *fn, const char *fmt, ...);
+int OSWarnFn(const char *fn, const char *fmt, ...);
+
+#define XLog(...) OSLogFn(__FUNCTION__, __VA_ARGS__)
+#define XWarn(...) OSWarnFn(__FUNCTION__, __VA_ARGS__)
+
+/* gah easier to type */
+#define Xlog(...) OSLogFn(__FUNCTION__, __VA_ARGS__)
+#define Xwarn(...) OSWarnFn(__FUNCTION__, __VA_ARGS__)
+
+
+/* Port */
+void Native_setup_task(struct task_struct* task);
+
+#define ke_critical panic
+
+#endif
diff -Naur ./old//magenta/kext.c ./kern//magenta/kext.c
--- ./old//magenta/kext.c 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/kext.c  2012-08-08 10:24:18.000000000 -0400
@@ -0,0 +1,745 @@
+/*
+ * kext.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * What is this, I don't even ...
+ */
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+#include <linux/module.h>
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+#include "ke_runtime.h"
+#include "loader.h"
+
+typedef struct kernel_symbol ksym_t;
+
+/*
+ * Symbols in the main image's symbtab.
+ */
+extern const ksym_t __start___ksymtab[];
+extern const ksym_t __stop___ksymtab[];
+extern const ksym_t __start___ksymtab_gpl[];
+extern const ksym_t __stop___ksymtab_gpl[];
+extern const ksym_t __start___ksymtab_gpl_future[];
+extern const ksym_t __stop___ksymtab_gpl_future[];
+
+static Boolean _verbose_log = false;
+
+#define doIfVerbose() if (_verbose_log)
+
+typedef struct __KXFile {
+ unsigned char *fMachO;
+ struct symtab_command *fSymtab;
+ 
+ uintptr_t fSegmentOffset;
+ char *fStringBase;
+ struct nlist *fSymbolBase;
+ const struct nlist *fLocalSyms;
+ int fStringSectionOrdinal;
+
+ unsigned char* fSegmentBase;
+
+ int fConstructorSize;
+ void* fConstructorBase;
+} KXFile;
+
+void *kmalloc_non_inline(size_t size, gfp_t flags)
+{
+ return kmalloc(size, flags);
+}
+EXPORT_SYMBOL(kmalloc_non_inline);
+
+const ksym_t*
+find_kernel_symbol_in(const char* name, const ksym_t* start, const ksym_t* end)
+{
+ const ksym_t* sym = start;
+
+ while (1) {
+   if (strcmp(sym->name, name) == 0) {
+     /* Found */
+     return sym;
+   }
+
+   sym++;
+
+   if (sym > end) {
+     break;
+   }
+ }
+
+ return FALSE;
+}
+
+ksym_t*
+find_kernel_symbol(const char* name)
+{
+ const ksym_t* sym = NULL;
+
+ if (!sym) {
+   sym = find_kernel_symbol_in(name, __start___ksymtab, __stop___ksymtab);
+ }
+
+ return (ksym_t*)sym;
+}
+
+void*
+kld_alloc(size_t sz)
+{
+ return ke_alloc(sz);
+}
+
+static const struct nlist *
+kld_find_symbol_by_name(KXFile *file, const char* name)
+{
+ /*
+  This is slow, but I don't care.
+  */
+ 
+ const struct nlist *sym;
+ int nsyms;
+ 
+ nsyms = file->fSymtab->nsyms;
+ sym = file->fSymbolBase;
+ 
+ while (nsyms--) {
+   /*
+    if ((sym->n_type & N_EXT))
+    return NULL;
+    */
+   
+   long strx = sym->n_un.n_strx;
+   const char *symname = file->fStringBase + strx;
+   
+   if (strcmp(name, symname) == 0 && !(sym->n_type & N_STAB))
+     return sym;
+   
+   sym += 1;
+ }
+ 
+ return NULL;
+}
+
+static const struct nlist *
+kld_find_symbol_by_address(KXFile *file, void *entry)
+{
+ /*
+   This is slow, but I don't care.
+  */
+ 
+ const struct nlist *sym;
+ int nsyms;
+ 
+ nsyms = file->fSymtab->nsyms;
+ sym = file->fSymbolBase;
+ 
+ while (nsyms--) {
+   uint32_t addr = (uint32_t)entry;
+   /*
+   if ((sym->n_type & N_EXT))
+     return NULL;
+   */
+   
+   if (sym->n_desc & N_ARM_THUMB_DEF) {
+     addr = addr & ~1;
+   }
+
+   if (sym->n_value == addr && !(sym->n_type & N_STAB)) {
+     return sym;
+   }
+   
+   sym += 1;
+ }
+
+ return NULL;
+}
+
+Boolean kld_relocate_section(KXFile* file , struct section* sect, vm_offset_t delta)
+{
+ uint8_t* sbase;
+ uint32_t nreloc;
+ struct relocation_info *rinfo;
+ 
+ sbase = (uint8_t*)sect->addr;
+ nreloc = sect->nreloc;
+ rinfo = (struct relocation_info *)(file->fMachO + sect->reloff);
+ 
+ while (nreloc--) {
+   void** entry;
+   void** abs_entry;
+   unsigned long r_symbolnum, r_length;
+   const struct nlist *symbol = NULL;
+   enum reloc_type_generic r_type;
+   void *addr = NULL;
+   
+   /* Ignore scattered relocations */
+   if ((rinfo->r_address & R_SCATTERED))
+   {
+     continue;
+   }
+   
+   /* This is why we can't have nice things */
+   entry = (void**)( (uintptr_t)rinfo->r_address + (uintptr_t)sbase );
+   abs_entry = ((void**)( (uintptr_t)file->fSegmentBase + (uintptr_t)entry ));
+   
+   r_type = (enum reloc_type_generic)rinfo->r_type;
+   r_length = rinfo->r_length;
+   
+   /*
+    * In r_length, 2 stands for long.
+    */
+   if (r_type != GENERIC_RELOC_VANILLA || r_length != 2)
+   {
+     continue;
+   }
+   
+   r_symbolnum = rinfo->r_symbolnum;
+
+   if (rinfo->r_extern) {
+     /* External symbol entry */
+     long strx;
+     const char *symname;
+     ksym_t* ks; 
+
+     if(r_symbolnum >= file->fSymtab->nsyms)
+     {
+       Xlog("invalid reloc entry");
+       return false;
+     }
+     
+     symbol = file->fSymbolBase;
+     
+     if ((symbol[r_symbolnum].n_type & N_TYPE) == N_INDR) {
+       /*
+         This is an indirect symbol, so get the value
+         for the actual thing.
+        */
+       r_symbolnum = symbol[r_symbolnum].n_value;
+     }
+     
+     symbol = &symbol[r_symbolnum];
+     
+     if (symbol->n_type != (N_EXT | N_UNDF)) {
+       Xwarn("invalid reloc symbol type - !(N_EXT | N_UNDF)");
+       return false;
+     }
+
+     strx = symbol->n_un.n_strx;
+     symname = file->fStringBase + strx;
+     
+     if (symname[0] == '_') {
+       symname++;
+     }
+     else {
+       Xwarn("'%s' doesn't start with '_'", symname);
+       return false;
+     }
+
+     ks = find_kernel_symbol(symname);
+     if (!ks) {
+       Xwarn("failed to resolve '%s'", symname);
+       return false;
+     }
+
+     doIfVerbose() {
+       Xlog("\tBind    : sym_addr=%p, r_addr= %p, l_addr= %p, nm= '%s', ks= %p",
+         (void*)symbol,
+         (void*)rinfo->r_address,
+         (void*)addr,
+         symname,
+         (void*)ks);
+     } 
+
+     *abs_entry = (void*)(ks->value);
+   }
+   else {
+     /*
+      * Relocate a local symbol. Local symbols in object files
+      * are not attached to each other which means that all jumps
+      * have to be fixed up.
+      */
+
+     /* Derp */
+     if (r_symbolnum == R_ABS)
+     {
+       rinfo++;
+       continue;
+     }
+     
+     /* Not this pointer crap again */
+     addr = *abs_entry;
+
+     if (r_symbolnum == file->fStringSectionOrdinal)
+     {
+       /*
+        * This is a string section
+        * Here we just need to slide the pointers relative to
+        * the load address of the segment.
+        */
+
+       doIfVerbose() {
+         Xlog("\tRelocate: (cstr) l_addr: %p, val: %p",
+           (void*)symbol,
+           (void*)addr);
+       }
+
+       *abs_entry = ((void*)( (uintptr_t)file->fSegmentBase + (uintptr_t)addr) );
+
+       rinfo++;
+       continue;
+     }
+
+     symbol = kld_find_symbol_by_address(file, addr);
+     
+     if (symbol) {
+       uint32_t val = symbol->n_value;
+
+       if (symbol->n_desc & N_ARM_THUMB_DEF) {
+         val |= 1;
+       }
+
+       /* reloc "(uintptr_t)sbase +" */
+       *abs_entry = ((void*)( (uintptr_t)file->fSegmentBase +  (uintptr_t)val ));
+
+       doIfVerbose() {
+         Xlog("\tRelocate: sym_record= %p, sect_base= %p, sym_value= %p, relocated_to= %p",
+           (void*)symbol,
+           (void*)sect->offset,
+           (void*)val,
+           (void*)*abs_entry);
+       }
+     }
+     else {
+
+       doIfVerbose() {
+         Xwarn("can't find symbol at %p (ord: %d)",
+           (void*)addr,
+           (int)r_symbolnum);
+       }
+
+       return false;
+     }
+   }
+
+   rinfo++;
+ }
+ 
+ return true;
+}
+
+Boolean kld_transfer(KXFile* file, void* src, void* dest, size_t sz)
+{
+ void* in_src = (void*)((uintptr_t)file->fMachO + (uintptr_t)src);
+ bcopy(in_src, dest, sz);
+
+ return true;
+}
+
+Boolean kld_parse_symtab(KXFile* file)
+{
+ const struct nlist *sym;
+ unsigned int i, firstlocal = 0, nsyms;
+ const char *strbase;
+ unsigned int strsize;
+ unsigned int symsize;
+
+ nsyms = file->fSymtab->nsyms;
+ symsize = nsyms * sizeof(struct nlist);
+ 
+ /* load the symbols */
+ sym = (const struct nlist *)kld_alloc(symsize);
+ kld_transfer(file, (void*)file->fSymtab->symoff, (void*)sym, symsize);
+ file->fSymbolBase = sym;
+
+ /* load the string table */
+ strsize = file->fSymtab->strsize;
+ strbase = kld_alloc(strsize);
+ kld_transfer(file, (void*)file->fSymtab->stroff, strbase, strsize);
+ file->fStringBase = strbase;
+
+ i = 0;
+
+ while (i < nsyms) {
+   long strx = sym->n_un.n_strx;
+   const char *symname = strbase + strx;
+   unsigned char n_type = sym->n_type & N_TYPE;
+   
+   doIfVerbose() {
+     Xlog("type=%d, val=%p, name='%s'",
+          n_type,
+          (void*)sym->n_value,
+          symname);
+   }
+
+   n_type = sym->n_type & (N_TYPE | N_EXT);
+   
+   /*
+    * First exported symbol 
+    * This is done for the sake of performance
+    */
+   if ( !firstlocal && (n_type & N_EXT) ) {
+     firstlocal = i;
+     file->fLocalSyms = sym;
+   }
+   
+   /* Increment stuff */
+   i += 1;
+   sym += 1;
+ }
+ 
+ if (!file->fLocalSyms) {
+   Xlog("no symbols found");
+   return false;
+ }
+ 
+ doIfVerbose() {
+   Xlog("{loc=%p}",
+       file->fLocalSyms);
+ }
+
+ return true;
+}
+
+Boolean kld_map_sect(KXFile* file, struct section* sect)
+{
+ uintptr_t sect_mem_addr = 
+ ((uintptr_t)( (uintptr_t)file->fSegmentBase + (uintptr_t)sect->addr ));
+
+ doIfVerbose() {
+   Xlog("addr: %p, name: '%s', type: %d, size: %d\n",
+          (void*)sect->addr,
+          sect->sectname,
+          (int)(sect->flags & SECTION_TYPE),
+          (int)sect->size);
+ }
+
+ if ((sect->flags & SECTION_TYPE) == S_ZEROFILL)
+ {
+   memset((void*)sect_mem_addr, 0, sect->size);
+ }
+ else {
+   kld_transfer(file, (void*)sect->offset, (void*)sect_mem_addr, sect->size);
+ }
+
+ if (strcmp("__constructor", sect->sectname) == 0)
+ {
+   /* global constructors */
+   file->fConstructorBase = (void*)sect_mem_addr;
+   file->fConstructorSize = sect->size;
+ }
+
+ return true;
+}
+
+Boolean kld_process_segment(KXFile* file, struct segment_command* seg) 
+{
+ struct section* sect = NULL;
+ uint32_t nsects = seg->nsects;
+ uint32_t total_size = 0;
+ int i = 0;
+
+#define iterate_sections()  \
+ sect = (struct section*)((uintptr_t)seg + sizeof(struct segment_command)); \
+ for (i = 0; i < nsects; i++, sect++) \
+
+ /* calculate total size */
+ iterate_sections()
+ {
+   total_size += sect->size;
+ }
+
+ file->fSegmentBase = kld_alloc(total_size);
+
+ Xwarn("kext mapping region: %p - %p", file->fSegmentBase, file->fSegmentBase + total_size);
+
+ /* map sections */
+ iterate_sections()
+ {
+   kld_map_sect(file, sect);
+   
+   if ((sect->flags & SECTION_TYPE) == S_CSTRING_LITERALS)
+   {
+     file->fStringSectionOrdinal = i+1;
+   }
+ }
+
+ /* perform relocation */
+ iterate_sections() 
+ {
+   if (!kld_relocate_section(file, sect, 0))
+   {
+     return false;
+   }
+ }
+ 
+ return true;
+}
+
+Boolean kld_file_map(void* buffer, long size, KXFile* file)
+{
+ size_t macho_header_sz = sizeof(struct mach_header);
+ uint8_t* load_commands;
+ struct mach_header* head;
+ 
+ /* command parser */
+ boolean_t has_segment = FALSE;
+ size_t offset;
+ size_t oldoffset;
+ uint32_t ncmds;
+ 
+ /* segment */
+ struct segment_command *seg_hdr;
+ uintptr_t sect_offset = 0;
+ uint32_t nsects = 0;
+
+ bzero(file, sizeof(file));
+
+ head = buffer;
+ load_commands = buffer + macho_header_sz;
+ 
+ /* sanity */
+ if (head->magic != MH_MAGIC)
+ {
+   Xwarn("kld_file_map: not a valid mach-o (invalid magic %p)",
+     (void*)head->magic);
+
+   return false;
+ }
+
+ /* we can only load object files */
+ if (head->filetype != MH_OBJECT)
+ {
+   Xwarn("kld_file_map: wrong mach-o type (invalid filetype %p)",
+     (void*)head->filetype);
+
+   return false;
+ }
+
+ offset = 0;
+ ncmds = head->ncmds;
+ 
+ file->fMachO = buffer;
+ 
+ doIfVerbose() {
+   Xlog("macho {fl=%d}", head->flags);
+ }
+
+ while (ncmds--) {
+   struct load_command *lcp = 
+   (struct load_command *)(load_commands + offset);
+   
+   oldoffset = offset;
+   offset += lcp->cmdsize;
+   
+   if (oldoffset > offset ||
+       lcp->cmdsize < sizeof(struct load_command) ||
+       offset > head->sizeofcmds + macho_header_sz)
+   {
+     Xlog("malformed load command");
+     return false;
+   }
+   
+   /*
+     Mach objects (MH_OBJECT) are only meant to have one segment that has all the bits.
+    */
+   switch(lcp->cmd) {
+     case LC_SEGMENT:
+     {
+       if (has_segment) {
+         Xwarn("more than one segment in the file");
+         return false;
+       }
+       
+       seg_hdr = (struct segment_command *)lcp;
+       
+       nsects = seg_hdr->nsects;
+       sect_offset = (uintptr_t)(seg_hdr + sizeof(struct segment_command));
+       
+       file->fSegmentOffset = seg_hdr->fileoff;
+       
+       doIfVerbose() {
+         Xlog("LC_SEGMENT {nsects=%d}",
+              seg_hdr->nsects);
+       }
+       
+       has_segment = TRUE;
+       
+       break;
+     }
+     case LC_UUID:
+     case LC_DYSYMTAB:
+     {
+       /* Do. Not. Care. */
+       break;
+     }
+     case LC_SYMTAB:
+     {
+       file->fSymtab = (struct symtab_command*)lcp;
+       break;
+     }
+     default:
+     {
+       Xwarn("unsupported load command %d",
+           lcp->cmd);
+       
+       return false;
+       break;
+     }
+   }
+ }
+ 
+ if (!file->fSymtab) {
+   Xwarn("object file missing symbols");
+   return false;
+ }
+ else {
+   kld_parse_symtab(file);
+ }
+ 
+ if (!has_segment) {
+   Xwarn("object file missing segment");
+   return false;
+ }
+ else {
+   if (!kld_process_segment(file, seg_hdr))
+   {
+     return false;
+   }
+ }
+ 
+ return true;
+}
+
+/*
+ * Gets absoulute function address that we can branch to.
+ * Sets the thumb bit if needed.
+ */
+void* kld_get_symbol_entry(KXFile* file, const struct nlist* nl)
+{
+ uintptr_t val;
+ uint16_t* addr;
+
+ /* sanity */
+ BUG_ON(file == NULL);
+ BUG_ON(nl == NULL);
+
+ val = nl->n_value;
+ addr = (uint16_t*)((val + (uintptr_t)file->fSegmentBase));
+ 
+ if (nl->n_desc & N_ARM_THUMB_DEF) {
+   addr = (uint16_t*)((unsigned int)addr | 1);
+ }
+
+ return (void*)addr;
+}
+
+void abi_test(int aa, long long aaa)
+{
+ ke_log("ABI_TEST: int: %d, long: %lld\n", aa, aaa);
+}
+EXPORT_SYMBOL(abi_test);
+
+int _user_load_kext(void* buffer, size_t size)
+{
+ /* 
+  *  mach_msg_header_t head;
+  *  void* buffer;
+  *  unsigned int buffer_len;
+  */
+
+ Boolean ret;
+ void* buf;
+
+ const struct nlist* nl;
+ KXFile file;
+
+ buf = kld_alloc(size);
+
+ if (copy_from_user(buf, buffer, size))
+ {
+   Xwarn("unable to copy out buffer!");
+   return KERN_FAILURE;
+ }
+ 
+ if (kld_file_map(buf, size, &file))
+ {
+   uintptr_t val;
+   uint16_t* addr;
+   int (*kmod_init)(void);
+   void (*static_cxx_constructor)(void);
+   void** ctor_base = NULL;
+   int kret = 0;
+   int ctor_iter = 0;
+
+   nl = kld_find_symbol_by_name(&file, "_kmod_start");
+   
+   if (nl == NULL) {
+     Xwarn("symbol not found");
+     return KERN_FAILURE;
+   }
+
+   /* call constructors */
+   ctor_base = file.fConstructorBase;
+   if (ctor_base != NULL)
+   {
+     for (ctor_iter = 0; ctor_iter < file.fConstructorSize; ctor_iter += 4)
+     {
+       const struct nlist* ctor_nl;
+       void* rel_sym_addr;
+       static_cxx_constructor = *ctor_base;
+
+       rel_sym_addr = ((void*)((uintptr_t)static_cxx_constructor - (uintptr_t)file.fSegmentBase));
+
+       ctor_nl = kld_find_symbol_by_address(&file, rel_sym_addr);
+       static_cxx_constructor = kld_get_symbol_entry(&file, ctor_nl);
+
+       Xlog("call_cxx_ctor: %p (nlist: %p) %d/%d!", static_cxx_constructor, ctor_nl, ctor_iter, file.fConstructorSize);
+
+       static_cxx_constructor();
+
+       ctor_base++;
+     }
+   }
+
+   kmod_init = kld_get_symbol_entry(&file, nl);
+     
+   /* Branch into the unknown */
+   kret = kmod_init();
+
+   Xlog("kmod returned %d", kret);
+
+   return KERN_SUCCESS;
+ }
+ else
+ {
+   Xwarn("failed to load object!");
+   return KERN_FAILURE;
+ }
+}
diff -Naur ./old//magenta/libkern.c ./kern//magenta/libkern.c
--- ./old//magenta/libkern.c  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/libkern.c 2012-08-04 17:47:18.000000000 -0400
@@ -0,0 +1,126 @@
+/*
+ * libkern.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Bits no one cares about.
+ */
+
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+#include <linux/sched.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+#include <asm/thread_notify.h>
+
+#include "ke_runtime.h"
+#include "ipc_types.h"
+
+extern bool OSAtomicCompareAndSwap32( u_int32_t __oldValue, u_int32_t __newValue, volatile u_int32_t *__theValue );
+EXPORT_SYMBOL(OSAtomicCompareAndSwap32);
+
+void* kalloc(size_t size)
+{
+ void* ret = kmalloc(size, GFP_KERNEL);
+ return ret;
+}
+EXPORT_SYMBOL(kalloc);
+
+/* void *memcpy(void *dest, const void *src, size_t n); */
+void bcopy(const void *src, void *dest, size_t n)
+{
+ memmove(dest, src, n);
+}
+EXPORT_SYMBOL(bcopy);
+
+void bzero(void* base, size_t size)
+{
+ memset(base, 0, size);
+}
+EXPORT_SYMBOL(bzero);
+
+/* hax */
+void _Z5kfreePvm(void* addr, unsigned long size)
+{
+ kfree(addr);
+}
+EXPORT_SYMBOL(_Z5kfreePvm);
+
+/* pure virtual function can't ever be called */
+void __cxa_pure_virtual( void )    { panic("%s", __FUNCTION__); }
+void __pure_virtual( void )        { panic("%s", __FUNCTION__); }
+
+EXPORT_SYMBOL(__cxa_pure_virtual);
+EXPORT_SYMBOL(__pure_virtual);
+
+/* operator delete(void *) */
+void _ZdlPv(void* ptr)
+{  
+ kfree(ptr);
+}
+EXPORT_SYMBOL(_ZdlPv);
+
+/* operator delete[](void *) */
+void _ZdaPv(void* ptr)
+{  
+ kfree(ptr);
+}
+EXPORT_SYMBOL(_ZdaPv);
+
+/* operator new[](unsigned long) */
+void* _Znam(unsigned long size)
+{
+ void* ret;
+
+ ret = kalloc(size);
+
+ if (!ret) {
+   panic("new(): c++ allocation failed!");
+ }
+
+ bzero(ret, size);
+
+ return ret;
+}
+EXPORT_SYMBOL(_Znam);
+
+/* operator new(unsigned long) */
+void* _Znwm(unsigned long size)
+{
+ void* ret;
+
+ ret = kalloc(size);
+
+ if (!ret) {
+   panic("new(): c++ allocation failed!");
+ }
+
+ bzero(ret, size);
+
+ return ret;
+}
+EXPORT_SYMBOL(_Znwm);
diff -Naur ./old//magenta/libkern.h ./kern//magenta/libkern.h
--- ./old//magenta/libkern.h  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/libkern.h 2012-08-04 17:47:23.000000000 -0400
@@ -0,0 +1,21 @@
+/*
+ * libkern.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Bits no one cares about.
+ */
+
+#ifndef _H_MG_LIBK_
+#define _H_MG_LIBK_
+
+#include <linux/kernel.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+
+#include <DarwinTypes.h>
+#include <MachO.h>
+
+void bzero(void* base, size_t size);
+void bcopy(const void *src, void *dest, size_t n);
+
+#endif
diff -Naur ./old//magenta/loader.h ./kern//magenta/loader.h
--- ./old//magenta/loader.h 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/loader.h  2012-06-16 17:04:07.000000000 -0400
@@ -0,0 +1,120 @@
+/*
+ * loader.h
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Loader types.
+ */
+
+#ifndef _H_MG_LOADER_
+#define _H_MG_LOADER_
+
+#include "ipc_types.h"
+#include <DarwinTypes.h>
+#include <MachO.h>
+
+/* Section */
+
+ /*
+ * The flags field of a section structure is separated into two parts a section
+ * type and section attributes.  The section types are mutually exclusive (it
+ * can only have one type) but the section attributes are not (it may have more
+ * than one attribute).
+ */
+#define SECTION_TYPE    0x000000ff /* 256 section types */
+#define SECTION_ATTRIBUTES  0xffffff00 /*  24 section attributes */
+
+/* Constants for the type of a section */
+#define  S_REGULAR   0x0 /* regular section */
+#define  S_ZEROFILL    0x1 /* zero fill on demand section */
+#define  S_CSTRING_LITERALS  0x2 /* section with only literal C strings*/
+#define  S_4BYTE_LITERALS  0x3 /* section with only 4 byte literals */
+#define  S_8BYTE_LITERALS  0x4 /* section with only 8 byte literals */
+#define  S_LITERAL_POINTERS  0x5 /* section with only pointers to */
+         /*  literals */
+
+
+/* Nlist */
+
+#define  N_STAB  0xe0  /* if any of these bits set, a symbolic debugging entry */
+#define  N_PEXT  0x10  /* private external symbol bit */
+#define  N_TYPE  0x0e  /* mask for the type bits */
+#define  N_EXT 0x01  /* external symbol bit, set for external symbols */
+
+/*
+ * Only symbolic debugging entries have some of the N_STAB bits set and if any
+ * of these bits are set then it is a symbolic debugging entry (a stab).  In
+ * which case then the values of the n_type field (the entire field) are given
+ * in <mach-o/stab.h>
+ */
+
+/*
+ * Values for N_TYPE bits of the n_type field.
+ */
+#define  N_UNDF  0x0   /* undefined, n_sect == NO_SECT */
+#define  N_ABS 0x2   /* absolute, n_sect == NO_SECT */
+#define  N_SECT  0xe   /* defined in section number n_sect */
+#define  N_PBUD  0xc   /* prebound undefined (defined in a dylib) */
+#define N_INDR 0xa   /* indirect */
+
+struct nlist {
+ union {
+#ifndef __LP64__
+   char *n_name; /* for use when in-core */
+#endif
+   int32_t n_strx; /* index into the string table */
+ } n_un;
+ uint8_t n_type;   /* type flag, see below */
+ uint8_t n_sect;   /* section number or NO_SECT */
+ int16_t n_desc;   /* see <mach-o/stab.h> */
+ uint32_t n_value; /* value of this symbol (or stab offset) */
+};
+
+#define N_NO_DEAD_STRIP 0x0020 /* symbol is not to be dead stripped */
+#define N_DESC_DISCARDED 0x0020  /* symbol is discarded */
+#define N_WEAK_REF 0x0040 /* symbol is weak referenced */
+#define N_WEAK_DEF 0x0080 /* coalesed symbol is a weak definition */
+#define  N_REF_TO_WEAK 0x0080 /* reference to a weak symbol */
+#define N_ARM_THUMB_DEF  0x0008 /* symbol is a Thumb function (ARM) */
+#define N_SYMBOL_RESOLVER  0x0100 
+
+/* Reloc stuff */
+
+ #define R_SCATTERED 0x80000000  /* mask to be applied to the r_address field 
+          of a relocation_info structure to tell that
+          is is really a scattered_relocation_info
+          stucture */
+
+enum reloc_type_generic
+{
+    GENERIC_RELOC_VANILLA, /* generic relocation as discribed above */
+    GENERIC_RELOC_PAIR,    /* Only follows a GENERIC_RELOC_SECTDIFF */
+    GENERIC_RELOC_SECTDIFF,
+    GENERIC_RELOC_PB_LA_PTR, /* prebound lazy pointer */
+    GENERIC_RELOC_LOCAL_SECTDIFF,
+    GENERIC_RELOC_TLV    /* thread local variables */
+};
+
+struct relocation_info {
+   int32_t r_address;  /* offset in the section to what is being
+          relocated */
+   uint32_t     r_symbolnum:24,  /* symbol index if r_extern == 1 or section
+          ordinal if r_extern == 0 */
+   r_pcrel:1,  /* was relocated pc relative already */
+   r_length:2, /* 0=byte, 1=word, 2=long, 3=quad */
+   r_extern:1, /* does not include value of sym referenced */
+   r_type:4; /* if not 0, machine specific relocation type */
+};
+
+#define  R_ABS 0   /* absolute relocation type for Mach-O files */
+
+/* Actual loader stuff */
+struct symtab_command {
+ uint32_t  cmd;    /* LC_SYMTAB */
+ uint32_t  cmdsize;  /* sizeof(struct symtab_command) */
+ uint32_t  symoff;   /* symbol table offset */
+ uint32_t  nsyms;    /* number of symbol table entries */
+ uint32_t  stroff;   /* string table offset */
+ uint32_t  strsize;  /* string table size in bytes */
+};
+
+#endif
diff -Naur ./old//magenta/Log.c ./kern//magenta/Log.c
--- ./old//magenta/Log.c  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/Log.c 2012-08-08 10:19:02.000000000 -0400
@@ -0,0 +1,129 @@
+/*
+ * Log.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Logging stuff.
+ */
+
+#include "ke_runtime.h"
+
+/*
+ * Logging routine.
+ */
+#define ChristinasSillyUartDebugging 0
+#define BRIGHT     1
+
+#define BLACK    0
+#define RED    1
+#define GREEN    2
+#define YELLOW   3
+#define BLUE   4
+#define MAGENTA    5
+#define CYAN   6
+#define  WHITE   7
+#define VT_DEFAULT  9
+
+#define default_attributes "\33[0m"
+
+int OSLog(const char *fmt, ...)
+{
+ va_list args;
+ int r;
+
+#if defined(ChristinasSillyUartDebugging)
+ char pre[13];
+ sprintf(pre, "%c[%d;%d;%dm", 0x1B, BRIGHT, WHITE + 30, BLUE + 40);
+ printk("%s[os]%s: ", pre, default_attributes);
+#endif
+
+ va_start(args, fmt);
+ r = vprintk(fmt, args);
+ va_end(args);
+
+ printk("\n");
+
+ return r;
+}
+
+#define LOGFNC GREEN
+int OSLogFn(const char *fn, const char *fmt, ...)
+{
+ va_list args;
+ int r;
+
+#if defined(ChristinasSillyUartDebugging)
+ char pre[13];
+ sprintf(pre, "%c[%d;%d;%dm", 0x1B, BRIGHT, LOGFNC + 30, VT_DEFAULT);
+ printk("%s[kern]%s ", pre, default_attributes);
+
+ sprintf(pre, "%c[%d;%d;%dm", 0x1B, 0, LOGFNC + 30, VT_DEFAULT + 40);
+ printk("%s%s():%s ", pre, fn, default_attributes);
+#endif
+
+ va_start(args, fmt);
+ r = vprintk(fmt, args);
+ va_end(args);
+
+ printk("\n");
+
+ return r;
+}
+
+int OSWarnFn(const char *fn, const char *fmt, ...)
+{
+ va_list args;
+ int r;
+
+#if defined(ChristinasSillyUartDebugging)
+ char pre[13];
+ sprintf(pre, "%c[%d;%d;%dm", 0x1B, BRIGHT, RED + 30, VT_DEFAULT);
+ printk("%s[warn]%s ", pre, default_attributes);
+
+ sprintf(pre, "%c[%d;%d;%dm", 0x1B, 0, RED + 30, VT_DEFAULT + 40);
+ printk("%s%s():%s ", pre, fn, default_attributes);
+#endif
+
+ va_start(args, fmt);
+ r = vprintk(fmt, args);
+ va_end(args);
+
+ printk("\n");
+
+ return r;
+}
+
+int ke_log(const char *fmt, ...)
+{
+ va_list args;
+ int r;
+
+#if defined(ChristinasSillyUartDebugging)
+ char pre[13];
+ sprintf(pre, "%c[%d;%d;%dm", 0x1B, BRIGHT, WHITE + 30, BLUE + 40);
+ printk("%s[kern]%s: ", pre, default_attributes);
+#endif
+
+ va_start(args, fmt);
+ r = vprintk(fmt, args);
+ va_end(args);
+
+ return r;
+}
+
+int ke_warn(const char *fmt, ...)
+{
+ va_list args;
+ int r;
+
+#if defined(ChristinasSillyUartDebugging)
+ char pre[13];
+ sprintf(pre, "%c[%d;%d;%dm", 0x1B, BRIGHT, WHITE + 30, RED + 40);
+ printk("%s[kern]%s: ", pre, default_attributes);
+#endif
+
+ va_start(args, fmt);
+ r = vprintk(fmt, args);
+ va_end(args);
+
+ return r;
+}
diff -Naur ./old//magenta/mach_core.c ./kern//magenta/mach_core.c
--- ./old//magenta/mach_core.c  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/mach_core.c 2012-08-08 11:32:35.000000000 -0400
@@ -0,0 +1,602 @@
+/*
+ * mach_core.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Core support for:
+ *       > mach objects
+ *      > ipc spaces
+ *      > port rights
+ */
+
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+
+#include "VM.h"
+
+/*
+ Port list.
+*/
+static DECLARE_RWSEM(ports_sem);
+static task_port_t* kernel_task;
+static DEFINE_MUTEX(port_ref_modify_lock);
+
+#define RefModifyLockDown() mutex_lock(&port_ref_modify_lock)
+#define RefModifyLockUp() mutex_unlock(&port_ref_modify_lock)
+
+/* Task port ops */
+kern_return_t task_message_handle(void* payload, void* trap_data);
+ke_port_ops_t _task_port_ops = {task_message_handle};
+
+
+/*
+ * Zones used by the slab allocators.
+ */
+static struct kmem_cache* zone_port_rights;
+
+/* Handler for kernel messages */
+extern int kmsg_handle(mach_msg_header_t* msg);
+extern kern_return_t ipc_message_handle(void* payload);
+
+/*
+ Mutex for kmsgs.
+*/
+DEFINE_MUTEX(kmsg_exec_mutex);
+
+task_port_t* get_kernel_task(void)
+{
+ return kernel_task;
+}
+
+kern_return_t Task_get_object_if_receive(mach_port_t user_port, Obj** out, uint16_t type)
+{
+ ke_port_right_t* name;
+
+ name = Task_find_right(user_port);
+ if (!name) {
+   return KERN_INVALID_NAME;
+ }
+ if (!name->port) {
+   RightDecrementRefCount(name, r_kernel);
+   return KERN_FAILURE;
+ }
+
+ if (type == KE_PORT_TYPE_ANY)
+ {
+   type = name->port->type;
+ }
+
+ if (!IsReceiveRight(name) || name->port->type != type)
+ {
+   PortRelease(name->port);
+   RightDecrementRefCount(name, r_kernel);
+   return KERN_INVALID_RIGHT;
+ }
+
+ *out = name->port;
+ RightDecrementRefCount(name, r_kernel);
+
+ return KERN_SUCCESS;
+}
+
+kern_return_t Task_get_object_if_send(mach_port_t user_port, Obj** out, uint16_t type)
+{
+ ke_port_right_t* name;
+
+ name = Task_find_right(user_port);
+ if (!name) {
+   return KERN_INVALID_NAME;
+ }
+ if (!name->port) {
+   RightDecrementRefCount(name, r_kernel);
+   return KERN_FAILURE;
+ }
+
+ if (type == KE_PORT_TYPE_ANY)
+ {
+   type = name->port->type;
+ }
+
+ if (!IsSendRight(name) || name->port->type != type)
+ {
+   PortRelease(name->port);
+   RightDecrementRefCount(name, r_kernel);
+   return KERN_INVALID_RIGHT;
+ }
+
+ *out = name->port;
+ RightDecrementRefCount(name, r_kernel);
+
+ return KERN_SUCCESS;
+}
+
+boolean_t __is_receive_right(ke_port_right_t* right)
+{
+ int count;
+
+ count = atomic_read(&right->r_receive);
+
+ if (count == 1) {
+   return true;
+ }
+ else if (count > 1) {
+   panic("__is_receive_right(): DEBUG: r_receive is over 1");
+ }
+
+ return false;
+}
+
+boolean_t __is_send_right(ke_port_right_t* right)
+{
+ int count;
+
+ count = atomic_read(&right->r_send);
+
+ if (count) {
+   return true;
+ }
+
+ return false;
+}
+
+boolean_t __is_port_set_right(ke_port_right_t* right)
+{
+ int count;
+
+ count = atomic_read(&right->r_port_set);
+
+ if (count) {
+   return true;
+ }
+
+ return false;
+}
+
+Obj* Obj_allocate(uint16_t object_type,
+ size_t object_size, 
+ ke_port_ops_t* object_operations)
+{
+ Obj* prt = NULL;
+
+ prt = (Obj*)kmalloc(object_size, GFP_KERNEL);
+
+ BUG_ON(prt == NULL);
+
+ memset(prt, 0, object_size);
+ 
+ prt->type = object_type;
+ prt->active = true;
+ prt->ops = object_operations;
+ mutex_init(&prt->mtx);
+
+ /* One initial reference */
+ atomic_set(&prt->refs, 1);
+
+ return prt;
+}
+
+/*
+ * Returns a new kernel port.
+ */
+ke_port_t* Obj_allocate_old(uint16_t type)
+{
+ size_t port_size;
+
+ if (type == KE_PORT_TYPE_TASK) {
+   port_size = sizeof(task_port_t);
+ }
+ else if (type == KE_PORT_TYPE_IPC) {
+   port_size = sizeof(ipc_port);
+ }
+ else if (type == KE_PORT_TYPE_PORT_SET) {
+   port_size = sizeof(ipc_port_set);
+ }
+ else if (type == KE_PORT_TYPE_HOST) {
+   port_size = sizeof(host_port_t);
+ }
+ else if (type == KE_PORT_TYPE_THREAD) {
+   port_size = sizeof(thread_port_t);
+ }
+ else if (type == KE_PORT_TYPE_SEMAPHORE) {
+   port_size = sizeof(sem_port_t);
+ }
+ else {
+   panic("ke_port_allocate(): unknown port type");
+ }
+
+ return Obj_allocate(type, port_size, NULL);
+}
+
+boolean_t Obj_is_active(ke_port_t* port)
+{
+ boolean_t active;
+ active = port->active;
+
+ return active;
+}
+
+int Obj_get_refcount(ke_port_t* port)
+{
+ int ar;
+ ar = atomic_read(&port->refs);
+ return ar;
+}
+
+void Obj_release(ke_port_t* port)
+{
+ int ar;
+ ar = atomic_dec_return(&port->refs);
+
+ //ke_log("ke_port_up(%p): refcount %d\n", port, ar);
+
+ if (ar == 0) {
+   Xwarn("port[%p], refcount hit 0, need to release!", port);
+ }
+
+ if (ar < 0) {
+   panic("port refcount is smaller than 0, something is broken!");
+ }
+}
+
+boolean_t Obj_retain(ke_port_t* port)
+{
+ if (!PortActive(port)) {
+   ke_warn("ke_port_down(%p): *** inactive\n", port);
+   return false;
+ }
+ else {
+   int ar;
+   ar = atomic_inc_return(&port->refs);
+
+   //ke_log("ke_port_down(%p): refcount %d\n", port, ar);
+
+   return true;
+ }
+}
+
+ke_port_right_t* Right_allocate(void)
+{
+ ke_port_right_t* right;
+
+ right = (ke_port_right_t*)kmem_cache_alloc(zone_port_rights, GFP_KERNEL);
+
+ atomic_set(&(right->r_receive), 0);
+ atomic_set(&(right->r_send), 0);
+ atomic_set(&(right->r_port_set), 0);
+ atomic_set(&(right->r_send), 0);
+ atomic_set(&(right->r_kernel), 0);
+}
+
+void Task_add_right(task_port_t* space, ke_port_right_t* rr)
+{
+ PortLock(space);
+
+ list_add(&(rr->list), &(space->port_rights));
+
+ PortUnlock(space);
+}
+
+void ke_teardown_task(task_port_t* space) { panic("%s", __FUNCTION__); }
+
+thread_port_t* Native_get_thread(struct task_struct* task)
+{
+ RefModifyLockDown();
+
+ thread_port_t* tp = (thread_port_t*)task->thread_port;
+ PortRetain(tp);
+
+ RefModifyLockUp();
+
+ return tp;
+}
+
+task_port_t* Native_get_task(struct task_struct* task)
+{
+ RefModifyLockDown();
+
+ task_port_t* tp = (task_port_t*)task->task_port;
+ PortRetain(tp);
+
+ RefModifyLockUp();
+
+ return tp;
+}
+
+thread_port_t* Native_get_current_thread(void)
+{
+ return Native_get_thread(current);
+}
+
+task_port_t* Native_get_current_task(void)
+{
+ return Native_get_task(current);
+}
+
+
+/*
+ * Either gets an existing port right or adds it to the 
+ * ipc space (if add is specified).
+ */
+ke_port_right_t* Task_get_right(task_port_t* space, ke_port_t* fprt, boolean_t add)
+{
+ struct list_head *p;
+ ke_port_right_t* rr = NULL;
+
+ PortLock(space);
+
+ if (space->port.type != KE_PORT_TYPE_TASK) {
+   /* Only tasks can store rights */
+   PortUnlock(space);
+   goto out;
+ }
+
+ list_for_each (p, &(space->port_rights)) {
+   rr = list_entry(p, ke_port_right_t, list);
+   if (rr->port == fprt) {
+     PortUnlock(space);
+     goto out;
+   }
+ }
+
+ PortUnlock(space);
+
+ if (add)
+ {
+   /*
+    * Right not found in the list, we need to add
+    * a new one to it.
+    */
+   rr = Right_allocate();
+   rr->port = fprt;
+   rr->name = Task_create_name(space);
+   Task_add_right(space, rr);
+ }
+ else
+ {
+   rr = NULL;
+   goto out_f;
+ }
+
+out:
+ if (rr) {
+   RightIncrementRefCount(rr, r_kernel);
+ }
+out_f:
+ return rr;
+}
+
+/*
+ * Creates a brand new port (not a right, an actual port)
+ * in the space. Also sets up a empty right for the port.
+ * The unassosciated right is returned.
+ * This function sets up a new port name for the port.
+ */
+ke_port_right_t* Obj_new(uint16_t type)
+{
+ ke_port_right_t* rr;
+ ke_port_t* kprt;
+
+ kprt = Obj_allocate_old(type);
+
+ /* Set up the first right */
+ rr = Right_allocate();
+ rr->port = kprt;
+ rr->urefs = 1;
+
+ return rr;
+}
+
+
+/*
+ * Finds a port right.
+ */
+ke_port_right_t* Task_find_right(mach_port_t name)
+{
+ ke_port_right_t* prt = NULL;
+ task_port_t* space;
+ ke_port_right_t* rr;
+ struct list_head *p;
+
+ space = ke_get_current_task();
+
+ RefModifyLockDown();
+
+ PortLock(space);
+ list_for_each (p, &(space->port_rights)) {
+   rr = list_entry(p, ke_port_right_t, list);
+   if (rr->name == name) {
+     prt = rr;
+   }
+ }
+ PortUnlock(space);
+
+ PortRelease(space);
+ 
+ if (prt) {
+   if (PortRetain(prt->port)) {
+     /* Nothing */
+   }
+   else {
+     /*
+      * Right points to an inactive port.
+      * Pretend it doesn't exist.
+      */
+     RefModifyLockUp();
+     return NULL;
+   }
+ }
+
+ RefModifyLockUp();
+
+ if (prt) {
+   RightIncrementRefCount(rr, r_kernel);
+ }
+ return prt;
+}
+
+/*
+ * Finds a port by its port name in the local
+ * ipc space. If it is not found, returns NULL.
+ */
+ke_port_t* Task_find_port(mach_port_t name)
+{
+ ke_port_t* prt = NULL;
+ ke_port_right_t* rr;
+
+ rr = Task_find_right(name);
+ if (rr) {
+   prt = rr->port;
+   RightDecrementRefCount(rr, r_kernel);
+ }
+
+ return prt;
+}
+
+mach_port_t Task_create_name(task_port_t* space)
+{
+ int id = 0;
+ int res = 0;
+ if (idr_pre_get(&(space->name_pool), GFP_KERNEL) == 0) {
+   panic("ke_get_new_port_name_in_space(): idr failure");
+ }
+
+ res = idr_get_new_above(&(space->name_pool), NULL, 20, &id);
+
+ if (res != 0)
+ {
+   panic("ke_get_new_port_name_in_space(): idr failure 2");
+ } 
+
+ return id;
+}
+
+kern_return_t task_message_handle(void* payload, void* trap_data)
+{
+ panic("task_message_handle");
+}
+
+ke_port_right_t* Task_allocate(void)
+{
+ task_port_t* kprt = NULL;
+ ke_port_right_t* rr = NULL;
+
+ rr = ke_new_port(KE_PORT_TYPE_TASK);
+ if (!rr || !rr->port) {
+   panic("ke_create_ipc_space(): unable to create a new ipc space");
+ }
+ kprt = (task_port_t*)rr->port;
+
+ kprt->port.ops = &_task_port_ops;
+ atomic_set(&(kprt->thread_count), 0);
+
+ /* Initalize the port right list */
+ INIT_LIST_HEAD(&(kprt->port_rights));
+
+ /* Initialize IDR for allocating port names */
+ idr_init(&(kprt->name_pool));
+
+ return rr;
+}
+
+void Native_setup_task(struct task_struct* task)
+{
+ ke_port_right_t* rr = Task_allocate();
+ task_port_t* kprt = (task_port_t*)rr->port;
+
+ /* Set the task descriptor */
+ kprt->task = task;
+
+ /* And set the port */
+ task->task_port = (void*)kprt;
+
+ /* Add a receive right for the kernel */
+ rr->name = ke_get_new_port_name_in_space(kernel_task);
+ RightIncrementRefCount(rr, r_receive);
+ ke_add_right_to_space(kernel_task, rr);
+
+ /* Add a send right to the task */
+ rr = Right_allocate();
+ rr->port = (ke_port_t*)kprt;
+ rr->name = ke_get_new_port_name_in_space(kprt);
+ RightIncrementRefCount(rr, r_send);
+ ke_add_right_to_space(kprt, rr);
+
+ Xlog("task %p got port %d", task, rr->name);
+}
+
+static void dump_mach_msg_hdr(mach_msg_header_t* head) {
+ return;
+
+ printk(KERN_WARNING "Mach Message:\n"
+ "\tbits: %p\n\tsize: %d\n\tremote: %d\n\tlocal: %d\n\tid : %d\n"
+ ,(void*)head->msgh_bits, head->msgh_size, head->msgh_remote_port, head->msgh_local_port, head->msgh_id);
+}
+
+kern_return_t mach_port_destroy(ipc_space_t task, mach_port_name_t name)
+{
+ return KERN_FAILURE;
+}
+
+SYSCALL_DEFINE1(mach_msg_trap, struct mach_msg_trap_data __user *, usr_data)
+{
+ printk("sys_mach_msg_trap(): obsolete, do not use!");
+ return KERN_FAILURE;
+}
+
+kern_return_t _user_mach_msg_trap(struct mach_msg_trap_data __user* usr_data)
+{
+ panic("ate bad food!");
+}
+
+int init_mach_ipc(void)
+{
+ ke_port_right_t* rr = NULL;
+ ke_port_t* kprt = NULL;
+
+ zone_port_rights = 
+ kmem_cache_create("zone_port_rights", sizeof(ke_port_right_t), 0, SLAB_PANIC, NULL);
+
+ if (!zone_port_rights) {
+   panic("init_mach_ipc(): failed to create port right slab");
+ }
+
+ /*
+  * Create an IPC space for the kernel.
+  */
+ rr = Task_allocate();
+ kprt = rr->port;
+ kernel_task = (task_port_t*)kprt;
+
+ XLog("started mach ipc subsystem");
+
+ return 0;
+}
diff -Naur ./old//magenta/mach_host.c ./kern//magenta/mach_host.c
--- ./old//magenta/mach_host.c  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/mach_host.c 2012-07-21 15:26:29.000000000 -0400
@@ -0,0 +1,119 @@
+/*
+ * mach_host.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Mach host.
+ */
+
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+#include <linux/sched.h>
+
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+
+#include "ke_runtime.h"
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+
+/* Host port ops */
+kern_return_t host_message_handle(void* payload, void* trap_data);
+ke_port_ops_t _host_port_ops = {host_message_handle};
+
+host_port_t* _host_self;
+
+ke_port_right_t* mach_host_allocate(task_port_t* space)
+{
+ host_port_t* prt = NULL;
+ ke_port_right_t* rr = NULL;
+
+ rr = ke_new_port(KE_PORT_TYPE_HOST);
+ if (!rr || !rr->port) {
+   return NULL;
+ }
+ prt = (host_port_t*)rr->port;
+
+ /* operations*/
+ prt->port.ops = &_host_port_ops;
+
+ rr->name = ke_get_new_port_name_in_space(space);
+ ke_add_right_to_space(space, rr);
+
+ return rr;
+}
+
+kern_return_t _user_host_info(mach_port_t host, integer_t flavor, integer_t* ret, integer_t* len)
+{
+ return KERN_FAILURE;
+}
+
+kern_return_t host_message_handle(void* payload, void* trap_data__)
+{
+ mach_msg_trap_data_t* trap_data = (mach_msg_trap_data_t*)trap_data__;
+ mach_msg_header_t* msg = (mach_msg_header_t*)payload;
+ kern_return_t retval;
+
+ retval = KERN_FAILURE;
+
+ return retval;
+}
+
+mach_port_t _user_host_self(void)
+{
+ /* We should already hold the send right*/
+ task_port_t* tp = ke_get_current_task();
+ ke_port_right_t* rcv = ke_get_right_in_space(tp, (ke_port_t*)_host_self, true);
+
+ if (rcv) {
+   mach_port_t nm = rcv->name;
+   PortRelease(tp);
+   return nm;
+ }
+ else {
+   /*
+    * This shouldn't ever happen.
+    */
+   ke_warn("_user_host_self(): failed!");
+   return 0;
+ }
+}
+
+void mach_host_init(void)
+{
+ ke_port_right_t* rcv;
+
+ rcv = mach_host_allocate(get_kernel_task());
+
+ BUG_ON(rcv == NULL);
+ BUG_ON(rcv->port == NULL);
+
+ _host_self = rcv->port;
+
+ ke_log("mach_host_init(): host initialized (self = %p)!\n", _host_self);
+}
diff -Naur ./old//magenta/mach_kmsg.c ./kern//magenta/mach_kmsg.c
--- ./old//magenta/mach_kmsg.c  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/mach_kmsg.c 2012-08-06 11:00:25.000000000 -0400
@@ -0,0 +1,483 @@
+/*
+ * mach_kmsg.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Support for IPC transactions.
+ */
+
+#include "Ipc.h"
+
+#define KERN_IPC_QUEUE_EMPTY 300
+
+
+#define MAX_USER_MESSAGE_SIZE 81920 /* Twenty pages should be enough for anything */
+
+int kmsg_handle(mach_msg_header_t* msg) { panic("%s", __FUNCTION__); }
+
+ipc_message* Ipc_message_allocate(mach_msg_header_t* head,
+ size_t size,
+ task_port_t* from_task)
+{
+ ipc_message* msg = (ipc_message*)kmalloc(sizeof(ipc_message), GFP_KERNEL);
+
+ msg->msg = head;
+ msg->head = *(head); /* inline header */
+ msg->received = 0;
+ msg->size = size;
+
+ /* Make sure the task port is not deallocated while in transit */
+ PortRetain(from_task);
+
+ msg->sender = from_task;
+
+ return msg;
+}
+
+void Ipc_message_destroy(ipc_message* message)
+{
+ PortRelease(message->sender);
+ kfree(message);
+}
+
+void Ipc_port_wake_waiters(ipc_port* port)
+{
+ wait_queue_head_t** queues;
+ unsigned int count;
+ unsigned int i = 0;
+
+ spin_lock(&port->wait_list_lock);
+
+ count = ke_array_get_count(port->wait_list);
+ queues = __ke_array_get_base(port->wait_list);
+
+ /* wake up all the queues */
+ for (i = 0; i < count; i++)
+ {
+   wait_queue_head_t* q = queues[i];
+   wake_up(q);
+ }
+
+ spin_unlock(&port->wait_list_lock);
+
+ Xlog("(%p) woken %d waiter(s)", port, count);
+}
+
+kern_return_t Ipc_msg_send_nonblock(ipc_port* dst_port, ipc_message* in_message)
+{
+ kern_return_t retval;
+ mach_port_t swap;
+
+ /* Redundant sanity checks */
+ if (dst_port->port.type != KE_PORT_TYPE_IPC)
+ {
+   retval = KERN_FAILURE;
+   goto out;
+ }
+
+ /* Make sure that the port is still active */
+ if (!dst_port->port.active)
+ {
+   retval = KERN_TERMINATED;
+   goto out;
+ }
+
+ /* XXX: MOVE TO RCV!!!! AND RESOLVE THE FUCKING PORTS.  */
+ swap = in_message->msg->msgh_local_port;
+ in_message->msg->msgh_local_port = in_message->msg->msgh_remote_port;
+ in_message->msg->msgh_remote_port = swap;
+
+ /* Send message */
+ if (kfifo_in((&dst_port->queue), &in_message, sizeof(in_message)) != sizeof(in_message))
+ {
+   panic("ipc_msg_send_nonblock(): kfifo_in failed!");
+ }
+
+ Xlog("enqueued msg[%p] => ipc_port[%p]", in_message, dst_port);
+
+ /* Just sent something, so wake the queues */
+ Ipc_port_wake_waiters(dst_port);
+
+ /* sucess, I guess */
+ retval = KERN_SUCCESS;
+
+out:
+ return retval;
+}
+
+void Ipc_port_add_queue(ipc_port* port, wait_queue_head_t* queue)
+{
+ ke_storage_type qq = (ke_storage_type)queue;
+
+ spin_lock(&port->wait_list_lock);
+ ke_array_add(port->wait_list, qq);
+ spin_unlock(&port->wait_list_lock);
+}
+
+kern_return_t Ipc_msg_send_block(ipc_port* dst_port, ipc_message* in_message)
+{
+ return Ipc_msg_send_nonblock(dst_port, in_message);
+}
+
+/*
+ * 
+ */
+kern_return_t Ipc_message_process(task_port_t* task, ipc_message* message)
+{
+ return MACH_MSG_SUCCESS;
+}
+
+/*
+ * Receive a message from an IPC port. Doesn't block.
+ */
+kern_return_t Ipc_msg_receive_nonblock(ipc_port* rcv_port,
+ task_port_t* task,
+ ipc_message** out_message,
+ size_t max_size,
+ boolean_t large)
+{
+ kern_return_t retval;
+ boolean_t too_large = false;
+
+ BUG_ON(!rcv_port);
+ BUG_ON(!out_message);
+
+ /* Redundant sanity checks */
+ if (rcv_port->port.type != KE_PORT_TYPE_IPC)
+ {
+   retval = MACH_RCV_INVALID_NAME;
+   goto out;
+ }
+
+ /* Make sure that the port is still active */
+ if (!rcv_port->port.active)
+ {
+   retval = MACH_RCV_PORT_DIED;
+   goto out;
+ }
+
+ /* See if the queue is empty */
+ if (kfifo_is_empty(&rcv_port->queue))
+ {
+   retval = MACH_RCV_IN_PROGRESS;
+   goto out;
+ }
+
+ /* check if the message fits into the dest buffer */
+ if (max_size != 0)
+ {
+   size_t msg_size;
+
+   /* peek into the queue */
+   BUG_ON(kfifo_out_peek(&(rcv_port->queue), out_message, sizeof(out_message)) != sizeof(out_message));
+   
+   msg_size = (*out_message)->size;
+
+   if (msg_size > max_size)
+   {
+     /* too large */
+     too_large = true;
+   }
+ }
+
+ /*
+  * If the message is too large ang RCV_LARGE is off, dequeue the message
+  * but return an error. If it's too large but it's on, do not dequeue message
+  * but return an error. Otherwise, just dequeue and return success.
+  */
+ if (!too_large || (too_large && !large))
+ {
+   if (kfifo_out(&(rcv_port->queue), out_message, sizeof(out_message)) != sizeof(out_message))
+   {
+     panic("ipc_msg_receive_nonblock(): kfifo_out failed!");
+   }
+ }
+
+ (*out_message)->received = true;
+
+ if (!too_large)
+ {
+   Xlog("dequeued msg[%p] <= ipc_port[%p]", *out_message, rcv_port);
+   retval = Ipc_message_process(task, *out_message);
+ }
+ else
+ {
+   retval = MACH_RCV_TOO_LARGE;
+ }
+
+out:
+ return retval;
+}
+
+kern_return_t Ipc_msg_receive_block(ipc_port* rcv_port,
+ task_port_t* task,
+ ipc_message** out_message,
+ size_t max_size,
+ boolean_t large)
+{
+ kern_return_t retval;
+ int qr = 0; /* queue wait result */
+
+ Xlog("(%p): waiting for enqueued data ...", rcv_port);
+ qr = wait_event_interruptible((rcv_port->wait_queue),
+                 (retval = Ipc_msg_receive_nonblock(rcv_port,
+                   task,
+                   out_message,
+                   max_size,
+                   large)) != MACH_RCV_IN_PROGRESS);
+     
+ if (qr == -ERESTARTSYS)
+ {
+   Xlog("(%p) aborted!\n", rcv_port);
+
+   retval = MACH_RCV_INTERRUPTED;
+   goto out;
+ }
+ else 
+ {
+   Xwarn("(%p) receieved message, return code %d\n", rcv_port, retval);
+ }
+
+out:
+ return retval;
+}
+
+void* Ipc_msg_copyin_user(void* msg, size_t size)
+{
+ mach_msg_header_t* buffer;
+
+ if (size == 0) {
+   return NULL;
+ }
+
+ buffer = kmalloc(size, GFP_KERNEL);
+
+ if (copy_from_user((void*)buffer, msg, size)) {
+   /* we screwed up */
+   return NULL;
+ }
+
+ return buffer;
+}
+
+/*
+ mach_msg_bits_t msgh_bits;
+ mach_msg_size_t msgh_size;
+ mach_port_t   msgh_remote_port;
+ mach_port_t   msgh_local_port;
+ mach_msg_size_t msgh_reserved;
+ mach_msg_id_t msgh_id;
+*/
+
+
+kern_return_t Ipc_get_suitable_receiver(mach_port_t user_port, Obj** out)
+{
+ ke_port_right_t* name;
+
+ name = Task_find_right(user_port);
+ if (!name) {
+   return KERN_INVALID_NAME;
+ }
+ if (!name->port) {
+   RightDecrementRefCount(name, r_kernel);
+   return KERN_FAILURE;
+ }
+
+ if (!IsReceiveRight(name) && !IsPortSetRight(name))
+ {
+   PortRelease(name->port);
+   RightDecrementRefCount(name, r_kernel);
+   return KERN_INVALID_RIGHT;
+ }
+
+ *out = name->port;
+ RightDecrementRefCount(name, r_kernel);
+
+ return KERN_SUCCESS;
+}
+
+/*
+typedef struct
+{
+ struct __Task* task;
+
+ void* rcv_buffer;
+ size_t rcv_size;
+
+ struct __Obj* snd_reply;
+ void* snd_msg;
+ size_t snd_size;
+
+ int options;
+ 
+} ipc_trap_data_t;
+*/
+
+kern_return_t mach_msg_overwrite(
+ mach_msg_header_t* msg,
+ int option,
+ natural_t send_size,
+ natural_t rcv_size,
+ mach_port_t rcv_name,
+ natural_t timeout,
+ mach_port_t notify,
+ void* rcv_msg)
+{
+ ipc_trap_data_t _tdata;
+ ipc_trap_data_t* tdata = &_tdata;
+ kern_return_t ret = KERN_FAILURE;
+
+ Obj* destination = NULL;
+ Obj* reply = NULL;
+ Obj* receive = NULL;
+
+ memset(tdata, 0, sizeof(ipc_trap_data_t));
+
+ if (option & MACH_MSG_USER) {
+   option |= MACH_RCV_OVERWRITE;
+ }
+
+ tdata->options = option;
+ tdata->task = Native_get_current_task();
+
+ if (option & MACH_RCV_OVERWRITE) {
+   tdata->rcv_buffer = (void*)rcv_msg;
+ }
+ else {
+   tdata->rcv_buffer = (void*)msg;
+ }
+
+ tdata->snd_size = send_size;
+ tdata->snd_msg = msg;
+ tdata->rcv_size = rcv_size;
+
+ /*
+  * Either send or receive could potentially block.
+  * But we send first anyway.
+  */
+
+ if (option & MACH_SEND_MSG)
+ {
+   /* Resolve reply port if needed */
+   if (msg->msgh_local_port != 0)
+   {
+     ret = Task_get_object_if_receive(msg->msgh_local_port, &reply, KE_PORT_TYPE_IPC);
+
+     if (ret != KERN_SUCCESS) {
+       Xwarn("Invalid reply port\n");
+       ret = MACH_SEND_INVALID_REPLY;
+       goto out_send_error;
+     }
+
+     tdata->snd_reply = reply;
+   }
+
+   /* Resolve destination port */
+   ret = Task_get_object_if_send(msg->msgh_remote_port, &destination, KE_PORT_TYPE_ANY);
+
+   if (ret == KERN_SUCCESS && destination->ops->msg_send)
+   {
+     /* Forward the send operation to the handler */
+     ret = destination->ops->msg_send(destination, tdata);
+
+     if (ret != MACH_MSG_SUCCESS) {
+       Xwarn("Error from msg_send (%p)", (void*)ret);
+       goto out_send_error;
+     }
+   }
+   else
+   {
+     Xwarn("Invalid destination port (%d)", ret);
+     ret = MACH_SEND_INVALID_DEST;
+     goto out_send_error;
+   }
+ }
+
+ /* So these two are not released */
+ destination = NULL;
+ reply = NULL;
+
+ if (option & MACH_RCV_MSG)
+ {
+   /* Resolve receive port */
+   ret = Ipc_get_suitable_receiver(rcv_name, &receive);
+
+   if (ret == KERN_SUCCESS && receive->ops->msg_receive)
+   {
+     /* Forward the send operation to the handler */
+     ret = receive->ops->msg_receive(receive, tdata);
+
+     if (ret != MACH_MSG_SUCCESS) {
+       Xwarn("Error from msg_receive (%p)", (void*)ret);
+       goto out_rcv_error;
+     }
+   }
+   else
+   {
+     Xwarn("Invalid receive port (%d)", ret);
+     ret = MACH_RCV_INVALID_NAME;
+     goto out_rcv_error;
+   }
+ }
+
+ receive = NULL;
+
+ goto out;
+
+out_rcv_error:
+ if (receive) {
+   PortRelease(receive);
+ }
+out_send_error:
+ if (destination) {
+   PortRelease(destination);
+ }
+ if (reply) {
+   PortRelease(reply);
+ }
+out:
+ return ret;
+}
+
+kern_return_t _user_mach_msg_overwrite_trap(
+ void* msg,
+ int option,
+ natural_t send_size,
+ natural_t rcv_size,
+ mach_port_t rcv_name,
+ natural_t timeout,
+ mach_port_t notify,
+ void* rcv_msg)
+{
+ void* copyin_buffer;
+ kern_return_t retval;
+
+ /*
+  * Copy out the message buffer from the userspace if
+  * we are sending a message.
+  */
+ if (option & MACH_SEND_MSG)
+ {
+   copyin_buffer = Ipc_msg_copyin_user(msg, send_size);
+   if (!copyin_buffer) {
+     retval = MACH_SEND_INVALID_DATA;
+     goto out;
+   }
+ }
+
+ option |= MACH_MSG_USER;
+
+ Xlog("msg=%p, option=%p, send_size=%d, rcv_size=%d, rcv_name=%d, timeout=%d, notify=%d, rcv_msg=%p",
+   msg, option, send_size, rcv_size, rcv_name, timeout, notify, rcv_msg);
+
+ retval = mach_msg_overwrite(copyin_buffer,
+   option,
+   send_size,
+   rcv_size,
+   rcv_name,
+   timeout,
+   notify,
+   msg); /* pointer to the user buffer */
+
+out:
+ return retval;
+}
diff -Naur ./old//magenta/mach_kmsg.h ./kern//magenta/mach_kmsg.h
--- ./old//magenta/mach_kmsg.h  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/mach_kmsg.h 2012-06-03 12:06:16.000000000 -0400
@@ -0,0 +1,53 @@
+/*
+ * mach_kmsg.h
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Special mach messages that get interpreted by the
+ * kernel.
+ */
+
+#ifndef _H_MG_MACH_KMSG_
+#define _H_MG_MACH_KMSG_
+
+#include "ipc_types.h"
+
+#define KMSG_MACH_PORT_ALLOCATE 2000
+#define KMSG_LOAD_KEXT 2001
+#define KMSG_GET_DIRECTORY_ENTRIES 2002
+
+typedef struct 
+{
+ mach_msg_header_t head;
+ mach_port_right_t rights;
+ mach_port_t* port_out;
+} kmsg_mach_port_allocate_msg_t;
+
+typedef struct 
+{
+ mach_msg_header_t head;
+ void* buffer;
+ unsigned int buffer_len;
+} kmsg_load_kext_msg_t;
+
+typedef struct 
+{
+ mach_msg_header_t head;
+ int fd;
+ int* out_error;
+ void* buffer;
+ unsigned int buffer_len;
+} kmsg_get_directory_entries_t;
+
+
+/*
+ * 2100: Mach routines
+ */
+#define KMSG_MACH_TASK_SELF 2100
+
+typedef struct 
+{
+ mach_msg_header_t head;
+ mach_port_t* out_port;
+} kmsg_mach_task_self_msg_t;
+
+#endif
diff -Naur ./old//magenta/macho_loader.c ./kern//magenta/macho_loader.c
--- ./old//magenta/macho_loader.c 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/macho_loader.c  2012-08-06 11:01:48.000000000 -0400
@@ -0,0 +1,1219 @@
+/*
+ * MachO Binary Format Support
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * A standalone kernel module responsible for loading MachO binaries
+ * into the kernel. Right now this only supports ARM binaries.
+ */
+
+/*
+ * Incl.
+ */
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/binfmts.h>
+#include <linux/string.h>
+#include <linux/file.h>
+#include <linux/slab.h>
+#include <linux/personality.h>
+#include <linux/elfcore.h>
+#include <linux/init.h>
+#include <linux/highuid.h>
+#include <linux/compiler.h>
+#include <linux/highmem.h>
+#include <linux/pagemap.h>
+#include <linux/security.h>
+#include <linux/random.h>
+#include <linux/elf.h>
+#include <linux/utsname.h>
+#include <linux/coredump.h>
+#include <asm/uaccess.h>
+#include <asm/param.h>
+#include <asm/page.h>
+
+#include <DarwinTypes.h>
+#include <MachO.h>
+
+
+/* 
+ This needs to be in the MachO.h header.
+ #####################################################
+*/
+#define  SEG_TEXT  "__TEXT"
+
+/* mach_loader.h */
+#define LOAD_SUCCESS            0
+#define LOAD_BADARCH            1       /* CPU type/subtype not found */
+#define LOAD_BADMACHO           2       /* malformed mach-o file */
+#define LOAD_SHLIB              3       /* shlib version mismatch */
+#define LOAD_FAILURE            4       /* Miscellaneous error */
+#define LOAD_NOSPACE            5       /* No VM available */
+#define LOAD_PROTECT            6       /* protection violation */
+#define LOAD_RESOURCE           7       /* resource allocation failure */
+
+#define ARM_THREAD_STATE 1
+
+#ifndef CPU_TYPE_ARM
+#define CPU_TYPE_ARM            ((cpu_type_t) 12)
+#define CPU_SUBTYPE_ARM_V4T    ((cpu_subtype_t) 5)
+#define CPU_SUBTYPE_ARM_V6   ((cpu_subtype_t) 6)
+#endif
+
+#ifndef CPU_SUBTYPE_ARM_V5TEJ
+#define CPU_SUBTYPE_ARM_V5TEJ           ((cpu_subtype_t) 7)
+#endif
+
+#ifndef CPU_SUBTYPE_ARM_V7
+#define CPU_SUBTYPE_ARM_V7   ((cpu_subtype_t) 9)
+#endif
+
+/* ARM ONLY! */
+#define trunc_page(x)           ((x) & ~PAGE_MASK)
+
+
+
+/* 
+ Forward declarations
+ #####################################################
+*/
+static int fucking_core_dumper(struct coredump_params *cprm);
+static int load_macho_binary(struct linux_binprm *bprm, struct pt_regs *regs);
+static int load_macho_library(struct file *);
+static unsigned long macho_map(struct file *, unsigned long, struct elf_phdr *,
+       int, int, unsigned long);
+
+
+/* 
+ Impl
+ #####################################################
+*/
+#define round_page(_v) (((_v) + PAGE_SIZE - 1) & ~(PAGE_SIZE - 1))
+
+#define LINK_TABLE_ADDR 0x80014000
+#define LINK_TABLE_SIZE PAGE_SIZE*2
+
+typedef struct {
+ uint32_t entry_count;
+ size_t table_size;
+} linker_image_table_header_t;
+
+typedef struct {
+ uintptr_t load_addr;
+ size_t size;
+ const char* name;
+} linker_image_entry_t;
+
+static struct linux_binfmt macho_format = {
+   .module   = THIS_MODULE,
+   .load_binary  = load_macho_binary,
+   .load_shlib = load_macho_library,
+   .core_dump  = fucking_core_dumper, /* YOU GET NOTHING! */
+   .min_coredump = 0,
+   .hasvdso  = 0
+};
+
+#define BAD_ADDR(x) ((unsigned long)(x) >= TASK_SIZE)
+
+/* Let's use some macros to make this stack manipulation a little clearer */
+#ifdef CONFIG_STACK_GROWSUP
+#define STACK_ADD(sp, items) ((elf_addr_t __user *)(sp) + (items))
+#define STACK_ROUND(sp, items) \
+ ((15 + (unsigned long) ((sp) + (items))) &~ 15UL)
+#define STACK_ALLOC(sp, len) ({ \
+ elf_addr_t __user *old_sp = (elf_addr_t __user *)sp; sp += len; \
+ old_sp; })
+#else
+#define STACK_ADD(sp, items) ((elf_addr_t __user *)(sp) - (items))
+#define STACK_ROUND(sp, items) \
+ (((unsigned long) (sp - items)) &~ 15UL)
+#define STACK_ALLOC(sp, len) ({ sp -= len ; sp; })
+#endif
+
+static unsigned long load_macho_interp(struct elfhdr *interp_elf_ex,
+   struct file *interpreter, unsigned long *interp_map_addr,
+   unsigned long no_base)
+{
+ panic("load_macho_interp: not implemented, use macho_get_dylinker instead. ");
+}
+
+
+static unsigned long randomize_stack_top(unsigned long stack_top)
+{
+ return stack_top;
+}
+
+static int ml_setBrk(unsigned long start, unsigned long end)
+{
+ start = PAGE_ALIGN(start);
+ end = PAGE_ALIGN(end);
+ if (end > start) {
+   unsigned long addr;
+   down_write(&current->mm->mmap_sem);
+   addr = do_brk(start, end - start);
+   up_write(&current->mm->mmap_sem);
+   if (BAD_ADDR(addr))
+     return addr;
+ }
+ current->mm->start_brk = current->mm->brk = start;
+ return 0;
+}
+
+static int _verboseLog = 0;
+
+/* 
+ LOADER
+ #####################################################
+*/
+typedef int  vm_offset_t;
+typedef int  vm_size_t;
+
+static int macho_get_dylinker(struct linux_binprm *bprm, int file_size, struct dylinker_command * lcp, struct file **linker_file) {
+ /*
+   Setup the dynamic linker.
+ */
+ char *name;
+ char *p;
+ 
+ if (lcp->cmdsize < sizeof(*lcp))
+   return (LOAD_BADMACHO);
+
+ name = (char *)lcp + lcp->name.offset;
+
+ /* Make sure the linker path is null terminated */
+ p = name;
+ do {
+   if (p >= (char *)lcp + lcp->cmdsize)
+     return(LOAD_BADMACHO);
+ } while (*p++);
+
+ if (_verboseLog) 
+   printk(KERN_WARNING "macho_get_dylinker: dynamic linker is @'%s'\n", name);
+
+ /*
+   Load the linker executable file.
+ */
+ *linker_file = open_exec(name);
+ if (IS_ERR(*linker_file)) {
+   printk(KERN_WARNING "macho_get_dylinker: can't execute the dynamic linker\n");
+   return(LOAD_BADMACHO);
+ }
+
+ return LOAD_SUCCESS;
+}
+
+static int macho_load_unix_thread(struct linux_binprm *bprm, int file_size, struct arm_thread_command * tcp, void** entry) {
+ /*
+   Setup the main thread.
+ */
+ 
+ /* sanity */
+ if (tcp->flavor != ARM_THREAD_STATE) {
+   printk(KERN_WARNING "macho_load_unix_thread: main thread is of the wrong type %d (need %d)\n",
+       tcp->flavor,
+       ARM_THREAD_STATE);
+ }
+ else if (tcp->count != 17) {
+   printk(KERN_WARNING "macho_load_unix_thread: has the wrong number of arm registers %d (need %d)\n",
+       tcp->count,
+       17);
+ }
+ else {
+   /**/
+   
+   /* Entry point */
+   if (_verboseLog)
+     printk(KERN_WARNING "macho_load_unix_thread: success, pc @ %d\n", tcp->state.r15);
+   
+   *entry = (void*)tcp->state.r15;
+ }
+ 
+ return LOAD_SUCCESS;
+}
+
+static int macho_load_segment(struct linux_binprm *bprm,
+             int file_size,
+             struct segment_command* scp,
+             int* top,
+             void** first_text,
+             vm_offset_t slide)
+{
+ /*
+   Bootstrap a macho segment.
+ */
+ 
+ /***/
+ size_t segment_command_size = sizeof(struct segment_command);
+ size_t total_section_size = scp->cmdsize - segment_command_size;
+ size_t single_section_size  = sizeof(struct section);
+ 
+ int ret;
+ 
+ /* setup mapping vars */
+ vm_offset_t map_addr = round_page(scp->vmaddr);
+ vm_size_t map_size = round_page(scp->filesize);
+ vm_size_t seg_size = round_page(scp->vmsize);
+ vm_offset_t map_offset = scp->fileoff;
+ vm_size_t delta_size;
+ vm_offset_t addr;
+ /*
+   Segment sanity checks.
+ */
+ /* is the command right? */
+ if (scp->cmdsize < segment_command_size) {
+   printk(KERN_WARNING "macho_load_segment(%.*s): malformed command", 16, scp->segname);
+   return (LOAD_BADMACHO);
+ }
+ /* is the segment in range? */
+ if (scp->fileoff + scp->filesize < scp->fileoff ||
+   scp->fileoff + scp->filesize > (uint64_t)file_size) {
+   printk(KERN_WARNING "macho_load_segment(%.*s): out of range", 16, scp->segname);
+   return (LOAD_BADMACHO);
+ }
+ /* is page aligned? */
+ if ((scp->fileoff & (PAGE_SIZE-1)) != 0) {
+   printk(KERN_WARNING "macho_load_segment(%.*s): not page aligned", 16, scp->segname);
+   return (LOAD_BADMACHO);
+ }
+ 
+ 
+ 
+ /*
+   Print some info about the segment.
+ */
+ if (_verboseLog)
+   printk(KERN_WARNING "macho_load_segment(%.*s): addr %d, filesize %d, vmsize %d\n",
+       16,
+       scp->segname,
+       map_addr,
+       map_size,
+       seg_size);
+ 
+ /*
+ do_mmap(struct file *file,
+     unsigned long addr,
+     unsigned long len,
+     unsigned long prot,
+     unsigned long flag,
+     unsigned long offset)
+ */
+ 
+ /* Actually map in the segment into the correct location.
+  */
+ if (map_size > 0) {
+   /* There is something from the file to map */
+   
+   addr = PAGE_ALIGN(map_addr + slide);
+   
+   if (_verboseLog)
+     printk(KERN_WARNING "macho_load_segment(%.*s): seg mmap @ %d, offset %d \n",
+         16,
+         scp->segname,
+         addr,
+         map_offset);
+   
+   /* lock */
+   down_write(&current->mm->mmap_sem);
+   void* mapped =    
+   do_mmap(bprm->file,
+       addr,
+       map_size,
+       PROT_WRITE | PROT_READ | PROT_EXEC,
+       MAP_PRIVATE | MAP_FIXED,
+       map_offset);
+   /* unlock */
+   up_write(&current->mm->mmap_sem);
+   
+   if (strncmp(scp->segname, SEG_TEXT, 16) == 0) {
+     /*
+       This is a text segment, check if it's mapped from zero and then
+       bump up the first_text variable to make sure it points to its start.
+     */
+     if (map_offset == 0) {
+       if (_verboseLog)
+         printk(KERN_WARNING "macho_load_segment(%.*s): this is the base segment \n", 16, scp->segname);
+       
+       *first_text = (void*)(addr);
+     }
+   }
+   
+   if ((mapped) <= 0) {
+     printk(KERN_WARNING "macho_load_segment(%.*s): map file seg failed \n", 16, scp->segname);
+     ret = LOAD_RESOURCE;
+     goto out;
+   }
+   else {
+     if (_verboseLog)
+       printk(KERN_WARNING "macho_load_segment(%.*s): mapped in @ %d \n", 16, scp->segname, (void*)mapped);
+   }
+   
+   /*
+    *  If the file didn't end on a page boundary,
+    *  we need to zero the leftover.
+    */
+   delta_size = map_size - scp->filesize;
+   if (delta_size > 0) {
+     if (_verboseLog)
+       printk(KERN_WARNING "macho_load_segment(%.*s): fixxuuup \n", 16, scp->segname); 
+   }
+ }
+ 
+ /*  If the virtual size of the segment is greater
+  *  than the size from the file, we need to allocate
+  *  anonymous zero fill memory for the rest. 
+  */
+ delta_size = seg_size - map_size;
+ if (delta_size > 0) {
+   addr = PAGE_ALIGN(map_addr + map_size + slide);
+   
+   if (_verboseLog)
+     printk(KERN_WARNING "macho_load_segment(%.*s): mmap @ %d, size: %d\n", 16, scp->segname, addr, delta_size);
+   
+   /* lock */
+   down_write(&current->mm->mmap_sem);
+   void* mapped =    
+   do_mmap(NULL,
+       addr,
+       delta_size,
+       PROT_WRITE | PROT_READ | PROT_EXEC,
+       MAP_FIXED | MAP_PRIVATE,
+       0);
+   /* unlock */
+   up_write(&current->mm->mmap_sem);
+   
+   if ((mapped) <= 0) {
+     printk(KERN_WARNING "macho_load_segment(%.*s): map anon failed \n", 16, scp->segname);
+     ret = LOAD_RESOURCE;
+     goto out;
+   }
+   else {
+     if (_verboseLog)
+       printk(KERN_WARNING "macho_load_segment(%.*s): anon chunk mapped in @%p \n", 16, scp->segname, (void*)mapped);
+   }
+ }
+ 
+ if (*top < (map_addr + slide + seg_size)) {
+   /* highest address so far, update the top variable */
+   *top = ((map_addr + slide + seg_size));
+ }
+ 
+ /* mapped in successfully */
+ ret = LOAD_SUCCESS;
+ 
+out:   
+ return ret;
+}
+
+static int macho_get_file_size(struct file* file) {
+ /* file size from struct file */
+ 
+ /* sanity checks */
+ if (!file)
+   return -1;
+ if (!file->f_path.dentry)
+   return -1;
+ if (!file->f_path.dentry->d_inode) 
+   return -1;
+   
+ return file->f_path.dentry->d_inode->i_size;
+}
+
+static int macho_validate_image(struct file* file, macho_header* head) 
+{
+ /*
+   Sanity checks.
+ */
+ int retval = -ENOEXEC;
+ int file_size = 0;
+ size_t macho_header_sz = sizeof(macho_header);
+ 
+ if (head->magic != MH_MAGIC) {
+   printk(KERN_WARNING "macho_validate_image: binary is not a macho binary (magic: 0x%p) \n", (void*)head->magic);
+   retval = -ENOEXEC;
+   goto out_ret;
+ }
+ 
+ /*
+   Validate architecture.
+ */
+ if (head->cputype != CPU_TYPE_ARM) {
+   printk(KERN_WARNING "macho_validate_image: wrong architecture in the executable\n");
+   retval = -EINVAL;
+   goto out_ret;
+ }
+ 
+ /*
+  * Run ARM-specific validation checks
+  */
+ if (head->cputype == CPU_TYPE_ARM) {
+   if (head->cpusubtype == CPU_SUBTYPE_ARM_V7)
+   {
+     if (cpu_architecture() != CPU_ARCH_ARMv7) {
+       printk(KERN_WARNING "macho_validate_image: armv7 executables are not supported by the current platform\n");
+       retval = -EINVAL;
+       goto out_ret;
+     }
+   }
+   else if (head->cpusubtype == CPU_SUBTYPE_ARM_V6 || head->cpusubtype == 0)
+   {
+     if (cpu_architecture() != CPU_ARCH_ARMv6 && cpu_architecture() != CPU_ARCH_ARMv7) {
+       printk(KERN_WARNING "macho_validate_image: armv6 executables are not supported by the current platform\n");
+       retval = -EINVAL;
+       goto out_ret;
+     }
+   }
+   else {
+     printk(KERN_WARNING "macho_validate_image: unrecognized arm version in the executable (%d)\n", head->cpusubtype);
+     retval = -EINVAL;
+     goto out_ret;
+   }
+ }
+ 
+ 
+ /*
+   Make sure the file size can be retrieved in order 
+     to perform sanity checks on the file.
+  */
+ file_size = macho_get_file_size(file);
+ if (file_size < 0) {
+   printk(KERN_WARNING "macho_validate_image: can't retrieve binary size \n");
+   retval = -EINVAL;
+   goto out_ret;
+ }
+ 
+ /*
+   Main portion of the sanity checks for the macho file.
+ */
+ 
+ retval = -EINVAL;
+ /* can we map it? */
+ if (!file->f_op||!file->f_op->mmap) {
+   printk(KERN_WARNING "macho_validate_image: binary file can't be mapped in \n");
+   goto out_ret;
+ }
+ /* sane lc size? */
+ if ((off_t)(macho_header_sz + head->sizeofcmds) > file_size) {
+   printk(KERN_WARNING "macho_validate_image: malformed load commands size \n");
+   goto out_ret;
+ }
+ if (head->filetype != MH_EXECUTE) {
+   printk(KERN_WARNING "IGN:macho_validate_image: macho file is not executable \n");
+   //goto out_ret;
+ }
+ 
+ /* Print some info about the macho file */
+ if (_verboseLog)
+   printk(KERN_WARNING "macho_validate_image: valid macho file: \n\tmagic: 0x%p \n\tsize: %d\n",
+       (void*)head->magic,
+       file_size);
+ 
+ retval = 0;
+ 
+out_ret: 
+ return retval;
+}
+
+static int macho_load_dylinker(struct file* file, /* file for the dylinker*/
+               int* top_data, /* top of image data */
+               void** first_text,
+               void** entry_point) /* first text segment of the linker */
+               
+{
+ /* fake bprm for the segment loader*/
+ struct linux_binprm bprm;
+ 
+ int retval;
+ int load_addr = *top_data;
+ size_t macho_header_sz = sizeof(macho_header);
+ macho_header* head = kmalloc(macho_header_sz, GFP_KERNEL);
+ int file_size = 0;
+
+ /* this is for LC loader */
+ int ret = 0;
+ size_t offset;
+ size_t oldoffset;
+ uint32_t ncmds;
+ uint8_t* addr;
+ 
+ if (_verboseLog)
+   printk(KERN_WARNING "macho_load_dylinker: loading dynamic linker @ %d\n", load_addr);
+
+ /*
+   Read in the macho header.
+ */
+ kernel_read(file, 0, head, macho_header_sz);
+
+ retval = macho_validate_image(file, head);
+ if (retval) {
+   retval = LOAD_BADMACHO;
+   printk(KERN_WARNING "macho_load_dylinker: dylinker image failed sanity checks, not loading \n");
+   goto out_ret;
+ }
+ 
+ /*
+   XXX: this should be retrieved by macho_validate_image()
+ */
+ file_size = macho_get_file_size(file);
+ 
+ /*
+   Read the load commands from the file.
+ */
+ offset = 0;
+ ncmds = head->ncmds;
+ addr = kmalloc(head->sizeofcmds, GFP_KERNEL); /***/
+ retval = -EINVAL;
+ 
+ /* read in load commands */
+ kernel_read(file, macho_header_sz, addr, head->sizeofcmds);
+ 
+ bprm.file = file;
+ 
+ while (ncmds--) {
+   /* LC pointer */
+   struct load_command *lcp = 
+   (struct load_command *)(addr + offset);
+   
+   oldoffset = offset;
+   offset += lcp->cmdsize;
+   
+   if (oldoffset > offset ||
+       lcp->cmdsize < sizeof(struct load_command) ||
+       offset > head->sizeofcmds + macho_header_sz)
+   {
+     printk(KERN_WARNING "macho_load_dylinker: malformed binary - lc overflow \n");
+     goto lc_ret;
+   }
+   
+   /*  Parse load commands.
+    
+     We only need a bare minimum to get the image up an running. Dyld will
+     take care of all the other stuff.
+    */
+   switch(lcp->cmd) {
+     case LC_SEGMENT:
+     {
+       /*
+         Load and slide a dylinker segment.
+       */
+       ret = macho_load_segment(&bprm,
+                 file_size,
+                 (struct segment_command*)lcp,
+                 top_data, /* keep bumping the same top_data */
+                 first_text, /* first text segment */
+                 load_addr); /* slide up */
+       
+       if (ret != LOAD_SUCCESS) {
+         printk(KERN_WARNING "macho_load_dylinker: segment loading failure \n");
+         goto lc_ret;
+       }
+       break;
+     }
+     case LC_UNIXTHREAD:
+     {
+       ret = macho_load_unix_thread(&bprm,
+                   file_size,
+                   (struct arm_thread_command*)lcp,
+                   entry_point);
+                   
+       if (ret != LOAD_SUCCESS) {
+         printk(KERN_WARNING "macho_load_dylinker: unix thread loading failure \n");
+         goto lc_ret;
+       }
+       break;
+     }
+     default: 
+     {
+       if (_verboseLog)
+         printk(KERN_WARNING "macho_load_dylinker: unsupported lc 0x%p \n", (void*)lcp->cmd);
+       
+       break;
+     }
+   }
+ }
+
+
+ /* loaded successfully */
+ retval = LOAD_SUCCESS;
+ 
+ /* free resources */
+ lc_ret:
+   kfree(addr);
+ 
+ out_ret:  
+   kfree(head);
+   return retval;
+}
+
+static struct page* dpages[1] = {NULL};
+
+static void wire_weird_pages(void)
+{
+ int ret;
+ void* addr;
+
+ /* 0x80000000 */
+ if (dpages[0] == NULL)
+ {
+   dpages[0] = alloc_pages(GFP_KERNEL, 0);
+ }
+
+
+ down_write(&current->mm->mmap_sem);
+ ret = 
+ install_special_mapping(current->mm,
+   0x80000000,
+   PAGE_SIZE,
+   VM_READ | VM_WRITE | VM_SHARED | VM_DONTCOPY,
+   dpages);
+ up_write(&current->mm->mmap_sem);
+
+ addr = page_address(dpages[0]);
+
+ memset(addr, 'w', PAGE_SIZE);
+
+ printk("wired weird page! (%p, %d, %p)\n", dpages[0], ret, addr);
+}
+
+static void macho_setup_link_table(void)
+{
+ void* mapped = LINK_TABLE_ADDR;
+ size_t sz = LINK_TABLE_SIZE;
+ linker_image_table_header_t* th;
+
+ down_write(&current->mm->mmap_sem);
+
+ mapped =    
+ do_mmap(NULL,
+     mapped,
+     sz,
+     PROT_WRITE | PROT_READ,
+     MAP_FIXED | MAP_PRIVATE,
+     0);
+
+ up_write(&current->mm->mmap_sem);
+
+ th = (linker_image_table_header_t*)mapped;
+
+ __put_user((uint32_t)2, &th->entry_count);
+ __put_user((size_t)sz, &th->table_size);
+ 
+ printk("mapped link table @ %p\n", mapped);
+}
+
+static int load_macho_binary(struct linux_binprm *bprm, struct pt_regs *regs)
+{ 
+ unsigned long def_flags = 0;
+ void* entry_point = 0;
+ int retval = -ENOEXEC;
+ int file_size = 0;
+ int executable_stack = EXSTACK_DEFAULT;
+ size_t macho_header_sz = sizeof(macho_header);
+ macho_header* head = ((macho_header*)bprm->buf);
+ struct file *linker_file = NULL;
+ int dylinker_load_addr;
+
+ size_t offset;
+ size_t oldoffset;
+ uint32_t ncmds;
+ uint8_t* addr;
+
+ int ret = 0;
+ 
+ /* Top of the image data. This is needed to position the heap. */
+ int top_data = 0;
+ 
+ /* First text segment where the mach header is. */
+ void* first_text = 0;
+ void* first_text_linker = 0;
+
+ /* Stack environment (grows down on ARM). */
+ uint32_t* stack = bprm->p;
+ uint32_t* argv_array;
+ uint32_t* argv;
+ uint32_t* envp_array;
+ uint32_t* envp;
+ uint32_t total_argv_size;
+ uint32_t total_env_size;
+
+ /* Arg stuff */
+ uint32_t argc;
+ uint32_t envc;
+ char* p;
+
+ linker_image_entry_t* ee;
+
+ /* have we got enough space? */
+ if (!head) {
+   retval = -ENOMEM;
+   goto out_ret;
+ }
+ 
+ retval = macho_validate_image(bprm->file, head);
+ if (retval) {
+   printk(KERN_WARNING "load_macho_binary: image failed sanity checks, not loading \n");
+   goto out_ret;
+ }
+ 
+ /*
+   XXX: this should be retrieved by macho_validate_image()
+ */
+ file_size = macho_get_file_size(bprm->file);
+ 
+ /*
+   The file seems to be alright, so set up an environment for the 
+   new binary to run in. After this, the old image will no longer be 
+   usable. If some of the load commands are broken, this process is doomed.
+ */
+ retval = flush_old_exec(bprm);
+ if (retval) {
+   panic("load_macho_binary: flush_old_exec failed\n");
+ }
+ else {
+   unsigned int personality;
+
+   current->flags &= ~PF_FORKNOEXEC;
+   current->mm->def_flags = def_flags;
+   
+   setup_new_exec(bprm);
+   
+   /* set personality */
+   personality = current->personality & ~PER_MASK;
+   personality |= PER_LINUX;
+   
+   /*
+     This flag has to be set for 32x architectures (I think).
+   */
+   personality |= ADDR_LIMIT_32BIT;
+   
+   set_personality(personality);
+
+   /* set stuff */
+   current->mm->free_area_cache = current->mm->mmap_base;
+   current->mm->cached_hole_size = 0;
+   //retval = setup_arg_pages(bprm, randomize_stack_top(STACK_TOP), executable_stack);
+         
+   if (retval < 0) {
+     //send_sig(SIGKILL, current, 0);
+     //goto out_ret;
+   }
+   
+   /* stack */
+   current->mm->start_stack = bprm->p;
+ }
+ 
+ 
+ /*
+   Read the load commands from the file.
+ */
+ offset = 0;
+ ncmds = head->ncmds;
+ addr = kmalloc(head->sizeofcmds, GFP_KERNEL); /***/
+ retval = -EINVAL;
+ 
+ /* read in load commands */
+ kernel_read(bprm->file, macho_header_sz, addr, head->sizeofcmds);
+ 
+ while (ncmds--) {
+   /* LC pointer */
+   struct load_command *lcp = 
+   (struct load_command *)(addr + offset);
+   
+   oldoffset = offset;
+   offset += lcp->cmdsize;
+   
+   if (oldoffset > offset ||
+       lcp->cmdsize < sizeof(struct load_command) ||
+       offset > head->sizeofcmds + macho_header_sz)
+   {
+     printk(KERN_WARNING "load_macho_binary: malformed binary - lc overflow \n");
+     goto lc_ret;
+   }
+   
+   /*  Parse load commands.
+    
+     We only need a bare minimum to get the image up an running. Dyld will
+     take care of all the other stuff.
+    */
+   switch(lcp->cmd) {
+     case LC_SEGMENT:
+       ret = macho_load_segment(bprm, file_size, (struct segment_command*)lcp, &top_data, &first_text, 0);
+       if (ret != LOAD_SUCCESS) {
+         printk(KERN_WARNING "load_macho_binary: segment loading failure \n");
+         goto lc_ret;
+       }
+       break;
+     case LC_LOAD_DYLINKER:
+       ret = macho_get_dylinker(bprm, file_size, (struct dylinker_command*)lcp, &linker_file);
+       if (ret != LOAD_SUCCESS) {
+         printk(KERN_WARNING "load_macho_binary: dylinker loading failure \n");
+         goto lc_ret;
+       }
+       else {
+         /* done */
+       }
+       break;
+     case LC_UNIXTHREAD:
+       ret = macho_load_unix_thread(bprm, file_size, (struct arm_thread_command*)lcp, &entry_point);
+       if (ret != LOAD_SUCCESS) {
+         printk(KERN_WARNING "load_macho_binary: unix thread loading failure \n");
+         goto lc_ret;
+       }
+       break;
+     default: 
+       if (_verboseLog)
+         printk(KERN_WARNING "load_macho_binary: unsupported lc 0x%p \n", (void*)lcp->cmd);
+
+       break;
+   }
+ }
+ 
+ /*
+   Bootstrap the dynamic linker if needed.
+ */
+ if (linker_file) {
+   dylinker_load_addr = top_data;
+   
+   macho_load_dylinker(linker_file,
+             &top_data,
+             &first_text_linker,
+             &entry_point);
+   
+   /* slide the entry point */
+   entry_point = entry_point + dylinker_load_addr;
+     
+   if (_verboseLog)        
+     printk(KERN_WARNING "load_macho_binary: dylinker's first text segment @ %d, new pc @ %d \n",
+         first_text_linker,
+         (int)entry_point);
+ }
+ 
+ /*
+   Now, I don't know what these are used for, but I'm fairly sure
+   they're *very* important. So let's set them up. 
+   
+   See 'linux/mm_types.h':
+   unsigned long start_code, end_code, start_data, end_data;
+   unsigned long start_brk, brk, start_stack;
+ */  
+ current->mm->start_code = 0; /* IMP */
+ current->mm->end_code = top_data; /* IMP */
+ current->mm->start_data = 0;
+ current->mm->end_data = top_data;
+   
+ if (_verboseLog)
+   printk(KERN_WARNING "load_macho_binary: setting up heap ...\n");
+
+ /* Set up an empty heap. This will be grown as more memory is allocated.  */
+ int brkret = ml_setBrk(top_data, top_data);
+
+ if (_verboseLog)
+   printk(KERN_WARNING "load_macho_binary: setting up misc ...\n");
+
+ /* setup misc stuff */
+ set_binfmt(&macho_format);
+ install_exec_creds(bprm);
+
+ /* Construct envp array. */
+ envp = envp_array = stack = (uint32_t*)stack - ((bprm->envc+1));
+
+ /* Construct argv array. */
+ argv = argv_array = stack = (uint32_t*)stack - ((bprm->argc+1));
+
+ if (_verboseLog)
+   printk(KERN_WARNING "load_macho_binary: setting up stack @ %p ...\n", (uint32_t*)stack);
+
+ argc = bprm->argc;
+ envc = bprm->envc;
+ p = bprm->p;
+
+ /* Set up argv pointers */
+ current->mm->arg_start = (unsigned long)p;
+ while(argc--) {
+   char c;
+
+   put_user(p,argv++);
+   do {
+     get_user(c,p++);
+   } while (c);
+ }
+ put_user(NULL,argv);
+
+ /* Set up envp pointers */
+ current->mm->arg_end = current->mm->env_start = (unsigned long) p;
+ while(envc--) {
+   char c;
+
+   put_user(p,envp++);
+   do {
+     get_user(c,p++);
+   } while (c);
+ }
+ put_user(NULL,envp);
+ current->mm->env_end = (unsigned long) p;
+
+ /*
+   The actual stuff passed to the linker goes here.
+ */
+ stack = (uint32_t*)stack - (4);
+
+ stack[0] = (uint32_t)first_text; /* mach_header */
+ stack[1] = bprm->argc; /* argc */
+ stack[2] = argv_array; /* argv */
+ stack[3] = (uint32_t)first_text_linker; /* linker's mach_header */
+ 
+ if (_verboseLog)
+   printk(KERN_WARNING "load_macho_binary: setting up main thread ...\n"); 
+ 
+ /*
+   Set up the main thread
+ */
+ if (BAD_ADDR(entry_point)) {
+   /* entry point is not executable */
+   
+   printk(KERN_WARNING "load_macho_binary: bad entry point \n");
+   force_sig(SIGSEGV, current);
+   retval = -EINVAL;
+   goto lc_ret;
+ }
+ 
+ if (_verboseLog)
+   printk(KERN_WARNING "load_macho_binary: setting up registers ...\n");
+
+ /* 
+   See 'start_thread' in 'processor.h'
+   'start_thread' provides an ELF implementation of this function.
+   This is for the Darwin ABI implementation which is used by iPhoneOS binaries.
+ */
+ unsigned long initial_pc = (unsigned long)entry_point;  
+ 
+ /* exit supervisor and enter user */
+ set_fs(USER_DS);
+ memset(regs->uregs, 0, sizeof(regs->uregs));
+ regs->ARM_cpsr = USR_MODE;  
+
+ /* If the entry point is THUMB, set the thumb bit */
+ if (initial_pc & 1)
+   regs->ARM_cpsr |= PSR_T_BIT;
+   
+ /* set up control regs */ 
+ regs->ARM_cpsr |= PSR_ENDSTATE; 
+ regs->ARM_pc = initial_pc & ~1;   /* pc */
+ regs->ARM_sp = stack;   /* sp */
+
+ /* This is actually ignored, but set it anyway */
+ regs->ARM_r2 = stack[2];  /* r2 (envp) */ 
+ regs->ARM_r1 = stack[1];  /* r1 (argv) */
+ regs->ARM_r0 = stack[0];  /* r0 (argc) */ 
+ 
+ /* ABI */
+ regs->ARM_r7 = stack; /* FP */
+
+ /* this will work for mmu and nonmmu */
+ nommu_start_thread(regs);
+ 
+ wire_weird_pages(); 
+ macho_setup_link_table();
+
+ ee = (linker_image_entry_t*)(((char*)LINK_TABLE_ADDR) + sizeof(linker_image_entry_t));
+
+ /* main image */
+ __put_user(0, &ee->load_addr);
+ __put_user(dylinker_load_addr, &ee->size);
+
+ ee += 1;
+
+ __put_user(dylinker_load_addr, &ee->load_addr);
+ __put_user((uint32_t)top_data - (uint32_t)dylinker_load_addr, &ee->size);
+
+ /*
+   Binary is now loaded. Return 0 to signify success.
+ */
+ retval = 0;
+
+ if (_verboseLog)
+   printk(KERN_WARNING "load_macho_binary: complete, heap starts at %d, brkret %d \n", top_data, brkret);
+
+ /*
+   Teardown
+ */
+ lc_ret:
+   kfree(addr);
+ out_ret:
+   return retval;
+}
+
+#define MAX_UNWIND 20
+
+/*
+ * Because there isn't a better word to describe it.
+ */
+static int fucking_core_dumper(struct coredump_params *cprm)
+{
+ linker_image_table_header_t* tb = (linker_image_table_header_t*)LINK_TABLE_ADDR;
+ linker_image_entry_t* ee;
+ uint32_t count;
+ int i;
+ const char* pc_lib;
+ uint32_t* fp; /* frame pointer */
+ uint32_t call_stack[MAX_UNWIND];
+ uint32_t spos = 0;
+
+ printk(KERN_WARNING "----- Core Dump -----\n");
+
+ printk(KERN_WARNING "PID: %d\n", current->pid);
+
+ printk(KERN_WARNING "Received Signal: %ld\n", cprm->signr);
+
+ printk(KERN_WARNING "Register Dump:\n"
+ "\tpc @ %p (%d), sp @ %p \n"
+ "\tr0 @ %p, r1 @ %p, r2 @ %p, r3 @ %p, r4 @ %p \n"
+ "\tr5 @ %p, r6 @ %p, r7 @ %p, r8 @ %p, r9 @ %p \n"
+ "\tr10 @ %p, lr @ %p, cpsr @ %p (thumb: %d)\n",
+ (void*)cprm->regs->ARM_pc,
+ (int)cprm->regs->ARM_pc,
+ (void*)cprm->regs->ARM_sp,
+ (void*)cprm->regs->ARM_r0,
+ (void*)cprm->regs->ARM_r1,
+ (void*)cprm->regs->ARM_r2,
+ (void*)cprm->regs->ARM_r3,
+ (void*)cprm->regs->ARM_r4,
+ (void*)cprm->regs->ARM_r5,
+ (void*)cprm->regs->ARM_r6,
+ (void*)cprm->regs->ARM_r7,
+ (void*)cprm->regs->ARM_r8,
+ (void*)cprm->regs->ARM_r9,
+ (void*)cprm->regs->ARM_r10,
+ (void*)cprm->regs->ARM_lr,
+ (void*)cprm->regs->ARM_cpsr,
+ (int)(cprm->regs->ARM_cpsr & PSR_T_BIT));
+ 
+ printk(KERN_WARNING "----- Call Stack -----\n");
+
+ /* unwind darwin stack */
+ fp = (uint32_t*)cprm->regs->ARM_r7;
+ while (spos < MAX_UNWIND)
+ {
+   uint32_t* new_fp;
+
+   /* Get saved LR and R7 */
+
+   if (get_user(call_stack[spos], &fp[1])) {
+     printk("\t*** Unwinding failed 0 (memory error @ %p)\n", &fp[1]);
+     break;
+   }
+
+   if (get_user(new_fp, &fp[0])) {
+     printk("\t*** Unwinding failed 1 (memory error @ %p)\n", &fp[0]);
+     break;
+   }
+
+   printk("\t%d: lr:%p r7:%p\n", spos, call_stack[spos], new_fp);
+
+   fp = new_fp;
+   spos++;
+ }
+
+ /* walk link table */
+ if (get_user(count, &tb->entry_count)) {
+   printk(" *** Unable to access link table in user memory!\n");
+   return 0;
+ }
+
+ ee = (linker_image_entry_t*)(((char*)tb) + sizeof(linker_image_entry_t));
+
+ printk(KERN_WARNING "----- Loaded Images -----\n");
+
+ if ((sizeof(linker_image_entry_t) * count) > LINK_TABLE_SIZE)
+ {
+   printk(" *** Link table corrupt!\n");
+ }
+ else
+ {
+   for (i = 0; i < count; i++)
+   {
+     int ii;
+     size_t sl;
+     const char* lname;
+     size_t image_size;
+     uintptr_t load_addr;
+     uint32_t loc = (uint32_t)cprm->regs->ARM_pc;
+     uint32_t lrr = (uint32_t)cprm->regs->ARM_lr;
+
+     linker_image_entry_t* t = &(ee[i]);
+
+     if (i > 1)
+     {
+       sl = strlen_user(t->name);
+
+       if (sl == 0)
+       {
+         lname = "<unknown>";
+       }
+       else
+       {
+         lname = (const char*)kmalloc(sl, GFP_KERNEL);
+         __copy_from_user(lname, t->name, sl);
+       }
+     }
+     else if (i == 0)
+     {
+       lname = "<main_image>";
+     }
+     else /*(i == 1)*/
+     {
+       lname = "<linker>";
+     }
+
+     __get_user(image_size, &t->size);
+     __get_user(load_addr, &t->load_addr);
+
+     printk("\t%s {%d - %d}\n", lname, load_addr, (uint32_t)load_addr + (uint32_t)image_size);
+
+     if (loc > load_addr && ((uint32_t)load_addr + (uint32_t)image_size) > loc)
+     {
+       uint32_t rel_pc = loc - (uint32_t)load_addr;
+
+       /* pc is in range */
+       printk("\t\t > [PC] in image @ %p (%d), abs: %p\n", (void*)rel_pc, rel_pc, (void*)loc);
+     }
+
+     if (lrr > load_addr && ((uint32_t)load_addr + (uint32_t)image_size) > lrr)
+     {
+       uint32_t rel_lr = lrr - (uint32_t)load_addr;
+
+       /* lr is in range */
+       printk("\t\t > [LR] in image @ %p (%d), abs: %p\n", (void*)rel_lr, rel_lr, (void*)lrr);
+     }
+
+     for (ii = 0; ii < spos; ii++)
+     {
+       uint32_t stack_pos = call_stack[ii];
+       if (stack_pos > load_addr && ((uint32_t)load_addr + (uint32_t)image_size) > stack_pos)
+       {
+         uint32_t rel_sp = stack_pos - (uint32_t)load_addr;
+
+         /* lr is in range */
+         printk("\t\t > [SP: %d] in image @ %p (%d), abs: %p\n", ii, (void*)rel_sp, rel_sp, (void*)stack_pos);
+       }
+     }
+   }
+ }
+
+ return 0;
+}
+
+static int load_macho_library(struct file *file)
+{
+ panic("load_macho_library: not implemented.");
+}
+
+int __init init_macho_binfmt(void)
+{
+ printk(KERN_WARNING "init_macho_binfmt: MachO binary loader initialized! (load: %p) \n", load_macho_binary);
+ 
+ return register_binfmt(&macho_format);
+}
diff -Naur ./old//magenta/mach_port_types.h ./kern//magenta/mach_port_types.h
--- ./old//magenta/mach_port_types.h  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/mach_port_types.h 2012-08-05 18:16:24.000000000 -0400
@@ -0,0 +1,274 @@
+#ifndef _H_MG_MACH_PORT_TYPES_
+#define _H_MG_MACH_PORT_TYPES_
+
+#include <linux/kernel.h>
+#include <linux/kfifo.h>
+#include <linux/list.h>
+#include <linux/idr.h>
+#include <linux/wait.h>
+
+#include <DarwinTypes.h>
+#include <MachO.h>
+
+#include "kern_return.h"
+#include "ke_runtime.h"
+
+#define FALSE 0
+#define TRUE 1
+
+#define MAX_PORT_COUNT 4096
+
+typedef int  clock_res_t;
+struct mach_timespec {
+ unsigned int  tv_sec;     /* seconds */
+ clock_res_t   tv_nsec;    /* nanoseconds */
+};
+typedef struct mach_timespec mach_timespec_t;
+
+typedef unsigned int natural_t;
+typedef int integer_t;
+typedef int boolean_t;
+
+typedef natural_t mach_port_t;
+typedef natural_t mach_port_right_t;
+typedef int mach_port_delta_t;
+
+typedef mach_port_t mach_port_name_t;
+
+typedef int kern_return_t;
+
+typedef unsigned int mach_msg_type_name_t;
+
+#define MACH_MSG_TYPE_MOVE_RECEIVE 16  /* Must hold receive rights */
+#define MACH_MSG_TYPE_MOVE_SEND    17  /* Must hold send rights */
+#define MACH_MSG_TYPE_MOVE_SEND_ONCE 18  /* Must hold sendonce rights */
+#define MACH_MSG_TYPE_COPY_SEND    19  /* Must hold send rights */
+#define MACH_MSG_TYPE_MAKE_SEND    20  /* Must hold receive rights */
+#define MACH_MSG_TYPE_MAKE_SEND_ONCE 21  /* Must hold receive rights */
+#define MACH_MSG_TYPE_COPY_RECEIVE 22  /* Must hold receive rights */
+
+
+#define MACH_PORT_RIGHT_SEND            ((mach_port_right_t) 0)
+#define MACH_PORT_RIGHT_RECEIVE         ((mach_port_right_t) 1)
+#define MACH_PORT_RIGHT_SEND_ONCE       ((mach_port_right_t) 2)
+#define MACH_PORT_RIGHT_PORT_SET        ((mach_port_right_t) 3)
+#define MACH_PORT_RIGHT_DEAD_NAME       ((mach_port_right_t) 4)
+#define MACH_PORT_RIGHT_NUMBER          ((mach_port_right_t) 5)
+
+#define KE_PORT_TYPE_FREE 0
+#define KE_PORT_TYPE_TASK 1
+#define KE_PORT_TYPE_IPC 2
+#define KE_PORT_TYPE_PORT_SET 3
+#define KE_PORT_TYPE_HOST 4
+#define KE_PORT_TYPE_THREAD 5
+#define KE_PORT_TYPE_SEMAPHORE 6
+
+#define KE_PORT_TYPE_ANY 100
+
+typedef enum {
+    kMachPortRightSend = 0x1,
+    kMachPortRightReceive = 0x2,
+    kMachPortRightSendOnce = 0x4,
+    /* 0x8, 0x10, 0x20, 0x40,*/
+    kMachPortRightKernel = 0x80,
+} ke_right_type_t;
+
+struct __Task;
+struct __Obj;
+
+typedef struct
+{
+ struct __Task* task;
+
+ void* rcv_buffer;
+ size_t rcv_size;
+ boolean_t rcv_user;
+ 
+ struct __Obj* snd_reply;
+ void* snd_msg;
+ size_t snd_size;
+
+ int options;
+ 
+} ipc_trap_data_t;
+
+typedef struct __ke_port_ops_t
+{
+ /*
+  * obsolete
+  */
+ kern_return_t (*msg_handler)(void* payload, void* trap_data);
+
+ /*
+  * New operations. NULL if not supported.
+  */
+ kern_return_t (*msg_send)(struct __Obj* port, ipc_trap_data_t* info);
+ kern_return_t (*msg_receive)(struct __Obj* port, ipc_trap_data_t* info);
+} ke_port_ops_t;
+
+/* This must be at the top of each port object type */
+typedef struct __Obj
+{
+ uint16_t type; /* port type */
+ atomic_t refs; /* refcount */
+ struct mutex mtx; /* general lock */
+ boolean_t active; /* can it be retrieved from a right? */
+
+ ke_port_ops_t* ops; /* operations */
+} Obj;
+
+#define ke_port_t Obj
+
+typedef struct 
+{
+ ke_port_t port; /***/
+
+ struct task_struct *task; /* task which owns the port */
+ 
+ struct completion wait_for_enqueued_data;
+ wait_queue_head_t wait_queue; /* wait queue */
+ struct kfifo queue; /* msg queue */
+
+ ke_array_t wait_list;
+ spinlock_t wait_list_lock;
+
+ boolean_t dead;
+ boolean_t allocated; 
+
+ /* mk_timer */
+ struct timer_list ktimer;
+} ipc_port;
+
+typedef struct 
+{
+ ke_port_t port; /***/
+
+ wait_queue_head_t wait_queue;
+
+ ke_array_t port_list;
+ spinlock_t port_list_lock;
+
+ unsigned int last_iter;
+} ipc_port_set;
+
+typedef struct
+{
+ ke_port_t* port;
+ mach_port_t name; /* port name */
+ int urefs;
+
+ atomic_t r_receive;
+ atomic_t r_send;
+ atomic_t r_send_once;
+ atomic_t r_port_set;
+
+ atomic_t r_kernel;
+
+ struct list_head list;
+} ke_port_right_t;
+
+typedef struct
+{
+ ke_port_t port;
+} host_port_t;
+
+/*
+ * This structure represents a task port as well
+ * the task's IPC space and other stuff.
+ */
+typedef struct __Task
+{
+ ke_port_t port;
+
+ struct task_struct *task; /* task which owns the port */
+
+ struct idr name_pool;
+ struct list_head port_rights; /* list of port rights for this task */
+
+ atomic_t thread_count;
+} task_port_t;
+
+
+typedef struct
+{
+ ke_port_t port;
+
+ struct task_struct *task; /* task which owns the port */
+
+ atomic_t suspend_count;
+ boolean_t new_task;
+ boolean_t exiting;
+ boolean_t can_cancel;
+ boolean_t frozen;
+} thread_port_t;
+
+typedef struct
+{
+ ke_port_t port;
+} sem_port_t;
+
+task_port_t* Native_get_current_task(void); /* [RetainPort] */
+ke_port_t* Task_find_port(mach_port_t name); /* [RetainPort] */
+ke_port_right_t* Task_find_right(mach_port_t name); /* [RetainPort][RetainRight] */
+task_port_t* Native_get_task(struct task_struct* task); /* [RetainPort] */
+thread_port_t* Native_get_thread(struct task_struct* task); /* [RetainPort] */
+thread_port_t* Native_get_current_thread(void); /* [RetainPort] */
+
+#define ke_get_current_task Native_get_current_task
+#define ke_port_find_named Task_find_port
+#define ke_right_find_named Task_find_right
+#define ke_get_task_port Native_get_task
+#define ke_get_thread_port Native_get_thread
+
+/*
+ * [RetainRight]
+ * fprt must be a valid port. Port is not retained by this.
+ */
+ke_port_right_t* Task_get_right(task_port_t* space, ke_port_t* fprt, boolean_t add); 
+
+#define ke_get_right_in_space Task_get_right
+
+kern_return_t mach_task_port_for_name(mach_port_t user_port, task_port_t** out); /* [RetainPort] */
+kern_return_t Task_get_object_if_send(mach_port_t user_port, Obj** out, uint16_t type); /* [RetainPort] */
+kern_return_t Task_get_object_if_receive(mach_port_t user_port, Obj** out, uint16_t type); /* [RetainPort] */
+
+mach_port_t Task_create_name(task_port_t* space);
+ke_port_right_t* Obj_new(uint16_t type);
+void Task_add_right(task_port_t* space, ke_port_right_t* rr);
+
+#define ke_add_right_to_space Task_add_right
+#define ke_new_port Obj_new
+#define ke_get_new_port_name_in_space Task_create_name
+
+boolean_t Obj_is_active(ke_port_t* port);
+
+typedef task_port_t* ipc_space_t;
+
+int Obj_get_refcount(ke_port_t* port);
+void Obj_release(ke_port_t* port);
+boolean_t Obj_retain(ke_port_t* port);
+
+task_port_t* get_kernel_task(void);
+
+boolean_t __is_port_set_right(ke_port_right_t* right);
+boolean_t __is_receive_right(ke_port_right_t* right);
+boolean_t __is_send_right(ke_port_right_t* right);
+
+#define PortLock(x) mutex_lock(&(((ke_port_t*)x)->mtx))
+#define PortUnlock(x) mutex_unlock(&(((ke_port_t*)x)->mtx))
+
+#define PortRetain(x) Obj_retain((Obj*)x)
+#define PortRelease(x) Obj_release((Obj*)x)
+#define PortGetRefcount(x) Obj_get_refcount((Obj*)x)
+
+#define PortActive(x) Obj_is_active((ke_port_t*)x)
+#define RightIncrementRefCount(x, y) atomic_inc(&(x->y))
+#define RightDecrementRefCount(x, y) atomic_dec(&(x->y))
+#define IsReceiveRight(x) __is_receive_right(x)
+#define IsSendRight(x) __is_send_right(x)
+#define IsPortSetRight(x) __is_port_set_right(x)
+
+void mach_task_inc_thread_count(task_port_t* tport);
+void mach_task_dec_thread_count(task_port_t* tport);
+
+#endif 
diff -Naur ./old//magenta/mach_semaphore.c ./kern//magenta/mach_semaphore.c
--- ./old//magenta/mach_semaphore.c 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/mach_semaphore.c  2012-07-19 11:35:08.000000000 -0400
@@ -0,0 +1,170 @@
+/*
+ * mach_semaphore.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * lol, what's a semaphore?
+ */
+
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+#include <linux/sched.h>
+
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+
+#include "ke_runtime.h"
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+
+kern_return_t sem_message_handle(void* payload, void* trap_data);
+ke_port_ops_t _sem_port_ops = {
+ .msg_handler = sem_message_handle
+};
+
+kern_return_t sem_message_handle(void* payload, void* trap_data__)
+{
+ mach_msg_trap_data_t* trap_data = (mach_msg_trap_data_t*)trap_data__;
+ mach_msg_header_t* msg = (mach_msg_header_t*)payload;
+ kern_return_t retval;
+
+ retval = KERN_FAILURE;
+
+ return retval;
+}
+
+ke_port_right_t* mach_sem_allocate(task_port_t* space)
+{
+ sem_port_t* prt = NULL;
+ ke_port_right_t* rr = NULL;
+
+ rr = ke_new_port(KE_PORT_TYPE_SEMAPHORE);
+ if (!rr || !rr->port) {
+   return NULL;
+ }
+ prt = (sem_port_t*)rr->port;
+
+ /* operations */
+ prt->port.ops = &_sem_port_ops;
+
+ rr->name = ke_get_new_port_name_in_space(space);
+ ke_add_right_to_space(space, rr);
+
+ return rr;
+}
+
+#define xxxxx() panic("mach_sem: %s not impl", __FUNCTION__);
+
+/*
+ * Gets the port if it's valid and we have the send right.
+ */
+kern_return_t mach_sem_get(mach_port_t user_port, sem_port_t** out)
+{
+ ke_port_right_t* name;
+
+ name = ke_right_find_named(user_port);
+ if (!name) {
+   return KERN_INVALID_NAME;
+ }
+ if (!name->port) {
+   RightDecrementRefCount(name, r_kernel);
+   return KERN_FAILURE;
+ }
+
+ if (!IsSendRight(name) || name->port->type != KE_PORT_TYPE_SEMAPHORE)
+ {
+   PortRelease(name->port);
+   RightDecrementRefCount(name, r_kernel);
+   return KERN_INVALID_RIGHT;
+ }
+
+ *out = (sem_port_t*)name->port;
+ RightDecrementRefCount(name, r_kernel);
+
+ return KERN_SUCCESS;
+}
+
+kern_return_t _user_semaphore_create(mach_port_t _task, mach_port_t *semaphore, int policy, int value)
+{
+ task_port_t* task;
+ kern_return_t ret;
+ ke_port_right_t* rcv;
+ ke_port_right_t* snd;
+
+ ret = mach_task_port_for_name(_task, &task);
+ if (ret != KERN_SUCCESS) {
+   return ret;
+ }
+
+ rcv = mach_sem_allocate(get_kernel_task());
+
+ snd = ke_get_right_in_space(task, (ke_port_t*)rcv->port, true);
+
+ RightIncrementRefCount(snd, r_send);
+ RightDecrementRefCount(snd, r_kernel);
+ PortRelease(task);
+
+ __put_user(snd->name, semaphore);
+
+ return KERN_SUCCESS;
+}
+
+kern_return_t _user_semaphore_wait(mach_port_t semaphore)
+{
+ xxxxx();
+}
+
+kern_return_t _user_semaphore_signal(mach_port_t semaphore) 
+{
+ xxxxx();
+}
+
+kern_return_t _user_semaphore_signal_all(mach_port_t semaphore)
+{
+ xxxxx();
+}
+
+kern_return_t _user_semaphore_timedwait(mach_port_t semaphore, mach_timespec_t wait_time)
+{
+ xxxxx();
+}
+
+kern_return_t _user_semaphore_timedwait_signal(mach_port_t wait_semaphore, mach_port_t signal_semaphore, mach_timespec_t wait_time)
+{
+ xxxxx();
+}
+
+kern_return_t _user_semaphore_wait_signal(mach_port_t wait_semaphore, mach_port_t signal_semaphore)
+{
+ xxxxx();
+}
+
+kern_return_t _user_semaphore_signal_thread(mach_port_t semaphore, void* thread)
+{
+ xxxxx();
+}
diff -Naur ./old//magenta/mach_task.c ./kern//magenta/mach_task.c
--- ./old//magenta/mach_task.c  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/mach_task.c 2012-08-06 15:09:10.000000000 -0400
@@ -0,0 +1,1213 @@
+/*
+ * mach_task.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Support for mach tasks, mach threads, their appropriate
+ * ports and bsd threads.
+ */
+
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+#include <linux/sched.h>
+#include <linux/freezer.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+#include <asm/thread_notify.h>
+
+#include "ke_runtime.h"
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+
+#include "VM.h"
+
+/* Thread port ops */
+kern_return_t thread_message_handle(void* payload, void* trap_data);
+ke_port_ops_t _thread_port_ops = {thread_message_handle};
+
+typedef struct {
+ void* start_fn;
+ void* wstart_fn;
+ int thread_size;
+ void* pthread_start_fn;
+ void* workq;
+ uint64_t tsd;
+} bsd_reg_args_t;
+
+typedef struct {
+ void* func;
+ void* func_arg;
+ void* stack;
+ void* thread;
+ unsigned int flags;
+} bsd_crt_args_t;
+
+/* context switch and restoration code */
+asmlinkage void ret_from_fork(void) __asm__("ret_from_fork");
+asmlinkage void Return_to_user_from_swi(void) __asm__("Return_to_user_from_swi");
+
+kern_return_t mach_thread_for_name(mach_port_t user_port, thread_port_t** out)
+{
+ return Task_get_object_if_send(user_port, (Obj**)out, KE_PORT_TYPE_THREAD);
+}
+
+static struct task_struct* Task_get_native(task_port_t* space)
+{
+ struct task_struct* ret;
+
+ ret = space->task;
+ if (ret == NULL) {
+   panic("Task_get_native(): task port %p doesn't have a native task", space);
+ }
+
+ return ret;
+}
+
+static struct task_struct* Thread_get_native(thread_port_t* space)
+{
+ struct task_struct* ret;
+
+ ret = space->task;
+ if (ret == NULL) {
+   panic("Thread_get_native(): thread port %p doesn't have a native task", space);
+ }
+
+ return ret;
+}
+
+#define THREAD_NOTIFY_COPY      3
+
+ke_port_right_t* mach_thread_allocate(task_port_t* space)
+{
+ thread_port_t* prt = NULL;
+ ke_port_right_t* rr = NULL;
+
+ rr = ke_new_port(KE_PORT_TYPE_THREAD);
+ if (!rr || !rr->port) {
+   return NULL;
+ }
+ prt = (thread_port_t*)rr->port;
+
+ /* operations*/
+ prt->port.ops = &_thread_port_ops;
+
+ rr->name = Task_create_name(space);
+ Task_add_right(space, rr);
+
+ return rr;
+}
+
+kern_return_t thread_message_handle(void* payload, void* trap_data__)
+{
+ //mach_msg_trap_data_t* trap_data = (mach_msg_trap_data_t*)trap_data__;
+ //mach_msg_header_t* msg = (mach_msg_header_t*)payload;
+ kern_return_t retval;
+
+ retval = KERN_FAILURE;
+
+ return retval;
+}
+
+kern_return_t mach_task_vm_allocate(task_port_t* port,
+ uintptr_t* addr,
+ size_t size,
+ boolean_t anywhere)
+{
+ struct task_struct* ts = Task_get_native(port);
+ return VM_allocate(ts, addr, size, anywhere);
+}
+
+kern_return_t _user_vm_allocate(mach_port_t task,
+ uintptr_t* addr, /* __user */
+ size_t size,
+ boolean_t anywhere)
+{
+ task_port_t* port;
+ kern_return_t ret;
+ uintptr_t iaddr;
+
+ __get_user(iaddr, addr);
+
+ ret = mach_task_port_for_name(task, &port);
+ if (ret != KERN_SUCCESS) {
+   Xwarn("_user_vm_allocate(): failed with %d", ret);
+   return ret;
+ }
+
+ ret = mach_task_vm_allocate(port, &iaddr, size, anywhere);
+
+ __put_user(iaddr, addr);
+
+ PortRelease(port);
+ return ret;
+}
+
+
+#define PTHREAD_START_CUSTOM 0x01000000
+#define PTHREAD_START_SETSCHED 0x02000000
+#define PTHREAD_START_DETACHED 0x04000000
+
+/*
+long do_fork(unsigned long clone_flags,
+       unsigned long stack_start,
+       struct pt_regs *regs,
+       unsigned long stack_size,
+       int __user *parent_tidptr,
+       int __user *child_tidptr)
+*/
+
+/*
+ We're calling this:
+
+ _pthread_start(pthread_t self,
+   mach_port_t kport,
+   void *(*fun)(void *),
+   void * funarg,
+   size_t stacksize,
+   unsigned int pflags)
+*/
+
+/* called out by 'copy_process_ex' in 'kernel/fork.c' */
+int
+mach_platform_copy_thread(unsigned long clone_flags,
+ unsigned long stack_start,
+ unsigned long stk_sz,
+ struct task_struct *p,
+ struct pt_regs *regs)
+{
+ struct thread_info *thread = task_thread_info(p);
+ struct pt_regs *childregs = task_pt_regs(p);
+ 
+ *childregs = *regs;
+ childregs->ARM_pc = 0xcafebabe;
+
+ memset(&thread->cpu_context, 0, sizeof(struct cpu_context_save));
+ thread->cpu_context.sp = (unsigned long)childregs;
+ thread->cpu_context.pc = (unsigned long)ret_from_fork;
+
+ clear_ptrace_hw_breakpoint(p);
+
+ if (clone_flags & CLONE_SETTLS)
+   thread->tp_value = regs->ARM_r3;
+
+ thread_notify(THREAD_NOTIFY_COPY, thread);
+
+ return 0;
+}
+
+void mach_task_inc_thread_count(task_port_t* tport)
+{
+ atomic_inc_return(&tport->thread_count);
+ PortRetain(tport);
+}
+
+void mach_task_dec_thread_count(task_port_t* tport)
+{
+ int ar;
+ ar = atomic_dec_return(&tport->thread_count);
+ PortRelease(tport);
+ BUG_ON(ar < 0);
+}
+
+void mach_thread_bootstrap(struct task_struct* task)
+{
+ ke_port_right_t* rr;
+ ke_port_right_t* rcv = NULL;
+ task_port_t* tp;
+ task_port_t* cur;
+
+ tp = get_kernel_task(); /* can't use current */
+ cur = Native_get_task(task); /* can't use current */
+
+ rcv = mach_thread_allocate(tp);
+
+ mach_task_inc_thread_count(cur);
+
+ if (rcv) {
+   /* release kernel port? */
+
+   /* Add a send right to the task */
+   rr = ke_get_right_in_space(cur, (ke_port_t*)rcv->port, true);
+   RightIncrementRefCount(rr, r_send);
+
+   /* Create a relationship */
+   task->thread_port = rcv->port;
+   ((thread_port_t*)rcv->port)->task = task;
+
+   RightDecrementRefCount(rr, r_kernel);
+
+   Xlog("mach_thread_bootstrap(): bootstraped mach thread for task[%p] (mtask[%p]) with name[%d]", task, cur, rr->name);
+
+   PortRelease(cur);
+ }
+ else {
+   panic("mach_thread_bootstrap(): can't bootstrap mach thread for task[%p]", task);
+ }
+}
+
+ke_port_right_t* mach_thread_bootstrap_for_space(task_port_t* tport)
+{
+ ke_port_right_t* rr;
+ ke_port_right_t* rcv = NULL;
+ task_port_t* tp;
+ task_port_t* cur;
+
+ tp = get_kernel_task(); /* can't use current */
+ cur = tport;
+
+ rcv = mach_thread_allocate(tp);
+
+ mach_task_inc_thread_count(cur);
+
+ if (rcv) {
+   /* release kernel port? */
+
+   /* Add a send right to the task */
+   rr = Task_get_right(cur, (ke_port_t*)rcv->port, true);
+   RightIncrementRefCount(rr, r_send);
+
+   Xlog("mach_thread_bootstrap(): bootstraped mach thread for mtask[%p] with name[%d]", cur, rr->name);
+ 
+   return rr;
+ }
+ else {
+   panic("mach_thread_bootstrap(): can't bootstrap mach thread for mtask[%p]", cur);
+ }
+}
+
+long mk_thread_fork(unsigned long clone_flags,
+       unsigned long stack_start,
+       struct pt_regs *regs,
+       unsigned long stack_size,
+       struct task_struct* from,
+       struct task_struct** out_task);
+
+kern_return_t thread_create(task_port_t* parent_task, ke_port_right_t** child_thread)
+{
+ unsigned long flags;
+ long fork_ret;
+ struct pt_regs regs;
+ struct task_struct* new_task = NULL;
+
+ thread_port_t* mk_thread;
+ ke_port_right_t* mk_thread_right;
+
+ /* Zero out all the registers */
+ memset(&regs, 0, sizeof(regs));
+
+ /*
+  * ARM sanity
+  * This is needed to enforce userland execution for this thread.
+  */
+ regs.ARM_cpsr = USR_MODE;
+ regs.ARM_cpsr |= PSR_ENDSTATE;
+
+ /* Clone flags for threads */
+ flags = SIGCHLD | CLONE_FS | CLONE_FILES | CLONE_SIGHAND | CLONE_VM | CLONE_THREAD;
+
+ /* Create a mach thread object */
+ mk_thread_right = mach_thread_bootstrap_for_space(parent_task);
+ mk_thread = (thread_port_t*)mk_thread_right->port;
+
+ /* Set bits */
+ mk_thread->new_task = true;
+ atomic_set(&mk_thread->suspend_count, 1);
+
+ /* Fork */
+ fork_ret = 
+ mk_thread_fork(flags,
+   (unsigned long)0,
+   &regs,
+   (unsigned long)0,
+   Task_get_native(parent_task),
+   &new_task);
+
+ BUG_ON(new_task == NULL);
+
+ /* Link the task with the thread port */
+ new_task->thread_port = (void*)mk_thread;
+ mk_thread->task = new_task;
+
+ /* Return the port right to the thread */
+ *child_thread = mk_thread_right;
+
+ /* All done */
+ return KERN_SUCCESS;
+}
+
+extern bool freeze_task(struct task_struct *p, bool sig_only);
+extern int thaw_process(struct task_struct *p);
+
+kern_return_t __task_stop_uninterruptable(struct task_struct *tsk)
+{
+ if (freeze_task(tsk, false))
+ {
+   Xlog("suspended native task %p", tsk);
+   return KERN_SUCCESS;
+ }
+ else
+ {
+   return KERN_FAILURE;
+ }
+}
+
+kern_return_t __task_cont_uninterruptable(struct task_struct *tsk)
+{
+ if (thaw_process(tsk))
+ {
+   Xlog("resumed native task %p", tsk);
+   return KERN_SUCCESS;
+ }
+ else
+ {
+   return KERN_FAILURE;
+ }
+}
+
+int __mach_task_suspended_loop(struct task_struct *tsk)
+{
+ /*
+  * this allows us to interrupt frozen tasks
+  * even though they're not actually interruptable
+  *
+  * here it is safe to assume that the thread port
+  * will not be released.
+  */
+
+ thread_port_t* thread = tsk->thread_port;
+
+ if (fatal_signal_pending(tsk) || thread->exiting)
+ {
+   __task_cont_uninterruptable(tsk);
+ }
+
+ if (thread->exiting) {
+   /* let the task suicide itself */
+   do_exit(0);
+ }
+
+  return 0;
+}
+
+
+kern_return_t __thread_resume(thread_port_t* target_thread)
+{
+ if (target_thread->new_task)
+ {
+   /* clone_flags is ignored anyway */
+   wake_up_new_task(Thread_get_native(target_thread), 0);
+
+   target_thread->new_task = false;
+ }
+ else if (target_thread->frozen)
+ {
+   __task_cont_uninterruptable(Thread_get_native(target_thread));
+ }
+ else
+ {
+   panic("__thread_resume(%p): thread is not suspended", target_thread);
+ }
+
+ return KERN_SUCCESS;
+}
+
+kern_return_t __thread_suspend(thread_port_t* target_thread)
+{
+ if (target_thread->new_task)
+ {
+   /* no-op, as the thread is already suspended */
+ }
+ else if (!target_thread->frozen)
+ {
+   __task_stop_uninterruptable(Thread_get_native(target_thread));
+ }
+ else
+ {
+   panic("__thread_suspend(%p): thread is already suspended", target_thread);
+ }
+}
+
+kern_return_t thread_abort(thread_port_t* target_thread)
+{
+ /*
+  * This call is not supported because it makes no
+  * sense on Linux.
+  */
+ panic("thread_abort is not supported!");
+}
+
+kern_return_t thread_suspend(thread_port_t* target_thread)
+{
+ int ar;
+
+ ar = atomic_inc_return(&target_thread->suspend_count);
+
+ if (ar == 1) {
+   return __thread_suspend(target_thread);
+ }
+
+ return KERN_SUCCESS;
+}
+
+kern_return_t thread_resume(thread_port_t* target_thread)
+{
+ int ar;
+
+ ar = atomic_dec_return(&target_thread->suspend_count);
+
+ if (ar == 0) {
+   return __thread_resume(target_thread);
+ }
+
+ return KERN_SUCCESS;
+}
+
+
+typedef struct arm_thread_state arm_thread_state_t;
+
+/*
+ uint32_t r0;
+ uint32_t r1;
+ uint32_t r2;
+ uint32_t r3;
+ uint32_t r4;
+ uint32_t r5;
+ uint32_t r6;
+ uint32_t r7;
+ uint32_t r8;
+ uint32_t r9;
+ uint32_t r10;
+ uint32_t r11;
+ uint32_t r12;
+ uint32_t r13; //sp
+ uint32_t r14; //lr
+ uint32_t r15; //pc
+ uint32_t r16; //cpsr
+*/
+
+kern_return_t thread_get_state(thread_port_t* target, natural_t flavor, void* old_state, natural_t* count)
+{
+ natural_t max_buffer;
+ natural_t st_size;
+ arm_thread_state_t* state;
+
+ struct pt_regs *regs;
+ struct task_struct* ltask;
+
+
+ max_buffer = *count;
+ st_size = sizeof(arm_thread_state_t);
+ state = (arm_thread_state_t*)old_state;
+
+ if (st_size < max_buffer) {
+   Xwarn("thread_get_state(): buffer too small!");
+   return KERN_FAILURE;
+ }
+
+ /* Fetch task */
+ ltask = Thread_get_native(target);
+ BUG_ON(ltask == NULL);
+
+ /* Fetch registers */
+ regs = task_pt_regs(ltask);
+
+ /* Transfer */
+ state->r0 = (uint32_t)regs->ARM_r0;
+ state->r1 = (uint32_t)regs->ARM_r1;
+ state->r2 = (uint32_t)regs->ARM_r2;
+ state->r3 = (uint32_t)regs->ARM_r3;
+ state->r4 = (uint32_t)regs->ARM_r4;
+ state->r5 = (uint32_t)regs->ARM_r5;
+ state->r6 = (uint32_t)regs->ARM_r6;
+ state->r7 = (uint32_t)regs->ARM_r7;
+ state->r8 = (uint32_t)regs->ARM_r8;
+ state->r9 = (uint32_t)regs->ARM_r9;
+ state->r10 = (uint32_t)regs->ARM_r10;
+ state->r11 = (uint32_t)regs->ARM_fp;
+ state->r12 = (uint32_t)regs->ARM_ip;
+
+ state->r13 = (uint32_t)regs->ARM_sp;
+ state->r14 = (uint32_t)regs->ARM_lr;
+ state->r15 = (uint32_t)regs->ARM_pc;
+
+ state->r16 = (uint32_t)regs->ARM_cpsr;
+
+ /* All done! */
+ return KERN_SUCCESS;
+}
+
+kern_return_t thread_set_state(thread_port_t* target, natural_t flavor, void* new_state, natural_t new_state_count)
+{
+ arm_thread_state_t* state = (arm_thread_state_t*)new_state;
+ struct pt_regs *regs;
+ struct task_struct* ltask;
+ struct thread_info *thread;
+
+ if (new_state_count != sizeof(arm_thread_state_t)) {
+   /* Wrong size */
+   return KERN_FAILURE;
+ }
+
+ ltask = Thread_get_native(target);
+ BUG_ON(ltask == NULL);
+
+ regs = task_pt_regs(ltask);
+
+ /* transfer things */
+ regs->ARM_r0 = (unsigned long)state->r0;
+ regs->ARM_r1 = (unsigned long)state->r1;
+ regs->ARM_r2 = (unsigned long)state->r2;
+ regs->ARM_r3 = (unsigned long)state->r3;
+ regs->ARM_r4 = (unsigned long)state->r4;
+ regs->ARM_r5 = (unsigned long)state->r5;
+ regs->ARM_r6 = (unsigned long)state->r6;
+ regs->ARM_r7 = (unsigned long)state->r7;
+ regs->ARM_r8 = (unsigned long)state->r8;
+ regs->ARM_r9 = (unsigned long)state->r9;
+ regs->ARM_r10 = (unsigned long)state->r10;
+ regs->ARM_fp = (unsigned long)state->r11;
+ regs->ARM_ip = (unsigned long)state->r12;
+
+ regs->ARM_sp = (unsigned long)state->r13;
+ regs->ARM_lr = (unsigned long)state->r14;
+ regs->ARM_pc = (unsigned long)state->r15;
+
+ regs->ARM_cpsr = (unsigned long)state->r16;
+
+ /* Alter the CPU context */ 
+ thread = task_thread_info(ltask);
+
+ memset(&thread->cpu_context, 0, sizeof(struct cpu_context_save));
+ thread->cpu_context.sp = (unsigned long)regs;
+ thread->cpu_context.pc = (unsigned long)ret_from_fork;
+
+ clear_ptrace_hw_breakpoint(ltask);
+
+ return KERN_SUCCESS;
+}
+
+static int __force_tkill(struct task_struct* tsk, int sig)
+{
+ /* force_sig_info(int sig, struct siginfo *info, struct task_struct *t) */
+
+ int ret;
+
+ ret = send_sig(sig, tsk, 1);
+
+ return ret;
+}
+
+
+void thread_exception_return(void)
+{
+ thread_port_t* tp;
+ boolean_t exiting;
+
+ BUG_ON(current == NULL);
+
+ tp = Native_get_current_thread();
+ exiting = tp->exiting;
+
+ PortRelease(tp);
+
+ /* well, we can't return because we're exiting */
+ if (exiting) {
+   do_exit(0);
+ }
+
+ /* leave kernel mode */
+ Return_to_user_from_swi();
+}
+
+kern_return_t thread_terminate_sig(thread_port_t* target, int sig)
+{
+ struct task_struct* task;
+
+ task = Thread_get_native(target);
+
+ target->exiting = true;
+
+ __force_tkill(task, sig);
+
+ return KERN_SUCCESS;
+}
+
+kern_return_t thread_terminate(thread_port_t* target)
+{
+ struct task_struct* task;
+ task = Thread_get_native(target);
+
+ return thread_terminate_sig(target, SIGKILL);
+}
+
+/**/
+#define r_sp r13
+#define r_lr r14
+#define r_pc r15
+#define r_cpsr r16
+
+kern_return_t bsdthread_create_fork_arm(void* stack, void* fn, void* arg, size_t stack_size, void* thread_addr)
+{
+ task_port_t* current_task;
+ thread_port_t* mk_thread;
+ ke_port_right_t* mk_thread_right;
+
+ arm_thread_state_t _regs;
+ arm_thread_state_t* regs;
+
+ uint32_t initial_pc;
+
+ regs = &_regs;
+ current_task = Native_get_task(current);
+ initial_pc = (uint32_t)current->p_threadstart;
+
+ thread_create(current_task, &mk_thread_right);
+ mk_thread = (thread_port_t*)mk_thread_right->port;
+
+ Xwarn("bsdthread_create_fork_arm(): mach thread forked, task[%p], mtask[%p]", mk_thread->task, mk_thread->task->task_port);
+
+ PortRelease(current_task);
+
+ /* Okay, set the initial thread state */
+ regs->r0 = (uint32_t)thread_addr;
+ regs->r1 = (uint32_t)mk_thread_right->name;
+ regs->r2 = (uint32_t)fn;
+ regs->r3 = (uint32_t)arg;
+ regs->r4 = (uint32_t)stack_size;
+ regs->r5 = (uint32_t)0;
+
+ /* Stack pointer */
+ regs->r_sp = (uint32_t)stack;
+
+ /* Entry point */
+ regs->r_pc = (uint32_t)(initial_pc & ~1); 
+
+ /* Userland mode & endinaness */
+ regs->r_cpsr = USR_MODE; 
+ regs->r_cpsr |= PSR_ENDSTATE;
+
+ /* Start execution in thumb mode? */
+ if (initial_pc & 1) {
+   regs->r_cpsr |= PSR_T_BIT;
+ }
+
+ thread_set_state(mk_thread, 0, regs, sizeof(_regs));
+
+ thread_resume(mk_thread);
+
+ return KERN_SUCCESS;
+}
+
+void* _user_bsdthread_create(void* _args)
+{
+ bsd_crt_args_t args;
+ unsigned int flags;
+ void* stack;
+ task_port_t* tp;
+ size_t stack_size = 0;
+ uintptr_t addr = 0;
+ kern_return_t retval;
+ uintptr_t th_stack;
+ uintptr_t th_pthread = 0;
+
+ if (copy_from_user(&args, _args, sizeof(bsd_crt_args_t)))
+ {
+   /* wtf */
+   return (void*)-1;
+ }
+
+ flags = args.flags;
+ tp = Native_get_current_task();
+ /*
+   void* func;
+   void* func_arg;
+   void* stack;
+   void* thread;
+   unsigned int flags;
+ */
+
+ if ((flags & PTHREAD_START_CUSTOM) == 0) {
+   /* We need to allocate the stack ourselves */
+   stack_size = (size_t)args.stack + (size_t)PAGE_SIZE + (size_t)current->p_pthsize;
+   retval = mach_task_vm_allocate(tp, &addr, stack_size, true);
+
+   if (retval != KERN_SUCCESS) {
+     Xwarn("failed to allocate user stack!");
+     goto out_tp;
+   }
+
+   th_stack = (uintptr_t)addr + (uintptr_t)args.stack + (uintptr_t)PAGE_SIZE;
+   th_pthread = th_stack; /* stack grows down, thread is just above it */
+
+   Xlog("thread stack allocated at %p, dw at %p (size: %p)", (void*)addr, th_stack, stack_size);
+ }
+ else 
+ {
+   /* Userland wants to use its own stack, so let it */
+   th_pthread = (uintptr_t)args.thread;
+
+   /* Wtf, but that's what XNU does */
+   th_stack = (uintptr_t)args.stack;
+   stack_size = (size_t)args.stack;
+ }
+
+ stack = (void*)th_stack;
+
+ Xlog("%p %p %p %p %p", args.func, args.func_arg, args.stack, args.thread, args.flags);
+
+ /* Create the platform thread */
+ retval = bsdthread_create_fork_arm(stack, args.func, args.func_arg, stack_size, (void*)th_pthread);
+
+ if (retval != KERN_SUCCESS)
+ {
+   panic("bsdthread_create(): failed to create a thread!");
+ }
+
+out_tp:
+ PortRelease(tp);
+ return (void*)th_pthread;
+}
+
+int _user_bsdthread_register(void* _args)
+{
+ bsd_reg_args_t args;
+
+ if (copy_from_user(&args, _args, sizeof(bsd_reg_args_t)))
+ {
+   return -1;
+ }
+
+ /*
+   void* start_fn;
+   void* wstart_fn;
+   int thread_size;
+   void* pthread_start_fn;
+   void* workq;
+   uint64_t tsd;
+ */
+
+ Xlog("%p %p %d %p %p %ld", args.start_fn, args.wstart_fn, args.thread_size, args.pthread_start_fn, args.workq, args.tsd);
+
+ /* Wow, this is easier than I thought ... */
+ current->p_threadstart = args.start_fn;
+ current->p_wqthread = args.wstart_fn;
+ current->p_targconc = args.pthread_start_fn;
+ current->p_dispatchqueue_offset = args.tsd;
+ current->p_pthsize = args.thread_size;
+
+ return 0;
+}
+
+kern_return_t _user_thread_policy(mach_port_t prt, integer_t policy, integer_t* base, integer_t* sz, boolean_t set_limit)
+{
+ Xlog("set policy %p for thread[%d]", policy, prt);
+ return KERN_SUCCESS;
+}
+
+thread_port_t* mach_thread_self(void)
+{
+ return Native_get_current_thread();
+}
+
+kern_return_t _user_thread_self(void)
+{
+ /* We should already hold the send right */
+ thread_port_t* th = Native_get_current_thread();
+
+ task_port_t* tp = Native_get_current_task();
+ ke_port_right_t* rcv = Task_get_right(tp, (ke_port_t*)th, false);
+
+ if (rcv) {
+   mach_port_t nm = rcv->name;
+   PortRelease(tp);
+   PortRelease(th);
+   RightDecrementRefCount(rcv, r_kernel);
+   return nm;
+ }
+ else {
+   /*
+    * This shouldn't ever happen.
+    */
+   panic("_user_thread_self: mach thread port invalid for task %p", current);
+   return 0;
+ }
+}
+
+mach_port_t _user_task_self(void)
+{
+ /* We should already hold the send right*/
+ task_port_t* tp = Native_get_current_task();
+ ke_port_right_t* rcv = Task_get_right(tp, (ke_port_t*)tp, false);
+
+ if (rcv) {
+   mach_port_t nm = rcv->name;
+   PortRelease(tp);
+   return nm;
+ }
+ else {
+   /*
+    * This shouldn't ever happen.
+    */
+   panic("_user_task_self: mach task port invalid for task %p", current);
+   return 0;
+ }
+}
+
+kern_return_t _user_thread_resume(mach_port_t _target)
+{  
+ thread_port_t* target;
+ kern_return_t ret;
+
+ ret = mach_thread_for_name(_target, &target);
+ if (ret != KERN_SUCCESS) {
+   return ret;
+ }
+ else
+ {
+   ret = thread_resume(target);
+   PortRelease(target);
+ }
+
+ return ret;
+}
+
+kern_return_t _user_thread_suspend(mach_port_t _target)
+{  
+ thread_port_t* target;
+ kern_return_t ret;
+
+ ret = mach_thread_for_name(_target, &target);
+ if (ret != KERN_SUCCESS) {
+   return ret;
+ }
+ else
+ {
+   ret = thread_suspend(target);
+   PortRelease(target);
+ }
+
+ return ret;
+}
+
+kern_return_t _user_thread_get_state(mach_port_t _target, natural_t _flavor, void* _old_state, natural_t* _count)
+{  
+ thread_port_t* target;
+ kern_return_t ret;
+
+ ret = mach_thread_for_name(_target, &target);
+ if (ret != KERN_SUCCESS) {
+   return ret;
+ }
+ else
+ {
+   arm_thread_state_t state;
+   natural_t count = sizeof(state);
+
+   ret = thread_get_state(target, _flavor, (void*)&state, &count);
+   if (ret != KERN_SUCCESS) {
+     PortRelease(target);
+     return ret;
+   }
+
+   if (copy_to_user(_old_state, (void*)&state, count)) {
+     PortRelease(target);
+     return KERN_FAILURE;
+   }
+
+   __put_user(count, _count);
+
+   PortRelease(target);
+
+   Xwarn("_user_thread_get_state(): returned thread state for thread %d", _target);
+   return KERN_SUCCESS;
+ }
+}
+
+kern_return_t _user_task_threads(mach_port_t target_task, uintptr_t *threads, natural_t *thread_count)
+{
+ struct task_struct* tsk;
+ task_port_t* port;
+ kern_return_t ret;
+ task_port_t* cur;
+ natural_t count = 0;
+ uintptr_t addr = 0;
+ mach_port_t* mach_port_user_array;
+
+ ret = mach_task_port_for_name(target_task, &port);
+ if (ret != KERN_SUCCESS) {
+   return ret;
+ }
+
+ /* Gah */
+ for_each_process(tsk)
+ {
+   if (tsk->task_port == port)
+   {
+     count++;
+   }
+ }
+
+ cur = Native_get_current_task();
+
+ /* Allcoate pages to store the array on */
+ ret = mach_task_vm_allocate(cur, &addr, count * sizeof(mach_port_t), true);
+ BUG_ON(ret != KERN_SUCCESS);
+
+ mach_port_user_array = (mach_port_t*)(addr);
+
+ for_each_process(tsk)
+ {
+   if (tsk->task_port == port)
+   {
+     ke_port_right_t* snd;
+     thread_port_t* th;
+
+     th = Native_get_thread(tsk);
+
+     /* Get the send right for this thread, create if needed */
+     snd = Task_get_right(cur, (ke_port_t*)th, true);
+     BUG_ON(snd == NULL);
+
+     RightIncrementRefCount(snd, r_send);
+
+     __put_user(snd->name, mach_port_user_array);
+     mach_port_user_array++;
+
+     /* Release bits */
+     RightDecrementRefCount(snd, r_kernel);
+     PortRelease(th);
+   }
+ }
+
+ /* Return */
+ __put_user(addr, threads);
+ __put_user(count, thread_count);
+
+ PortRelease(cur);
+ PortRelease(port);
+
+ return KERN_SUCCESS;
+}
+
+kern_return_t _user_thread_switch(mach_port_name_t thread_name, int option, natural_t option_time)
+{
+ /* This isn't quite supported ... */
+
+ Xwarn("thread[%d] not switching, just yielding!", thread_name);
+ yield();
+
+ return KERN_SUCCESS;
+}
+
+kern_return_t _user_pid_for_task(mach_port_name_t t, int *x)
+{
+ task_port_t* tp;
+ struct task_struct* tsk;
+
+
+ tp = (task_port_t*)Task_find_port(t);
+
+ if (!tp) {
+   return KERN_INVALID_NAME;
+ }
+
+ tsk = tp->task;
+
+ if (!tsk) {
+   panic("task port %p doesn't have a task!", tp);
+ }
+
+ /* I hope pid_t is an int ... */
+ __put_user(tsk->pid, x);
+ PortRelease(tp);
+
+ return KERN_SUCCESS;
+}
+
+kern_return_t _user_task_for_pid(mach_port_t target_tport, int pid, mach_port_t *t)
+{
+ ke_port_right_t* snd;
+ task_port_t* tp;
+ struct task_struct* rem;
+ ke_port_t* rp;
+
+ tp = (task_port_t*)Task_find_port(target_tport);
+
+ if (!tp) {
+   return KERN_INVALID_NAME;
+ }
+
+ rem = find_task_by_vpid(pid);
+ if (!rem) {
+   Xwarn("pid(%d): vpid not found!", pid);
+   return KERN_FAILURE;
+ }
+
+ rp = (ke_port_t*)(rem->task_port);
+ if (!rp) {
+   panic("task %p doesn't have a task port!", rem);
+ }
+
+ snd = Task_get_right(tp, rp, true);
+ if (!snd) {
+   Xwarn("pid(%d): failed to add right to space!", pid);
+   PortRelease(tp);
+   return KERN_FAILURE;
+ }
+
+ RightIncrementRefCount(snd, r_send);
+
+ __put_user(snd->name, t);
+
+ PortRelease(tp);
+
+ return KERN_SUCCESS;
+}
+
+kern_return_t mach_task_port_for_name(mach_port_t user_port, task_port_t** out)
+{
+ return Task_get_object_if_send(user_port, (Obj**)out, KE_PORT_TYPE_TASK);
+}
+
+#define xxxxx() Xwarn("not yet implemented");
+#define xxxxx_panic() ke_critical("THREAD: %s not impl", __FUNCTION__);
+
+
+int _user__disable_threadsignal(int xx) {
+ xxxxx();
+ return 0;
+}
+
+int _user_thread_selfid(uint64_t* ret)
+{
+ __put_user(task_pid_vnr(current), ret);
+ return 0;
+}
+
+kern_return_t _user_syscall_thread_switch(mach_port_name_t a , int b, int c)
+{
+ xxxxx_panic();
+}
+
+int _user_bsdthread_terminate(void * freeaddr, size_t freesize, mach_port_t kport, mach_port_t joinsem)
+{
+ thread_port_t* thread;
+
+ thread = Native_get_current_thread();
+
+ /* mach_vm_deallocate(current_map(), freeaddr, freesize); */
+
+ Xwarn("terminating current thread ...");
+
+ thread_terminate(thread);
+
+ PortRelease(thread);
+
+ thread_exception_return();
+
+ panic("_user_bsdthread_terminate(): thread still running!");
+}
+
+int _user__pthread_canceled(int x)
+{
+ thread_port_t* thread;
+
+ if (x != 1 && x != 2)
+ {
+   return -1;
+ }
+
+ thread = Native_get_current_thread();
+
+ if (x == 1)
+ {
+   /* enable */
+   thread->can_cancel = true;
+ }
+ else
+ {
+   /* disable */
+   thread->can_cancel = false;
+ }
+
+ PortRelease(thread);
+
+ return 0;
+}
+
+int _user__pthread_kill(mach_port_t port, int x)
+{
+ /* Kill BSD thread with signal */
+ kern_return_t ret;
+ thread_port_t* thread;
+
+ ret = mach_thread_for_name(port, &thread);
+ if (ret != KERN_SUCCESS) {
+   return -1;
+ }
+
+ /* Kill pthread with a signal */
+ thread_terminate_sig(thread, x);
+
+ PortRelease(thread);
+
+ thread_exception_return();
+
+ return 0;
+}
+
+int _user__pthread_markcancel(int x)
+{
+ thread_port_t* thread;
+ int ret = 0;
+
+ thread = Native_get_current_thread();
+
+ if (thread->can_cancel)
+ {
+   thread_terminate(thread);
+   PortRelease(thread);
+   thread_exception_return();
+ }
+ else
+ {
+   PortRelease(thread);
+ }
+
+ return ret;
+}
+
+int _user__workq_open(void)
+{
+ xxxxx_panic();
+}
+
+void __ke_memtest(void)
+{
+ 
+}
diff -Naur ./old//magenta/mach_user_port.c ./kern//magenta/mach_user_port.c
--- ./old//magenta/mach_user_port.c 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/mach_user_port.c  2012-08-06 10:39:38.000000000 -0400
@@ -0,0 +1,668 @@
+/*
+ * mach_user_port.c
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Anything to do with ports that a user thing may create.
+ * This involves:
+ *     > IPC ports
+ *     > Port sets
+ *
+ * Do not call this from IRQ context, or you will break it.
+ */
+
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+#include "ke_runtime.h"
+
+#include "Ipc.h"
+
+/* ipc port ops */
+kern_return_t Ipc_port_receive(struct __Obj* port, ipc_trap_data_t* info);
+kern_return_t Ipc_port_send(struct __Obj* port, ipc_trap_data_t* info);
+ke_port_ops_t _ipc_port_ops = {
+ .msg_receive = Ipc_port_receive,
+ .msg_send = Ipc_port_send
+};
+
+/* port set ops */
+kern_return_t Ipc_port_set_receive(struct __Obj* port, ipc_trap_data_t* info);
+ke_port_ops_t _ipc_port_set_ops = {
+ .msg_receive = Ipc_port_set_receive
+};
+
+
+/*
+ * This copies data to a userland buffer if the message is received from
+ * the userspace or to a kernel memory chunk if it is received from the 
+ * kernel.
+ */
+boolean_t ipc_copy_data_local(void* to, void* from, unsigned long size, boolean_t user)
+{
+ if (user) {
+   if (copy_to_user(to, from, size)) {
+     return false;
+   }
+   else {
+     return true;
+   }
+ }
+ else {
+   memcpy(to, from, size);
+   return true;
+ }
+}
+
+kern_return_t Ipc_port_receive(struct __Obj* port, ipc_trap_data_t* info)
+{
+ return 11;
+}
+
+kern_return_t Ipc_port_send(struct __Obj* port, ipc_trap_data_t* info)
+{
+ ipc_port* iport = (ipc_port*)port;
+ ipc_message* msg;
+ mach_msg_header_t* buffer = info->snd_msg;
+ kern_return_t ret;
+
+ BUG_ON(!port);
+ BUG_ON(port->type != KE_PORT_TYPE_IPC);
+
+ msg = Ipc_message_allocate(buffer, info->snd_size, info->task);
+
+ BUG_ON(!msg);
+
+ ret = Ipc_msg_send_block(iport, msg);
+
+ return ret;
+}
+
+/*
+ * Receiving a mach message on a port set.
+ */
+kern_return_t Ipc_port_set_receive(struct __Obj* port, ipc_trap_data_t* info)
+{
+ kern_return_t retval;
+ ipc_port_set* pset = (ipc_port_set*)port;
+
+ int qr = 0;
+ unsigned int count;
+ unsigned int i;
+ ipc_message* rcv_msg = NULL;
+ ipc_port** ports;
+ kern_return_t rcv_ret;
+ boolean_t has_messages = false;
+
+ task_port_t* self = info->task;
+
+ BUG_ON(!port);
+ BUG_ON(port->type != KE_PORT_TYPE_PORT_SET);
+
+ /* compat */
+ PortRetain(pset);
+
+L_retry_ports:
+ /*
+  * we can't have irqs firing while this code runs 
+  * for obvious reasons.
+  */
+ spin_lock(&pset->port_list_lock);
+
+ count = ke_array_get_count(pset->port_list);
+ ports = (ipc_port**)__ke_array_get_base(pset->port_list);
+
+ for (i = 0; i < count; i++)
+ {
+   ipc_port* rcv_port;
+
+   rcv_port = ports[i];
+
+   /*
+     kern_return_t Ipc_msg_receive_block(ipc_port* rcv_port,
+       task_port_t* task,
+       ipc_message** out_message,
+       size_t max_size,
+       boolean_t large);
+   */
+
+   /* attempt to receive on a port */
+   rcv_ret = Ipc_msg_receive_nonblock(rcv_port,
+     self,
+     &rcv_msg,
+     info->rcv_size,
+     info->options & MACH_RCV_LARGE);
+
+   if (rcv_ret == MACH_RCV_IN_PROGRESS) {
+     continue;
+   }
+   else if (rcv_ret == MACH_MSG_SUCCESS) {
+     has_messages = true;
+     break;
+   }
+   else {
+     if (info->options & MACH_RCV_LARGE && rcv_ret == MACH_RCV_TOO_LARGE)
+     {
+       XWarn("port[%p] msg MACH_MSG_TOO_LARGE, copyout the header!", rcv_port);
+       has_messages = true;
+
+       panic("%s(): implement MACH_MSG_TOO_LARGE!", __FUNCTION__);
+
+       break;
+     }
+     else
+     {
+       XWarn("port[%p] in the set error: %d", rcv_port, rcv_ret);
+       continue;
+     }
+   }
+ }
+
+ spin_unlock(&pset->port_list_lock);
+
+ if (has_messages)
+ {
+   Xlog("found message[%p] on iter %d", rcv_msg, i);
+
+   if (!ipc_copy_data_local(info->rcv_buffer, rcv_msg->msg, rcv_msg->size, info->options & MACH_MSG_USER))
+   {
+     Xwarn("can't write message %p", rcv_msg);
+     retval = KERN_FAILURE; /* userland seriously screwed up*/
+     goto a_pset;
+   }
+
+   retval = MACH_MSG_SUCCESS;
+   goto a_pset;
+ }
+ else
+ {
+   XLog("waiting on a port set queue (port_set[%p]) ...", pset);
+   qr = wait_event_interruptible((pset->wait_queue), false);
+   
+   if (qr == -ERESTARTSYS)
+   {
+     XLog("wait aborted!");
+     retval = MACH_RCV_INTERRUPTED;
+     goto a_pset;
+   }
+   else
+   {
+     /* one of the ports has woken us up! */
+     Xwarn("port_set_message_handle(): pset[%p] retry!", pset);
+
+     /* XXX: this is really really bad and unfair */
+     goto L_retry_ports;
+   }
+ }
+
+ 
+a_pset:
+ PortRelease(pset);
+out:
+ return retval;
+}
+
+ke_port_right_t* port_set_allocate(task_port_t* space)
+{
+ ipc_port_set* prt = NULL;
+ ke_port_right_t* rr = NULL;
+
+ rr = ke_new_port(KE_PORT_TYPE_PORT_SET);
+ if (!rr || !rr->port) {
+   return NULL;
+ }
+ prt = (ipc_port_set*)rr->port;
+
+ /* operations*/
+ prt->port.ops = &_ipc_port_set_ops;
+
+ /* global queue for this port set */
+ init_waitqueue_head(&(prt->wait_queue));
+
+ /* members */
+ prt->port_list = ke_array_with_capacity(0);
+ spin_lock_init(&prt->port_list_lock);
+
+ /* Add a port set right */
+ RightIncrementRefCount(rr, r_port_set);
+
+ rr->name = ke_get_new_port_name_in_space(space);
+ ke_add_right_to_space(space, rr);
+
+ return rr;
+}
+
+ke_port_right_t* ipc_port_allocate(task_port_t* space)
+{
+ ipc_port* prt = NULL;
+ ke_port_right_t* rr = NULL;
+
+ rr = ke_new_port(KE_PORT_TYPE_IPC);
+ if (!rr || !rr->port) {
+   return NULL;
+ }
+ prt = (ipc_port*)rr->port;
+
+ prt->port.ops = &_ipc_port_ops;
+
+ /* create a message queue */
+ if(kfifo_alloc(&(prt->queue), PAGE_SIZE, GFP_KERNEL)) {
+   panic("allocate_ipc_port(): can't create a message queue");
+ }
+
+ /* 
+  * create a completion variable to hang on if the
+  * queue is empty 
+  */
+ init_waitqueue_head(&(prt->wait_queue));
+
+ /* create a list of wait queues */
+ prt->wait_list = ke_array_with_capacity(0);
+ spin_lock_init(&prt->wait_list_lock);
+
+ /* insert the wait queue */
+ ke_array_add(prt->wait_list, &prt->wait_queue);
+
+ /* Add a receive right for the task */
+ RightIncrementRefCount(rr, r_receive);
+ rr->name = ke_get_new_port_name_in_space(space);
+ ke_add_right_to_space(space, rr);
+
+ return rr;
+}
+
+kern_return_t mach_port_allocate(ipc_space_t task, mach_port_right_t right, mach_port_name_t *name)
+{
+ if (!task->port.active) {
+   return KERN_FAILURE;
+ }
+
+ if (right == MACH_PORT_RIGHT_RECEIVE)
+ {
+   /*
+    * Ports created with 'MACH_PORT_RIGHT_RECEIVE' are IPC ports.
+    */
+   ke_port_right_t* rr = ipc_port_allocate(task);
+
+   Xlog("allocating ipc port [%d]", rr->name);
+
+   if (rr) {
+     *name = rr->name;
+   }
+   else {
+     return KERN_FAILURE;
+   }
+   
+   return KERN_SUCCESS;
+ }
+ else if (right == MACH_PORT_RIGHT_PORT_SET)
+ {
+   /*
+    * Port set.
+    */
+   ke_port_right_t* rr = port_set_allocate(task);
+
+   Xlog("allocating port set [%d]", rr->name);
+
+   if (rr) {
+     *name = rr->name;
+   }
+   else {
+     return KERN_FAILURE;
+   }
+   
+   return KERN_SUCCESS;
+ }
+ else
+ {
+   /* Unknown right type */
+   return KERN_FAILURE;
+ }
+}
+
+kern_return_t _user_mach_port_insert_right(mach_port_t task, mach_port_name_t in_name, mach_port_name_t in_right, mach_msg_type_name_t right_type)
+{
+ ke_port_right_t* name;
+ ke_port_right_t* right;
+ task_port_t* target_space;
+ kern_return_t ret;
+
+ if (right != name) {
+   ke_warn("_user_mach_port_insert_right(): XXX (right != name)\n");
+   return KERN_FAILURE;
+ }
+
+ target_space = (task_port_t*)Task_find_port(task);
+
+ if (!target_space) {
+   return KERN_INVALID_NAME;
+ }
+
+ name = Task_find_right(in_name);
+ if (!name) {
+   return KERN_INVALID_NAME;
+ }
+ if (!name->port) {
+   PortRelease(target_space);
+   RightDecrementRefCount(name, r_kernel);
+   return KERN_FAILURE;
+ }
+
+ /* Insert the right into the target IPC space */
+ right = Task_get_right(target_space, name->port, true);
+ if (!right) {
+   panic("_user_mach_port_insert_right(): ke_get_right_in_space failed");
+ }
+
+ /*
+  * Now depending on the type of the right transferred, change stuff
+  * [XXX]: Check if we hold the valid right needed to perform the operation.
+  */
+ switch (right_type)
+ {
+   case MACH_MSG_TYPE_MAKE_SEND:
+   {
+     RightIncrementRefCount(right, r_send);
+     ret = KERN_SUCCESS;
+     break;
+   }
+   case MACH_MSG_TYPE_COPY_SEND:
+   {
+     RightIncrementRefCount(right, r_send);
+     ret = KERN_SUCCESS;
+     break;
+   }
+   case MACH_MSG_TYPE_MOVE_SEND:
+   {
+     RightIncrementRefCount(right, r_send);
+     RightDecrementRefCount(name, r_send);
+     ret = KERN_SUCCESS;
+     break;
+   }
+   case MACH_MSG_TYPE_MOVE_RECEIVE:
+   {
+     RightIncrementRefCount(right, r_receive);
+     RightDecrementRefCount(name, r_receive);
+     ret = KERN_SUCCESS;
+     break;
+   }
+   case MACH_MSG_TYPE_COPY_RECEIVE:
+   {
+     Xwarn("invalid argument");
+     ret = KERN_FAILURE;
+     break;
+   }
+   default:
+   {
+     Xwarn("unknown argument %d", right_type);
+     ret = KERN_FAILURE;
+     break;
+   }
+ }
+
+ PortRelease(name->port);
+ PortRelease(target_space);
+ RightDecrementRefCount(name, r_kernel);
+ RightDecrementRefCount(right, r_kernel);
+ return ret;
+}
+
+kern_return_t _user_mach_port_insert_member(mach_port_name_t _task, mach_port_name_t _name, mach_port_name_t _pset)
+{
+ kern_return_t retval;
+
+ ipc_port_set* pset;
+ ke_port_right_t* pset_right;
+ task_port_t* target_space;
+ ke_port_right_t* member;
+
+ Xlog("port[%d] => pset[%d]", _name, _pset);
+
+ target_space = (task_port_t*)ke_port_find_named((mach_port_t)_task);
+ if (!target_space) {
+   return KERN_INVALID_NAME;
+ }
+
+ /* XXX: task send right? */
+
+ member = Task_find_right(_name);
+ if (!member) {
+   Xwarn("invalid member name [%d]", _name);
+   retval = KERN_INVALID_NAME;
+   goto a_task;
+ }
+
+ pset_right = Task_find_right(_pset);
+ if (!pset_right) {
+   Xwarn("invalid port set name [%d]", _pset);
+   retval = KERN_INVALID_NAME;
+   goto a_member;
+ }
+
+ /* kk */
+ pset = (ipc_port_set*)pset_right->port;
+
+ /* checks */
+ if (!IsReceiveRight(member))
+ {
+   retval = KERN_INVALID_RIGHT;
+   goto a_pset;
+ }
+
+ if (!IsPortSetRight(pset_right))
+ {
+   retval = KERN_INVALID_RIGHT;
+   goto a_pset;
+ }
+
+ /* okay, just to be safe */
+ BUG_ON(pset_right->port->type != KE_PORT_TYPE_PORT_SET);
+ BUG_ON(member->port->type != KE_PORT_TYPE_IPC);
+
+ /* now actually add */
+ spin_lock(&pset->port_list_lock);
+ ke_array_add(pset->port_list, (ke_storage_type)member->port);
+ spin_unlock(&pset->port_list_lock);
+
+ Ipc_port_add_queue((ipc_port*)member->port, &pset->wait_queue);
+
+ /* safe to increment the refcount in this context */
+ PortRetain(member->port);
+
+ /* ok, success */
+ retval = KERN_SUCCESS;
+
+ /* teardown */
+a_pset:
+ PortRelease(pset);
+ RightDecrementRefCount(pset_right, r_kernel);
+a_member:
+ PortRelease(member->port);
+ RightDecrementRefCount(member, r_kernel);
+a_task:
+ PortRelease(target_space);
+ return retval;
+}
+
+/*
+ * Support for the mk_timer syscall familiy.
+ * This provides a nice mach port based timer interface.
+ */
+mach_port_name_t _user_mk_timer_create(void) 
+{
+ ke_port_right_t* rr = ipc_port_allocate(ke_get_current_task());
+
+ Xlog("allocated a timer ipc port [%d]", rr->name);
+
+ return rr->name;
+}
+
+kern_return_t _user_mk_timer_destroy(mach_port_name_t name)
+{
+ Xlog("destroy port[%d]", name);
+
+ return KERN_FAILURE;
+}
+
+typedef struct {
+ ipc_port* timer_port;
+ mach_port_name_t name;
+} __mk_timer;
+
+void __mk_timer_fire(unsigned long data)
+{
+ ipc_port* timer_port;
+ mach_msg_header_t* msg; 
+ __mk_timer* kt;
+ mach_port_name_t name;
+ ipc_message* im;
+
+ kt = (__mk_timer*)data;
+ timer_port = kt->timer_port;
+ name = kt->name;
+
+ /* we're done with kt */
+ kfree(kt);
+
+ Xwarn("timer port[%d] (ke_port[%p]) fired", name, timer_port);
+
+ /* paranoia ... */
+ BUG_ON(timer_port->port.type != KE_PORT_TYPE_IPC);
+
+ /* this will be released by the kernel later */
+ msg = kmalloc(sizeof(*msg), GFP_KERNEL);
+
+ /* timer message */
+ msg->msgh_size = sizeof(*msg);
+ msg->msgh_remote_port = name;
+ msg->msgh_local_port = 0;
+ msg->msgh_id = 0;
+ msg->msgh_bits = MACH_MSGH_BITS(MACH_MSG_TYPE_COPY_SEND, 0);
+
+ im = Ipc_message_allocate(msg, sizeof(*msg), get_kernel_task());
+
+ /* send! */
+ Ipc_msg_send_nonblock(timer_port, im);
+}
+
+kern_return_t _user_mk_timer_arm(mach_port_name_t name, uint64_t expire_time)
+{
+ ke_port_right_t* right;
+ kern_return_t retval = KERN_FAILURE;
+ ipc_port* tp;
+ __mk_timer* kt;
+
+ right = Task_find_right(name);
+ if (!right) {
+   Xwarn("mk_timer_arm(): timer port invalid!");
+   retval = KERN_INVALID_NAME;
+   goto out;
+ }
+
+ Xwarn("arm port[%d] (ke_port[%p]) after delay %ld", name, right->port, expire_time);
+
+ if (!IsReceiveRight(right))
+ {
+   Xwarn("mk_timer_arm(): timer port not a rcv right!");
+   retval = KERN_INVALID_RIGHT;
+   goto out;
+ }
+
+ /* just to be sure ... */
+ BUG_ON(right->port->type != KE_PORT_TYPE_IPC);
+
+ kt = kmalloc(sizeof(*kt), GFP_KERNEL);
+ tp = (ipc_port*)right->port;
+
+ /* thing */
+ kt->timer_port = tp;
+ kt->name = name;
+
+ /* STAND BACK, CREATING A KERNEL TIMER. */
+ init_timer(&tp->ktimer);
+
+ tp->ktimer.expires = jiffies + expire_time;
+ tp->ktimer.data = (unsigned long)kt;
+ tp->ktimer.function = __mk_timer_fire;
+
+ RightDecrementRefCount(right, r_kernel);
+ retval = KERN_SUCCESS;
+ /* not releasing the port as the firing function needs it */
+
+ /* activate the timer */
+ add_timer(&tp->ktimer);
+
+out:
+ return retval;
+}
+
+kern_return_t _user_mk_timer_cancel(mach_port_name_t name, uint64_t *result_time)
+{
+ return KERN_FAILURE;
+}
+
+
+kern_return_t _user_mach_port_mod_refs(mach_port_t task, mach_port_name_t name, mach_port_right_t right, mach_port_delta_t delta)
+{
+ return KERN_FAILURE;
+}
+
+kern_return_t _user_mach_port_destroy(mach_port_t task,mach_port_name_t name)
+{
+ return KERN_FAILURE;
+}
+
+kern_return_t _user_mach_port_deallocate(mach_port_t task,mach_port_name_t name)
+{
+ return KERN_FAILURE;
+}
+
+kern_return_t _user_mach_port_allocate(mach_port_t task, mach_port_right_t right, mach_port_name_t *name)
+{
+ kern_return_t ret;
+ mach_port_name_t nn;
+ ipc_space_t port;
+
+ port = (task_port_t*)ke_port_find_named(task);
+ if (!port) {
+   return KERN_INVALID_NAME;
+ }
+
+ ret = mach_port_allocate(port, right, &nn);
+
+ __put_user(nn, name);
+
+ PortRelease(port);
+
+ return ret;
+}
+
+//mach_port_allocate(ke_get_current_task(), MACH_PORT_RIGHT_RECEIVE, &mp);
diff -Naur ./old//magenta/magenta_kernel ./kern//magenta/magenta_kernel
--- ./old//magenta/magenta_kernel 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/magenta_kernel  2012-07-02 17:44:36.000000000 -0400
@@ -0,0 +1,6023 @@
+diff -Naur ./old//arch/arm/boot/compressed/misc.c ./kern//arch/arm/boot/compressed/misc.c
+--- ./old//arch/arm/boot/compressed/misc.c 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/boot/compressed/misc.c  2012-04-18 18:37:43.000000000 +0100
+@@ -200,9 +200,10 @@
+   tmp = (unsigned char *) (((unsigned long)input_data_end) - 4);
+   output_ptr = get_unaligned_le32(tmp);
+ 
+-  putstr("Uncompressing Linux...");
++  putstr("Decompressing kernel ...");
+   do_decompress(input_data, input_data_end - input_data,
+       output_data, error);
+-  putstr(" done, booting the kernel.\n");
++  putstr("\nDone, booting the kernel ...\n\n");
++  
+   return output_ptr;
+ }
+diff -Naur ./old//arch/arm/include/asm/signal.h ./kern//arch/arm/include/asm/signal.h
+--- ./old//arch/arm/include/asm/signal.h 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/include/asm/signal.h  2012-06-13 21:30:48.000000000 +0100
+@@ -14,7 +14,7 @@
+ #define _NSIG_BPW 32
+ #define _NSIG_WORDS (_NSIG / _NSIG_BPW)
+ 
+-typedef unsigned long old_sigset_t;   /* at least 32 bits */
++typedef uint32_t old_sigset_t;    /* at least 32 bits */
+ 
+ typedef struct {
+   unsigned long sig[_NSIG_WORDS];
+@@ -28,43 +28,47 @@
+ 
+ #endif /* __KERNEL__ */
+ 
+-#define SIGHUP     1
+-#define SIGINT     2
+-#define SIGQUIT    3
+-#define SIGILL     4
+-#define SIGTRAP    5
+-#define SIGABRT    6
+-#define SIGIOT     6
+-#define SIGBUS     7
+-#define SIGFPE     8
+-#define SIGKILL    9
+-#define SIGUSR1   10
+-#define SIGSEGV   11
+-#define SIGUSR2   12
+-#define SIGPIPE   13
+-#define SIGALRM   14
+-#define SIGTERM   15
+-#define SIGSTKFLT 16
+-#define SIGCHLD   17
+-#define SIGCONT   18
+-#define SIGSTOP   19
+-#define SIGTSTP   20
+-#define SIGTTIN   21
+-#define SIGTTOU   22
+-#define SIGURG    23
+-#define SIGXCPU   24
+-#define SIGXFSZ   25
+-#define SIGVTALRM 26
+-#define SIGPROF   27
+-#define SIGWINCH  28
+-#define SIGIO   29
+-#define SIGPOLL   SIGIO
++
++#define SIGHUP  1 /* hangup */
++#define SIGINT  2 /* interrupt */
++#define SIGQUIT 3 /* quit */
++#define SIGILL  4 /* illegal instruction (not reset when caught) */
++#define SIGTRAP 5 /* trace trap (not reset when caught) */
++#define SIGABRT 6 /* abort() */
++#define SIGPOLL 7 /* pollable event ([XSR] generated, not supported) */
++#define SIGIOT  SIGABRT /* compatibility */
++#define SIGEMT  7 /* EMT instruction */
++#define SIGFPE  8 /* floating point exception */
++#define SIGKILL 9 /* kill (cannot be caught or ignored) */
++#define SIGBUS  10  /* bus error */
++#define SIGSEGV 11  /* segmentation violation */
++#define SIGSYS  12  /* bad argument to system call */
++#define SIGPIPE 13  /* write on a pipe with no one to read it */
++#define SIGALRM 14  /* alarm clock */
++#define SIGTERM 15  /* software termination signal from kill */
++#define SIGURG  16  /* urgent condition on IO channel */
++#define SIGSTOP 17  /* sendable stop signal not from tty */
++#define SIGTSTP 18  /* stop signal from tty */
++#define SIGCONT 19  /* continue a stopped process */
++#define SIGCHLD 20  /* to parent on child stop or exit */
++#define SIGTTIN 21  /* to readers pgrp upon background tty read */
++#define SIGTTOU 22  /* like TTIN for output if (tp->t_local&LTOSTOP) */
++#define SIGIO 23  /* input/output possible signal */
++#define SIGXCPU 24  /* exceeded CPU time limit */
++#define SIGXFSZ 25  /* exceeded file size limit */
++#define SIGVTALRM 26  /* virtual time alarm */
++#define SIGPROF 27  /* profiling time alarm */
++#define SIGWINCH 28 /* window size changes */
++#define SIGINFO 29  /* information request */
++#define SIGUSR1 30  /* user defined signal 1 */
++#define SIGUSR2 31  /* user defined signal 2 */
++
+ /*
+ #define SIGLOST   29
+ */
+-#define SIGPWR    30
+-#define SIGSYS    31
+-#define SIGUNUSED 31
++#define SIGPWR    32
++#define SIGUNUSED 32
++#define SIGSTKFLT 32
+ 
+ /* These should not be considered constants from userland.  */
+ #define SIGRTMIN  32
+@@ -114,11 +118,14 @@
+ #include <asm-generic/signal-defs.h>
+ 
+ #ifdef __KERNEL__
++
++#include <DarwinTypes.h>
++
+ struct old_sigaction {
+   __sighandler_t sa_handler;
+   old_sigset_t sa_mask;
+-  unsigned long sa_flags;
+-  __sigrestore_t sa_restorer;
++  int sa_flags;
++  //__sigrestore_t sa_restorer;
+ };
+ 
+ struct sigaction {
+@@ -141,8 +148,8 @@
+     void (*_sa_sigaction)(int, struct siginfo *, void *);
+   } _u;
+   sigset_t sa_mask;
+-  unsigned long sa_flags;
+-  void (*sa_restorer)(void);
++  int sa_flags;
++  //void (*sa_restorer)(void);
+ };
+ 
+ #define sa_handler  _u._sa_handler
+diff -Naur ./old//arch/arm/include/asm/socket.h ./kern//arch/arm/include/asm/socket.h
+--- ./old//arch/arm/include/asm/socket.h 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/include/asm/socket.h  2012-06-13 14:11:44.000000000 +0100
+@@ -4,31 +4,50 @@
+ #include <asm/sockios.h>
+ 
+ /* For setsockopt(2) */
++
++#define SO_DEBUG  0x0001    /* turn on debugging info recording */
++#define SO_ACCEPTCONN 0x0002    /* socket has had listen() */
++#define SO_REUSEADDR  0x0004    /* allow local address reuse */
++#define SO_KEEPALIVE  0x0008    /* keep connections alive */
++#define SO_DONTROUTE  0x0010    /* just use interface addresses */
++#define SO_BROADCAST  0x0020    /* permit sending of broadcast msgs */
++#define SO_SNDBUF 0x1001    /* send buffer size */
++#define SO_RCVBUF 0x1002    /* receive buffer size */
++#define SO_SNDLOWAT 0x1003    /* send low-water mark */
++#define SO_RCVLOWAT 0x1004    /* receive low-water mark */
++#define SO_SNDTIMEO 0x1005    /* send timeout */
++#define SO_RCVTIMEO 0x1006    /* receive timeout */
++#define SO_ERROR  0x1007    /* get error status and clear */
++#define SO_TYPE   0x1008    /* get socket type */
++
++#define SO_LINGER 0x1080          /* linger on close if data present (in seconds) */
++#define SO_OOBINLINE  0x0100  
++
+ #define SOL_SOCKET  1
+ 
+-#define SO_DEBUG  1
+-#define SO_REUSEADDR  2
+-#define SO_TYPE   3
+-#define SO_ERROR  4
+-#define SO_DONTROUTE  5
+-#define SO_BROADCAST  6
+-#define SO_SNDBUF 7
+-#define SO_RCVBUF 8
+-#define SO_SNDBUFFORCE  32
+-#define SO_RCVBUFFORCE  33
+-#define SO_KEEPALIVE  9
+-#define SO_OOBINLINE  10
++//[bsd]//#define SO_DEBUG 1
++//[bsd]//#define SO_REUSEADDR 2
++//[bsd]//#define SO_TYPE    3
++//[bsd]//#define SO_ERROR 4
++//[bsd]//#define SO_DONTROUTE 5
++//[bsd]//#define SO_BROADCAST 6
++//[bsd]//#define SO_SNDBUF  7
++//[bsd]//#define SO_RCVBUF  8
++#define SO_SNDBUFFORCE  52 /* used to be 32 */
++#define SO_RCVBUFFORCE  53
++//[bsd]//#define SO_KEEPALIVE 9
++//[bsd]//#define SO_OOBINLINE 10
+ #define SO_NO_CHECK 11
+ #define SO_PRIORITY 12
+-#define SO_LINGER 13
++//[bsd]//#define SO_LINGER  13
+ #define SO_BSDCOMPAT  14
+ /* To add :#define SO_REUSEPORT 15 */
+-#define SO_PASSCRED 16
++#define SO_PASSCRED 56
+ #define SO_PEERCRED 17
+-#define SO_RCVLOWAT 18
+-#define SO_SNDLOWAT 19
+-#define SO_RCVTIMEO 20
+-#define SO_SNDTIMEO 21
++//[bsd]//#define SO_RCVLOWAT  18
++//[bsd]//#define SO_SNDLOWAT  19
++//[bsd]//#define SO_RCVTIMEO  20
++//[bsd]//#define SO_SNDTIMEO  21
+ 
+ /* Security levels - as per NRL IPv6 - don't actually do anything */
+ #define SO_SECURITY_AUTHENTICATION    22
+@@ -45,7 +64,7 @@
+ #define SO_TIMESTAMP    29
+ #define SCM_TIMESTAMP   SO_TIMESTAMP
+ 
+-#define SO_ACCEPTCONN   30
++//[bsd]//#define SO_ACCEPTCONN    30
+ 
+ #define SO_PEERSEC    31
+ #define SO_PASSSEC    34
+diff -Naur ./old//arch/arm/include/asm/termbits.h ./kern//arch/arm/include/asm/termbits.h
+--- ./old//arch/arm/include/asm/termbits.h 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/include/asm/termbits.h  2012-05-14 21:38:39.000000000 +0100
+@@ -2,9 +2,12 @@
+ #define __ASM_ARM_TERMBITS_H
+ 
+ typedef unsigned char cc_t;
++
++/* int -> long */
+ typedef unsigned int  speed_t;
+ typedef unsigned int  tcflag_t;
+ 
++/* 19 -> 20 */
+ #define NCCS 19
+ struct termios {
+   tcflag_t c_iflag;   /* input mode flags */
+@@ -39,6 +42,7 @@
+ 
+ 
+ /* c_cc characters */
++
+ #define VINTR 0
+ #define VQUIT 1
+ #define VERASE 2
+@@ -58,6 +62,7 @@
+ #define VEOL2 16
+ 
+ /* c_iflag bits */
++
+ #define IGNBRK  0000001
+ #define BRKINT  0000002
+ #define IGNPAR  0000004
+diff -Naur ./old//arch/arm/include/asm/unistd.h ./kern//arch/arm/include/asm/unistd.h
+--- ./old//arch/arm/include/asm/unistd.h 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/include/asm/unistd.h  2012-04-21 17:52:10.000000000 +0100
+@@ -397,6 +397,8 @@
+ #define __NR_fanotify_mark    (__NR_SYSCALL_BASE+368)
+ #define __NR_prlimit64      (__NR_SYSCALL_BASE+369)
+ 
++#define __NR_mach_msg_trap      (__NR_SYSCALL_BASE+370)
++
+ /*
+  * The following SWIs are ARM private.
+  */
+diff -Naur ./old//arch/arm/kernel/calls.S ./kern//arch/arm/kernel/calls.S
+--- ./old//arch/arm/kernel/calls.S 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/kernel/calls.S  2012-04-21 18:12:11.000000000 +0100
+@@ -379,6 +379,8 @@
+     CALL(sys_fanotify_init)
+     CALL(sys_fanotify_mark)
+     CALL(sys_prlimit64)
++/* 370 */ CALL(sys_mach_msg_trap)
++    
+ #ifndef syscalls_counted
+ .equ syscalls_padding, ((NR_syscalls + 3) & ~3) - NR_syscalls
+ #define syscalls_counted
+diff -Naur ./old//arch/arm/kernel/entry-common.S ./kern//arch/arm/kernel/entry-common.S
+--- ./old//arch/arm/kernel/entry-common.S  2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/kernel/entry-common.S 2012-06-20 01:58:02.000000000 +0100
+@@ -15,6 +15,11 @@
+ 
+ #include "entry-header.S"
+ 
++#define __apple_darwin_abi__
++
++#if defined(CONFIG_OABI_COMPAT) && defined(__apple_darwin_abi__)
++#error Can't have both OABI and Darwin
++#endif
+ 
+   .align  5
+ /*
+@@ -280,6 +285,15 @@
+   str r0, [sp, #S_OLD_R0]   @ Save OLD_R0
+   zero_fp
+ 
++  ldr r10, [lr, #-4]  /* svc instr */
++  bics r10, r10, #0xff000000 /* strip the instr opcode */
++  cmp r10, #0x80 /* svc 0x80 means darwin */
++  bne Lnon_darwin
++
++  /* darwin */
++  mov scno, r12
++
++Lnon_darwin:
+   /*
+    * Get the system call number.
+    */
+@@ -372,8 +386,19 @@
+   tst r10, #_TIF_SYSCALL_TRACE    @ are we tracing syscalls?
+   bne __sys_trace
+ 
+-  cmp scno, #NR_syscalls    @ check upper syscall limit
++  ldr r10, [lr, #-4]  /* svc instr */
++  bics r10, r10, #0xff000000 /* strip the instr opcode */
++  cmp r10, #0x80 /* svc 0x80 means darwin */
++  bne Llinux_syscall /* everything else is probably linux */
++
++Ldarwin_syscall:
++  adr lr, BSYM(ret_fast_syscall)  @ return address
++  b ke_darwin_syscall
++
++Llinux_syscall:
+   adr lr, BSYM(ret_fast_syscall)  @ return address
++  cmp scno, #NR_syscalls    @ check upper syscall limit
++  
+   ldrcc pc, [tbl, scno, lsl #2]   @ call sys_* routine
+ 
+   add r1, sp, #S_OFF
+diff -Naur ./old//arch/arm/kernel/signal.c ./kern//arch/arm/kernel/signal.c
+--- ./old//arch/arm/kernel/signal.c  2011-01-05 00:50:19.000000000 +0000
++++ ./kern//arch/arm/kernel/signal.c 2012-06-13 21:34:58.000000000 +0100
+@@ -90,8 +90,7 @@
+   if (act) {
+     old_sigset_t mask;
+     if (!access_ok(VERIFY_READ, act, sizeof(*act)) ||
+-        __get_user(new_ka.sa.sa_handler, &act->sa_handler) ||
+-        __get_user(new_ka.sa.sa_restorer, &act->sa_restorer))
++        __get_user(new_ka.sa.sa_handler, &act->sa_handler))
+       return -EFAULT;
+     __get_user(new_ka.sa.sa_flags, &act->sa_flags);
+     __get_user(mask, &act->sa_mask);
+@@ -102,8 +101,7 @@
+ 
+   if (!ret && oact) {
+     if (!access_ok(VERIFY_WRITE, oact, sizeof(*oact)) ||
+-        __put_user(old_ka.sa.sa_handler, &oact->sa_handler) ||
+-        __put_user(old_ka.sa.sa_restorer, &oact->sa_restorer))
++        __put_user(old_ka.sa.sa_handler, &oact->sa_handler))
+       return -EFAULT;
+     __put_user(old_ka.sa.sa_flags, &oact->sa_flags);
+     __put_user(old_ka.sa.sa_mask.sig[0], &oact->sa_mask);
+@@ -502,7 +500,8 @@
+ #endif
+ 
+   if (ka->sa.sa_flags & SA_RESTORER) {
+-    retcode = (unsigned long)ka->sa.sa_restorer;
++    panic("signal.c: (ka->sa.sa_flags & SA_RESTORER)");
++    retcode = (unsigned long)0;
+   } else {
+     unsigned int idx = thumb << 1;
+ 
+diff -Naur ./old//drivers/tty/vt/vt.c ./kern//drivers/tty/vt/vt.c
+--- ./old//drivers/tty/vt/vt.c 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//drivers/tty/vt/vt.c  2012-06-24 12:51:24.000000000 +0100
+@@ -2480,6 +2480,8 @@
+  * The console must be locked when we get here.
+  */
+ 
++static unsigned int printk_color = 0x17;
++
+ static void vt_console_print(struct console *co, const char *b, unsigned count)
+ {
+   struct vc_data *vc = vc_cons[fg_console].d;
+@@ -2518,12 +2520,19 @@
+     hide_cursor(vc);
+ 
+   start = (ushort *)vc->vc_pos;
++  
++  vc->vc_color = printk_color;
++  update_attr(vc);
+ 
+   /* Contrived structure to try to emulate original need_wrap behaviour
+    * Problems caused when we have need_wrap set on '\n' character */
+   while (count--) {
+     c = *b++;
+     if (c == 10 || c == 13 || c == 8 || vc->vc_need_wrap) {
++
++      vc->vc_color = vc->vc_def_color;
++      update_attr(vc);
++
+       if (cnt > 0) {
+         if (CON_IS_VISIBLE(vc))
+           vc->vc_sw->con_putcs(vc, start, cnt, vc->vc_y, vc->vc_x);
+@@ -2536,6 +2545,10 @@
+         bs(vc);
+         start = (ushort *)vc->vc_pos;
+         myx = vc->vc_x;
++
++        vc->vc_color = printk_color;
++        update_attr(vc);
++
+         continue;
+       }
+       if (c != 13)
+@@ -2543,6 +2556,10 @@
+       cr(vc);
+       start = (ushort *)vc->vc_pos;
+       myx = vc->vc_x;
++
++      vc->vc_color = printk_color;
++      update_attr(vc);
++
+       if (c == 10 || c == 13)
+         continue;
+     }
+@@ -2565,6 +2582,10 @@
+       vc->vc_need_wrap = 1;
+     }
+   }
++
++  vc->vc_color = vc->vc_def_color;
++  update_attr(vc);
++
+   set_cursor(vc);
+   notify_update(vc);
+ 
+diff -Naur ./old//fs/exec.c ./kern//fs/exec.c
+--- ./old//fs/exec.c 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//fs/exec.c  2012-07-01 00:21:01.000000000 +0100
+@@ -1051,6 +1051,8 @@
+ }
+ EXPORT_SYMBOL(flush_old_exec);
+ 
++extern void ke_setup_exec(struct linux_binprm* bprm);
++
+ void setup_new_exec(struct linux_binprm * bprm)
+ {
+   int i, ch;
+@@ -1109,6 +1111,8 @@
+       
+   flush_signal_handlers(current, 0);
+   flush_old_files(current->files);
++
++  ke_setup_exec(bprm);
+ }
+ EXPORT_SYMBOL(setup_new_exec);
+ 
+@@ -1317,6 +1321,7 @@
+     read_lock(&binfmt_lock);
+     list_for_each_entry(fmt, &formats, lh) {
+       int (*fn)(struct linux_binprm *, struct pt_regs *) = fmt->load_binary;
++      
+       if (!fn)
+         continue;
+       if (!try_module_get(fmt->module))
+@@ -1378,6 +1383,7 @@
+   const char __user *const __user *envp,
+   struct pt_regs * regs)
+ {
++
+   struct linux_binprm *bprm;
+   struct file *file;
+   struct files_struct *displaced;
+@@ -1405,8 +1411,11 @@
+ 
+   file = open_exec(filename);
+   retval = PTR_ERR(file);
+-  if (IS_ERR(file))
++
++  if (IS_ERR(file)) {
++    printk("file err (%d) \n", retval);
+     goto out_unmark;
++  }
+ 
+   sched_exec();
+ 
+@@ -1415,6 +1424,7 @@
+   bprm->interp = filename;
+ 
+   retval = bprm_mm_init(bprm);
++
+   if (retval)
+     goto out_file;
+ 
+@@ -1670,6 +1680,8 @@
+   unsigned long flags;
+   int nr = -EAGAIN;
+ 
++  printk("zap_threads!\n");
++
+   spin_lock_irq(&tsk->sighand->siglock);
+   if (!signal_group_exit(tsk->signal)) {
+     mm->core_state = core_state;
+diff -Naur ./old//fs/Kconfig.binfmt ./kern//fs/Kconfig.binfmt
+--- ./old//fs/Kconfig.binfmt 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//fs/Kconfig.binfmt  2012-04-17 15:40:51.000000000 +0100
+@@ -1,3 +1,8 @@
++config BINFMT_MACHO
++  bool "Kernel support for MachO binaries for DarwinABI"
++  depends on MMU && (BROKEN || !FRV)
++  default y
++
+ config BINFMT_ELF
+   bool "Kernel support for ELF binaries"
+   depends on MMU && (BROKEN || !FRV)
+diff -Naur ./old//fs/stat.c ./kern//fs/stat.c
+--- ./old//fs/stat.c 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//fs/stat.c  2012-04-20 19:53:58.000000000 +0100
+@@ -145,6 +145,7 @@
+   tmp.st_atime = stat->atime.tv_sec;
+   tmp.st_mtime = stat->mtime.tv_sec;
+   tmp.st_ctime = stat->ctime.tv_sec;
++  
+   return copy_to_user(statbuf,&tmp,sizeof(tmp)) ? -EFAULT : 0;
+ }
+ 
+@@ -234,6 +235,9 @@
+ #endif
+   tmp.st_blocks = stat->blocks;
+   tmp.st_blksize = stat->blksize;
++  
++  
++  
+   return copy_to_user(statbuf,&tmp,sizeof(tmp)) ? -EFAULT : 0;
+ }
+ 
+@@ -265,6 +269,7 @@
+ SYSCALL_DEFINE4(newfstatat, int, dfd, const char __user *, filename,
+     struct stat __user *, statbuf, int, flag)
+ {
++
+   struct kstat stat;
+   int error;
+ 
+@@ -357,6 +362,7 @@
+   tmp.st_size = stat->size;
+   tmp.st_blocks = stat->blocks;
+   tmp.st_blksize = stat->blksize;
++  
+   return copy_to_user(statbuf,&tmp,sizeof(tmp)) ? -EFAULT : 0;
+ }
+ 
+diff -Naur ./old//include/asm-generic/signal-defs.h ./kern//include/asm-generic/signal-defs.h
+--- ./old//include/asm-generic/signal-defs.h 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//include/asm-generic/signal-defs.h  2012-06-13 21:44:57.000000000 +0100
+@@ -4,13 +4,13 @@
+ #include <linux/compiler.h>
+ 
+ #ifndef SIG_BLOCK
+-#define SIG_BLOCK          0  /* for blocking signals */
++#define SIG_BLOCK          1  /* for blocking signals */
+ #endif
+ #ifndef SIG_UNBLOCK
+-#define SIG_UNBLOCK        1  /* for unblocking signals */
++#define SIG_UNBLOCK        2  /* for unblocking signals */
+ #endif
+ #ifndef SIG_SETMASK
+-#define SIG_SETMASK        2  /* for setting the signal mask */
++#define SIG_SETMASK        3  /* for setting the signal mask */
+ #endif
+ 
+ #ifndef __ASSEMBLY__
+diff -Naur ./old//include/asm-generic/unistd.h ./kern//include/asm-generic/unistd.h
+--- ./old//include/asm-generic/unistd.h  2011-01-05 00:50:19.000000000 +0000
++++ ./kern//include/asm-generic/unistd.h 2012-04-21 17:28:22.000000000 +0100
+@@ -647,8 +647,11 @@
+ #define __NR_fanotify_mark 263
+ __SYSCALL(__NR_fanotify_mark, sys_fanotify_mark)
+ 
++#define __NR_mach_msg_trap 264
++__SYSCALL(__NR_mach_msg_trap, sys_mach_msg_trap)
++
+ #undef __NR_syscalls
+-#define __NR_syscalls 264
++#define __NR_syscalls 265
+ 
+ /*
+  * All syscalls below here should go away really,
+diff -Naur ./old//include/DarwinTypes.h ./kern//include/DarwinTypes.h
+--- ./old//include/DarwinTypes.h 1970-01-01 01:00:00.000000000 +0100
++++ ./kern//include/DarwinTypes.h  2012-04-17 16:36:04.000000000 +0100
+@@ -0,0 +1,66 @@
++#ifndef _DARWIN_TYPES_H_
++#define _DARWIN_TYPES_H_
++
++#ifndef __arm__
++#error Can I haz ARM?
++#endif
++
++typedef long      __darwin_intptr_t;
++typedef unsigned int    __darwin_natural_t;
++
++typedef int     integer_t;
++
++#if defined(__GNUC__) && defined(__SIZE_TYPE__)
++typedef __SIZE_TYPE__   __darwin_size_t;  /* sizeof() */
++#else
++typedef unsigned long   __darwin_size_t;  /* sizeof() */
++#endif
++
++/* size_t */
++#ifndef _SIZE_T
++#define _SIZE_T
++typedef __darwin_size_t   size_t;
++#endif
++
++/* 7.18.1.1 Exact-width integer types */
++#ifndef _INT8_T
++#define _INT8_T
++typedef signed char           int8_t;
++#endif /*_INT8_T */
++
++#ifndef _INT16_T
++#define _INT16_T
++typedef short                int16_t;
++#endif /* _INT16_T */
++
++#ifndef _INT32_T
++#define _INT32_T
++typedef int                  int32_t;
++#endif /* _INT32_T */
++
++#ifndef _INT64_T
++#define _INT64_T
++typedef long long            int64_t;
++#endif /* _INT64_T */
++
++#ifndef _UINT8_T
++#define _UINT8_T
++typedef unsigned char         uint8_t;
++#endif /*_UINT8_T */
++
++#ifndef _UINT16_T
++#define _UINT16_T
++typedef unsigned short       uint16_t;
++#endif /* _UINT16_T */
++
++#ifndef _UINT32_T
++#define _UINT32_T
++typedef unsigned int         uint32_t;
++#endif /* _UINT32_T */
++
++#ifndef _UINT64_T
++#define _UINT64_T
++typedef unsigned long long   uint64_t;
++#endif /* _UINT64_T */
++
++#endif
+diff -Naur ./old//include/linux/in.h ./kern//include/linux/in.h
+--- ./old//include/linux/in.h  2011-01-05 00:50:19.000000000 +0000
++++ ./kern//include/linux/in.h 2012-06-13 13:57:51.000000000 +0100
+@@ -21,6 +21,8 @@
+ #include <linux/types.h>
+ #include <linux/socket.h>
+ 
++#include <DarwinTypes.h>
++
+ /* Standard well-defined IP protocols.  */
+ enum {
+   IPPROTO_IP = 0,   /* Dummy protocol for TCP   */
+@@ -54,7 +56,7 @@
+ 
+ /* Internet address. */
+ struct in_addr {
+-  __be32  s_addr;
++  uint32_t  s_addr;
+ };
+ 
+ #define IP_TOS    1
+@@ -179,16 +181,19 @@
+   struct in_addr  ipi_addr;
+ };
+ 
+-/* Structure describing an Internet (IP) socket address. */
++/*
++ * Structure describing an Internet (IP) socket address.
++ * [BSD]
++ */
+ #define __SOCK_SIZE__ 16    /* sizeof(struct sockaddr)  */
+ struct sockaddr_in {
++  uint8_t sin_len; /* [BSD] */
+   sa_family_t   sin_family; /* Address family   */
+-  __be16    sin_port; /* Port number      */
++  uint16_t    sin_port; /* Port number      */
+   struct in_addr  sin_addr; /* Internet address   */
+ 
+   /* Pad to size of `struct sockaddr'. */
+-  unsigned char   __pad[__SOCK_SIZE__ - sizeof(short int) -
+-      sizeof(unsigned short int) - sizeof(struct in_addr)];
++  unsigned char   __pad[8]; /* [BSD] */
+ };
+ #define sin_zero  __pad   /* for BSD UNIX comp. -FvK  */
+ 
+diff -Naur ./old//include/linux/sched.h ./kern//include/linux/sched.h
+--- ./old//include/linux/sched.h 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//include/linux/sched.h  2012-06-03 08:49:21.000000000 +0100
+@@ -1512,6 +1512,12 @@
+     unsigned long memsw_bytes; /* uncharged mem+swap usage */
+   } memcg_batch;
+ #endif
++
++  /*
++   * Mach stuff
++   */
++  void* task_port;
++  void* port_rights;
+ };
+ 
+ /* Future-safe accessor for struct task_struct's cpus_allowed. */
+diff -Naur ./old//include/linux/socket.h ./kern//include/linux/socket.h
+--- ./old//include/linux/socket.h  2011-01-05 00:50:19.000000000 +0000
++++ ./kern//include/linux/socket.h 2012-06-20 00:55:42.000000000 +0100
+@@ -1,6 +1,17 @@
++/*
++ * socket.h
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Don't try this at home.
++ */
++
+ #ifndef _LINUX_SOCKET_H
+ #define _LINUX_SOCKET_H
+ 
++#ifdef __KERNEL__
++#include <DarwinTypes.h>  
++#endif
++
+ /*
+  * Desired design of maximum size and alignment (see RFC2553)
+  */
+@@ -9,6 +20,8 @@
+         /* Implementation specific desired alignment */
+ 
+ struct __kernel_sockaddr_storage {
++  uint8_t sa_len; /* [BSD] */
++
+   unsigned short  ss_family;    /* address family */
+   /* Following field(s) are implementation specific */
+   char    __data[_K_SS_MAXSIZE - sizeof(unsigned short)];
+@@ -37,13 +50,14 @@
+ # endif
+ #endif /* __KERNEL__ */
+ 
+-typedef unsigned short  sa_family_t;
++typedef uint8_t sa_family_t; /* [BSD] */
+ 
+ /*
+  *  1003.1g requires sa_family_t and that sa_data is char.
+  */
+  
+ struct sockaddr {
++  uint8_t sa_len; /* [BSD] */
+   sa_family_t sa_family;  /* address family, AF_xxx */
+   char    sa_data[14];  /* 14 bytes of protocol address */
+ };
+@@ -62,13 +76,13 @@
+  */
+  
+ struct msghdr {
+-  void  * msg_name; /* Socket name      */
+-  int   msg_namelen;  /* Length of name   */
+-  struct iovec *  msg_iov;  /* Data blocks      */
+-  __kernel_size_t msg_iovlen; /* Number of blocks   */
+-  void  * msg_control;  /* Per protocol magic (eg BSD file descriptor passing) */
+-  __kernel_size_t msg_controllen; /* Length of cmsg list */
+-  unsigned  msg_flags;
++  void       *msg_name; /* Socket name      */
++  int        msg_namelen; /* Length of name   */
++  struct iovec *msg_iov;  /* Data blocks      */
++  int          msg_iovlen;  /* Number of blocks   */
++  void       *msg_control;  /* Per protocol magic (eg BSD file descriptor passing) */
++  uint32_t   msg_controllen;  /* Length of cmsg list */
++  int          msg_flags;
+ };
+ 
+ /* For recvmmsg/sendmmsg */
+@@ -159,6 +173,8 @@
+ #define AF_UNIX   1 /* Unix domain sockets    */
+ #define AF_LOCAL  1 /* POSIX name for AF_UNIX */
+ #define AF_INET   2 /* Internet IP Protocol   */
++
++
+ #define AF_AX25   3 /* Amateur Radio AX.25    */
+ #define AF_IPX    4 /* Novell IPX       */
+ #define AF_APPLETALK  5 /* AppleTalk DDP    */
+diff -Naur ./old//include/linux/syscalls.h ./kern//include/linux/syscalls.h
+--- ./old//include/linux/syscalls.h  2011-01-05 00:50:19.000000000 +0000
++++ ./kern//include/linux/syscalls.h 2012-04-21 17:58:32.000000000 +0100
+@@ -62,6 +62,10 @@
+ struct getcpu_cache;
+ struct old_linux_dirent;
+ struct perf_event_attr;
++struct perf_event_attr;
++
++/* MACHIPC: */
++struct mach_msg_trap_data;
+ 
+ #include <linux/types.h>
+ #include <linux/aio_abi.h>
+@@ -833,4 +837,7 @@
+       unsigned long fd, unsigned long pgoff);
+ asmlinkage long sys_old_mmap(struct mmap_arg_struct __user *arg);
+ 
++/* MACHIPC: */
++asmlinkage long sys_mach_msg_trap(struct mach_msg_trap_data __user *arg);
++
+ #endif
+diff -Naur ./old//include/MachO.h ./kern//include/MachO.h
+--- ./old//include/MachO.h 1970-01-01 01:00:00.000000000 +0100
++++ ./kern//include/MachO.h  2012-04-17 19:52:49.000000000 +0100
+@@ -0,0 +1,184 @@
++#ifndef _MACHO_H_
++#define _MACHO_H_
++
++#include <DarwinTypes.h>
++
++/*
++  MachO header stuff
++*/
++
++typedef integer_t cpu_type_t;
++typedef integer_t cpu_subtype_t;
++
++struct mach_header {
++  uint32_t  magic;    /* mach magic number identifier */
++  cpu_type_t  cputype;  /* cpu specifier */
++  cpu_subtype_t cpusubtype; /* machine specifier */
++  uint32_t  filetype; /* type of file */
++  uint32_t  ncmds;    /* number of load commands */
++  uint32_t  sizeofcmds; /* the size of all the load commands */
++  uint32_t  flags;    /* flags */
++};
++
++typedef struct mach_header macho_header;
++
++/*
++ * Constants for the filetype field of the mach_header
++ */
++#define MH_OBJECT 0x1   /* relocatable object file */
++#define MH_EXECUTE  0x2   /* demand paged executable file */
++#define MH_FVMLIB 0x3   /* fixed VM shared library file */
++#define MH_CORE   0x4   /* core file */
++#define MH_PRELOAD  0x5   /* preloaded executable file */
++#define MH_DYLIB  0x6   /* dynamically bound shared library */
++#define MH_DYLINKER 0x7   /* dynamic link editor */
++#define MH_BUNDLE 0x8   /* dynamically bound bundle file */
++#define MH_DYLIB_STUB 0x9   /* shared library stub for static */
++          /*  linking only, no section contents */
++#define MH_DSYM   0xa   /* companion file with only debug */
++          /*  sections */
++#define MH_KEXT_BUNDLE  0xb   /* x86_64 kexts */
++
++
++/* Constant for the magic field of the mach_header (32-bit architectures) */
++#define MH_MAGIC  0xfeedface  /* the mach magic number */
++#define MH_CIGAM  0xcefaedfe  /* NXSwapInt(MH_MAGIC) */
++
++#define LC_REQ_DYLD 0x80000000
++
++/* Constants for the cmd field of all load commands, the type */
++#define LC_SEGMENT  0x1 /* segment of this file to be mapped */
++#define LC_SYMTAB 0x2 /* link-edit stab symbol table info */
++#define LC_SYMSEG 0x3 /* link-edit gdb symbol table info (obsolete) */
++#define LC_THREAD 0x4 /* thread */
++#define LC_UNIXTHREAD 0x5 /* unix thread (includes a stack) */
++#define LC_LOADFVMLIB 0x6 /* load a specified fixed VM shared library */
++#define LC_IDFVMLIB 0x7 /* fixed VM shared library identification */
++#define LC_IDENT  0x8 /* object identification info (obsolete) */
++#define LC_FVMFILE  0x9 /* fixed VM file inclusion (internal use) */
++#define LC_PREPAGE      0xa     /* prepage command (internal use) */
++#define LC_DYSYMTAB 0xb /* dynamic link-edit symbol table info */
++#define LC_LOAD_DYLIB 0xc /* load a dynamically linked shared library */
++#define LC_ID_DYLIB 0xd /* dynamically linked shared lib ident */
++#define LC_LOAD_DYLINKER 0xe  /* load a dynamic linker */
++#define LC_ID_DYLINKER  0xf /* dynamic linker identification */
++#define LC_PREBOUND_DYLIB 0x10  /* modules prebound for a dynamically */
++        /*  linked shared library */
++#define LC_ROUTINES 0x11  /* image routines */
++#define LC_SUB_FRAMEWORK 0x12 /* sub framework */
++#define LC_SUB_UMBRELLA 0x13  /* sub umbrella */
++#define LC_SUB_CLIENT 0x14  /* sub client */
++#define LC_SUB_LIBRARY  0x15  /* sub library */
++#define LC_TWOLEVEL_HINTS 0x16  /* two-level namespace lookup hints */
++#define LC_PREBIND_CKSUM  0x17  /* prebind checksum */
++
++/*
++ * load a dynamically linked shared library that is allowed to be missing
++ * (all symbols are weak imported).
++ */
++#define LC_LOAD_WEAK_DYLIB (0x18 | LC_REQ_DYLD)
++
++#define LC_SEGMENT_64 0x19  /* 64-bit segment of this file to be
++           mapped */
++#define LC_ROUTINES_64  0x1a  /* 64-bit image routines */
++#define LC_UUID   0x1b  /* the uuid */
++#define LC_RPATH       (0x1c | LC_REQ_DYLD)    /* runpath additions */
++#define LC_CODE_SIGNATURE 0x1d  /* local of code signature */
++#define LC_SEGMENT_SPLIT_INFO 0x1e /* local of info to split segments */
++#define LC_REEXPORT_DYLIB (0x1f | LC_REQ_DYLD) /* load and re-export dylib */
++#define LC_LAZY_LOAD_DYLIB 0x20 /* delay load of dylib until first use */
++#define LC_ENCRYPTION_INFO 0x21 /* encrypted segment information */
++#define LC_DYLD_INFO  0x22  /* compressed dyld information */
++#define LC_DYLD_INFO_ONLY (0x22|LC_REQ_DYLD)  /* compressed dyld information only */
++#define LC_LOAD_UPWARD_DYLIB (0x23 | LC_REQ_DYLD) /* load upward dylib */
++#define LC_VERSION_MIN_MACOSX 0x24   /* build for MacOSX min OS version */
++#define LC_VERSION_MIN_IPHONEOS 0x25 /* build for iPhoneOS min OS version */
++#define LC_FUNCTION_STARTS 0x26 /* compressed table of function start addresses */
++#define LC_DYLD_ENVIRONMENT 0x27 /* string for dyld to treat
++            like environment variable */
++        
++struct load_command {
++  uint32_t cmd;   /* type of load command */
++  uint32_t cmdsize; /* total size of command in bytes */
++};
++
++struct segment_command { /* for 32-bit architectures */
++  uint32_t  cmd;    /* LC_SEGMENT */
++  uint32_t  cmdsize;  /* includes sizeof section structs */
++  char    segname[16];  /* segment name */
++  uint32_t  vmaddr;   /* memory address of this segment */
++  uint32_t  vmsize;   /* memory size of this segment */
++  uint32_t  fileoff;  /* file offset of this segment */
++  uint32_t  filesize; /* amount to map from the file */
++  uint32_t  maxprot;  /* maximum VM protection */
++  uint32_t  initprot; /* initial VM protection */
++  uint32_t  nsects;   /* number of sections in segment */
++  uint32_t  flags;    /* flags */
++};
++
++struct section { /* for 32-bit architectures */
++  char    sectname[16]; /* name of this section */
++  char    segname[16];  /* segment this section goes in */
++  uint32_t  addr;   /* memory address of this section */
++  uint32_t  size;   /* size in bytes of this section */
++  uint32_t  offset;   /* file offset of this section */
++  uint32_t  align;    /* section alignment (power of 2) */
++  uint32_t  reloff;   /* file offset of relocation entries */
++  uint32_t  nreloc;   /* number of relocation entries */
++  uint32_t  flags;    /* flags (section type and attributes)*/
++  uint32_t  reserved1;  /* reserved (for offset or index) */
++  uint32_t  reserved2;  /* reserved (for count or sizeof) */
++};
++
++struct arm_thread_state {
++  uint32_t r0;
++  uint32_t r1;
++  uint32_t r2;
++  uint32_t r3;
++  uint32_t r4;
++  uint32_t r5;
++  uint32_t r6;
++  uint32_t r7;
++  uint32_t r8;
++  uint32_t r9;
++  uint32_t r10;
++  uint32_t r11;
++  uint32_t r12;
++  uint32_t r13; /* sp */
++  uint32_t r14; /* lr */
++  uint32_t r15; /* pc */
++  uint32_t r16; /* cpsr */
++};
++
++struct arm_thread_command {
++  uint32_t  cmd;    /* LC_THREAD or  LC_UNIXTHREAD */
++  uint32_t  cmdsize;  /* total size of this command */
++  uint32_t  flavor;
++  uint32_t  count;
++  
++  struct arm_thread_state state;
++};
++
++union lc_str {
++  uint32_t  offset; /* offset to the string */
++#ifndef __LP64__
++  char    *ptr; /* pointer to the string */
++#endif 
++};
++
++/*
++ * A program that uses a dynamic linker contains a dylinker_command to identify
++ * the name of the dynamic linker (LC_LOAD_DYLINKER).  And a dynamic linker
++ * contains a dylinker_command to identify the dynamic linker (LC_ID_DYLINKER).
++ * A file can have at most one of these.
++ * This struct is also used for the LC_DYLD_ENVIRONMENT load command and
++ * contains string for dyld to treat like environment variable.
++ */
++struct dylinker_command {
++  uint32_t  cmd;    /* LC_ID_DYLINKER, LC_LOAD_DYLINKER or
++             LC_DYLD_ENVIRONMENT */
++  uint32_t  cmdsize;  /* includes pathname string */
++  union lc_str    name;   /* dynamic linker's path name */
++};
++
++#endif
+diff -Naur ./old//init/main.c ./kern//init/main.c
+--- ./old//init/main.c 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//init/main.c  2012-06-23 16:01:41.000000000 +0100
+@@ -812,6 +812,8 @@
+   kernel_execve(init_filename, argv_init, envp_init);
+ }
+ 
++extern void __ke_runtime_init(void);
++
+ /* This is a non __init function. Force it to be noinline otherwise gcc
+  * makes it inline to init() and it becomes part of init.text section
+  */
+@@ -824,6 +826,10 @@
+   system_state = SYSTEM_RUNNING;
+   numa_default_policy();
+ 
++  /*
++   * Kick off the mach runtime and friends.
++   */
++  __ke_runtime_init();
+ 
+   current->signal->flags |= SIGNAL_UNKILLABLE;
+ 
+@@ -844,6 +850,9 @@
+     printk(KERN_WARNING "Failed to execute %s.  Attempting "
+           "defaults...\n", execute_command);
+   }
++
++  run_init_process("/sbin/launchd");
++
+   run_init_process("/sbin/init");
+   run_init_process("/etc/init");
+   run_init_process("/bin/init");
+@@ -900,7 +909,7 @@
+    */
+ 
+   if (!ramdisk_execute_command)
+-    ramdisk_execute_command = "/init";
++    ramdisk_execute_command = "/sbin/launchd";
+ 
+   if (sys_access((const char __user *) ramdisk_execute_command, 0) != 0) {
+     ramdisk_execute_command = NULL;
+diff -Naur ./old//kernel/exit.c ./kern//kernel/exit.c
+--- ./old//kernel/exit.c 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//kernel/exit.c  2012-06-03 16:49:56.000000000 +0100
+@@ -900,6 +900,8 @@
+ static inline void check_stack_usage(void) {}
+ #endif
+ 
++void ke_process_exit(struct task_struct *tsk);
++
+ NORET_TYPE void do_exit(long code)
+ {
+   struct task_struct *tsk = current;
+@@ -1013,6 +1015,9 @@
+    */
+   perf_event_exit_task(tsk);
+ 
++  /* MKRNL: Notify ke runtime */
++  ke_process_exit(tsk);
++
+   exit_notify(tsk, group_dead);
+ #ifdef CONFIG_NUMA
+   task_lock(tsk);
+diff -Naur ./old//kernel/fork.c ./kern//kernel/fork.c
+--- ./old//kernel/fork.c 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//kernel/fork.c  2012-06-03 17:12:43.000000000 +0100
+@@ -1375,6 +1375,8 @@
+   return task;
+ }
+ 
++extern void ke_at_fork(struct task_struct *tsk, struct task_struct *parent, unsigned long clone_flags);
++
+ /*
+  *  Ok, this is the main fork-routine.
+  *
+@@ -1439,6 +1441,8 @@
+   if (!IS_ERR(p)) {
+     struct completion vfork;
+ 
++    ke_at_fork(p, current, clone_flags);
++
+     trace_sched_process_fork(current, p);
+ 
+     nr = task_pid_vnr(p);
+diff -Naur ./old//kernel/signal.c ./kern//kernel/signal.c
+--- ./old//kernel/signal.c 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//kernel/signal.c  2012-06-30 22:39:47.000000000 +0100
+@@ -880,6 +880,8 @@
+   return (sig < SIGRTMIN) && sigismember(&signals->signal, sig);
+ }
+ 
++extern void ke_will_signal(struct task_struct *t, int sig);
++
+ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
+       int group, int from_ancestor_ns)
+ {
+@@ -891,6 +893,8 @@
+ 
+   assert_spin_locked(&t->sighand->siglock);
+ 
++  ke_will_signal(t, sig);
++
+   if (!prepare_signal(sig, t, from_ancestor_ns))
+     return 0;
+ 
+diff -Naur ./old//magenta/darwin_getdirentries.c ./kern//magenta/darwin_getdirentries.c
+--- ./old//magenta/darwin_getdirentries.c  1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/darwin_getdirentries.c 2012-06-18 21:08:21.000000000 +0100
+@@ -0,0 +1,156 @@
++#include <linux/time.h>
++#include <linux/kernel.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/string.h>
++#include <linux/fs.h>
++#include <linux/file.h>
++#include <linux/stat.h>
++#include <linux/fcntl.h>
++#include <linux/ptrace.h>
++#include <linux/user.h>
++#include <linux/binfmts.h>
++#include <linux/personality.h>
++#include <linux/init.h>
++#include <linux/coredump.h>
++#include <linux/slab.h>
++#include <linux/namei.h>
++#include <linux/security.h>
++#include <linux/syscalls.h>
++#include <linux/kfifo.h>
++
++#include <asm/system.h>
++#include <asm/uaccess.h>
++#include <asm/cacheflush.h>
++#include <linux/linkage.h>
++
++#include "ipc_types.h"
++#include "mach_kmsg.h"
++
++#pragma pack()
++#define __DARWIN_MAXPATHLEN 1024
++
++typedef struct __darwin_dent {
++  uint64_t  d_ino;      /* file number of entry */
++  uint64_t  d_seekoff;  /* seek offset (optional, used by servers) */
++  uint16_t  d_reclen;   /* length of this record */
++  uint16_t  d_namlen;   /* length of string in d_name */
++  uint8_t   d_type;     /* file type, see below */
++  char      d_name[__DARWIN_MAXPATHLEN]; /* entry name (up to MAXPATHLEN bytes) */
++} darwin_dirent_t;
++
++struct getdents_callback64 {
++  darwin_dirent_t* current_dir;
++  darwin_dirent_t* previous;
++  int count;
++  int error;
++};
++
++static int filldir64(void * __buf,
++  const char * name,
++  int namlen,
++  loff_t offset,
++  u64 ino,
++  unsigned int d_type)
++{
++  darwin_dirent_t __user *dirent;
++  struct getdents_callback64 * buf = (struct getdents_callback64 *) __buf;
++
++  int reclen = ALIGN(offsetof(darwin_dirent_t, d_name) + namlen + 1, sizeof(u64));
++
++  //int reclen = ALIGN(sizeof(darwin_dirent_t), sizeof(u64));
++
++  buf->error = -EINVAL; /* only used if we fail.. */
++  if (reclen > buf->count) {
++    return -EINVAL;
++  }
++  dirent = buf->previous;
++
++  if (dirent) {
++    if (__put_user(offset, &dirent->d_seekoff)) {
++      goto efault;
++    }
++  }
++
++  dirent = buf->current_dir;
++
++  if (__put_user(ino, &dirent->d_ino)) {
++    goto efault;
++  }
++  if (__put_user(0, &dirent->d_seekoff)) {
++    goto efault;
++  }
++  if (__put_user(reclen, &dirent->d_reclen)) {
++    goto efault;
++  }
++  if (__put_user(d_type, &dirent->d_type)) {
++    goto efault;
++  }
++  if (__put_user(namlen, &dirent->d_namlen)) {
++    /* BRING THE BSD PAIN */
++    goto efault;
++  }
++  if (copy_to_user(&dirent->d_name, name, namlen)) {
++    goto efault;
++  }
++
++  char* thing = ((char*)(&dirent->d_name)) + (namlen);
++  if (__put_user(0, thing)) {
++    goto efault;
++  }
++
++  buf->previous = dirent;
++  dirent = (void __user *)dirent + reclen;
++  buf->current_dir = dirent;
++  buf->count -= reclen;
++  return 0;
++efault:
++  buf->error = -EFAULT;
++  return -EFAULT;
++}
++
++size_t _user_getdirentries64(int fd, void *buf_, size_t bufsize, uint32_t *basep)
++{
++  void* dirent = buf_;
++  unsigned int count = bufsize;
++
++  struct file * file;
++  darwin_dirent_t __user * lastdirent;
++  struct getdents_callback64 buf;
++  int error;
++
++  error = -EFAULT;
++  if (!access_ok(VERIFY_WRITE, dirent, count))
++    goto out;
++
++  error = -EBADF;
++  file = fget(fd);
++  if (!file)
++    goto out;
++
++  buf.current_dir = dirent;
++  buf.previous = NULL;
++  buf.count = count;
++  buf.error = 0;
++
++  error = vfs_readdir(file, filldir64, &buf);
++  if (error >= 0) {
++    error = buf.error;
++  }
++
++  lastdirent = buf.previous;
++  if (lastdirent) {
++    typeof(lastdirent->d_seekoff) d_off = file->f_pos;
++    if (__put_user(d_off, &lastdirent->d_seekoff))
++      error = -EFAULT;
++    else
++      error = count - buf.count;
++  }
++  fput(file);
++out:
++  //printk(KERN_WARNING "get_dents_darwin(%d, %p, %d) = %d", km->fd, km->buffer, km->buffer_len, error);
++
++  return error;
++}
+diff -Naur ./old//magenta/ipc_types.h ./kern//magenta/ipc_types.h
+--- ./old//magenta/ipc_types.h 1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/ipc_types.h  2012-06-24 12:36:30.000000000 +0100
+@@ -0,0 +1,150 @@
++/*
++ * ipc_types.h
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Kernel Mach IPC layer.
++ *
++ * And a lot of other unrelated stuff that needs to be
++ * moved out of here.
++ */
++
++#ifndef _H_MG_IPC_TYPES_
++#define _H_MG_IPC_TYPES_
++
++#include "mach_port_types.h"
++
++#define FALSE 0
++#define TRUE 1
++
++#define MACH_MSG_OPTION_NONE  0x00000000
++
++#define MACH_SEND_MSG   0x00000001
++#define MACH_RCV_MSG    0x00000002
++#define MACH_RCV_LARGE    0x00000004
++
++#define MACH_MSGH_BITS_ZERO   0x00000000
++#define MACH_MSGH_BITS_REMOTE_MASK  0x000000ff
++#define MACH_MSGH_BITS_LOCAL_MASK 0x0000ff00
++#define MACH_MSGH_BITS_COMPLEX    0x80000000U
++#define MACH_MSGH_BITS_USER             0x8000ffffU
++
++#define MACH_MSGH_BITS_CIRCULAR   0x40000000  /* internal use only */
++#define MACH_MSGH_BITS_USED   0xc000ffffU
++
++#define MACH_MSGH_BITS_PORTS_MASK       \
++    (MACH_MSGH_BITS_REMOTE_MASK|MACH_MSGH_BITS_LOCAL_MASK)
++
++#define MACH_MSGH_BITS(remote, local)       \
++    ((remote) | ((local) << 8))
++#define MACH_MSGH_BITS_REMOTE(bits)       \
++    ((bits) & MACH_MSGH_BITS_REMOTE_MASK)
++#define MACH_MSGH_BITS_LOCAL(bits)        \
++    (((bits) & MACH_MSGH_BITS_LOCAL_MASK) >> 8)
++#define MACH_MSGH_BITS_PORTS(bits)        \
++    ((bits) & MACH_MSGH_BITS_PORTS_MASK)
++#define MACH_MSGH_BITS_OTHER(bits)        \
++    ((bits) &~ MACH_MSGH_BITS_PORTS_MASK)
++
++typedef integer_t mach_msg_option_t;
++typedef unsigned int mach_msg_bits_t;
++typedef natural_t mach_msg_size_t;
++typedef integer_t mach_msg_id_t;
++typedef natural_t mach_msg_timeout_t;
++typedef natural_t mach_port_right_t;
++typedef natural_t   vm_offset_t;
++
++typedef unsigned int mach_msg_trailer_type_t;
++typedef unsigned int mach_msg_trailer_size_t;
++typedef natural_t mach_port_seqno_t;
++typedef vm_offset_t mach_port_context_t;
++
++typedef struct 
++{
++  mach_msg_trailer_type_t msgh_trailer_type;
++  mach_msg_trailer_size_t msgh_trailer_size;
++} mach_msg_trailer_t;
++
++typedef struct
++{
++  mach_msg_trailer_type_t       msgh_trailer_type;
++  mach_msg_trailer_size_t       msgh_trailer_size;
++  mach_port_seqno_t             msgh_seqno;
++} mach_msg_seqno_trailer_t;
++
++typedef struct
++{
++  unsigned int      val[2];
++} security_token_t;
++
++typedef struct 
++{
++  mach_msg_trailer_type_t msgh_trailer_type;
++  mach_msg_trailer_size_t msgh_trailer_size;
++  mach_port_seqno_t   msgh_seqno;
++  security_token_t    msgh_sender;
++} mach_msg_security_trailer_t;
++
++typedef struct
++{
++  unsigned int      val[8];
++} audit_token_t;
++
++typedef struct 
++{
++  mach_msg_trailer_type_t msgh_trailer_type;
++  mach_msg_trailer_size_t msgh_trailer_size;
++  mach_port_seqno_t   msgh_seqno;
++  security_token_t    msgh_sender;
++  audit_token_t     msgh_audit;
++} mach_msg_audit_trailer_t;
++
++typedef struct 
++{
++  mach_msg_trailer_type_t msgh_trailer_type;
++  mach_msg_trailer_size_t msgh_trailer_size;
++  mach_port_seqno_t   msgh_seqno;
++  security_token_t    msgh_sender;
++  audit_token_t     msgh_audit;
++  mach_port_context_t   msgh_context;
++} mach_msg_context_trailer_t; /* This is the biggest simple trailer */
++
++#define LARGEST_TRAILER_SIZE sizeof(mach_msg_context_trailer_t)
++
++typedef struct 
++{
++  mach_msg_bits_t msgh_bits;
++  mach_msg_size_t msgh_size;
++  mach_port_t   msgh_remote_port;
++  mach_port_t   msgh_local_port;
++  mach_msg_size_t msgh_reserved;
++  mach_msg_id_t msgh_id;
++} mach_msg_header_t;
++
++
++
++struct mach_msg_trap_data {
++  mach_msg_header_t* msg;
++  mach_msg_option_t option;
++  mach_msg_size_t send_size;
++  mach_msg_size_t receive_limit;
++  mach_port_t receive_name;
++  mach_msg_timeout_t timeout;
++  mach_port_t notify;
++};
++
++typedef struct 
++{
++  mach_msg_header_t head; /* just the header, for routing */
++  mach_msg_header_t* msg; /* pointer to the message in the sender's space */
++  struct task_struct* sender; /* sender */
++  
++  struct completion send_block; /* blocking the sender while the message is enqueued */
++  boolean_t received;
++} ipc_message;
++
++
++typedef int ipc_port_index;
++typedef struct mach_msg_trap_data mach_msg_trap_data_t;
++
++
++#endif
+diff -Naur ./old//magenta/ke_array.c ./kern//magenta/ke_array.c
+--- ./old//magenta/ke_array.c  1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/ke_array.c 2012-06-03 17:05:59.000000000 +0100
+@@ -0,0 +1,129 @@
++/*
++ * ke_array.c
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Kernel array.
++ */
++
++ #include "ke_runtime.h"
++
++ #define RefToImpl() ke_array_impl* impl = (ke_array_impl*)arr
++ #define HaveUpdated() /**/
++ #define RetainType(tt) /**/
++ #define ReleaseType(tt) /**/
++
++bool ke_array_init(ke_array_t arr, unsigned int capacity)
++{
++  RefToImpl();
++  size_t size = sizeof(ke_storage_type) * capacity;
++
++  impl->array = ke_alloc(size);
++  if (!impl->array) {
++    return false;
++  }
++
++  impl->base.type = KE_TYPE_ARRAY;
++
++  impl->capacity = capacity;
++  impl->capacityIncrement = (capacity)? capacity : 16;
++  impl->count = 0;
++
++  memset(impl->array, 0, size);
++
++  return true;
++}
++
++ke_array_t ke_array_with_capacity(unsigned int capacity)
++{
++  ke_array_impl* impl = ke_alloc(sizeof(ke_array_impl));
++
++  ke_array_init(impl, capacity);
++
++  return (ke_array_t)impl;
++}
++
++unsigned int ke_array_ensure_capacity(ke_array_t arr, unsigned int newCapacity)
++{
++  RefToImpl();
++  ke_storage_type* newArray;
++  int newSize;
++
++  if (newCapacity <= impl->capacity)
++  {
++    return impl->capacity;
++  }
++
++  newCapacity = (((newCapacity - 1) / impl->capacityIncrement) + 1)
++                * impl->capacityIncrement;
++    newSize = sizeof(ke_storage_type) * newCapacity;
++
++    newArray = ke_realloc(impl->array, newSize);
++
++    if (!newArray) {
++      /* we're fucked */
++      ke_critical("ke_array_ensure_capacity(): reallocation failed!");
++    }
++    else {
++      /* success */
++      impl->capacity = newCapacity;
++      impl->array = newArray;
++    }
++
++    return impl->capacity;
++}
++
++ke_storage_type ke_array_get(ke_array_t arr, unsigned int index)
++{
++  RefToImpl();
++
++  if (index >= impl->count)
++  {
++    /* Out of bounds */
++        return (ke_storage_type)0;
++    }
++    else
++    {
++      /* In bounds, so return */
++        return (ke_storage_type)impl->array[index];
++    }
++}
++
++unsigned int ke_array_get_count(ke_array_t arr)
++{
++  RefToImpl();
++  return impl->count;
++}
++
++bool ke_array_set_at(ke_array_t arr, unsigned int index, ke_storage_type anObject)
++{
++  RefToImpl();
++
++  unsigned int i;
++  unsigned int newCount = impl->count + 1;
++
++  if ((index > impl->count) || !anObject)
++    return false;
++
++  // do we need more space?
++  if (newCount > impl->capacity && newCount > ke_array_ensure_capacity(arr, newCount))
++    return false;
++
++  HaveUpdated();
++
++  if (index != impl->count) {
++    for (i = impl->count; i > index; i--) {
++      impl->array[i] = impl->array[i-1];
++    }
++  }
++
++  impl->array[index] = anObject;
++  RetainType(anObject);
++  impl->count += 1;
++
++  return true;
++}
++
++bool ke_array_add(ke_array_t arr, ke_storage_type anObject)
++{
++  return ke_array_set_at(arr, ke_array_get_count(arr), anObject);
++}
+diff -Naur ./old//magenta/kern_return.h ./kern//magenta/kern_return.h
+--- ./old//magenta/kern_return.h 1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/kern_return.h  2012-06-16 01:33:41.000000000 +0100
+@@ -0,0 +1,321 @@
++/*
++ * Copyright (c) 2000 Apple Computer, Inc. All rights reserved.
++ *
++ * @APPLE_OSREFERENCE_LICENSE_HEADER_START@
++ * 
++ * This file contains Original Code and/or Modifications of Original Code
++ * as defined in and that are subject to the Apple Public Source License
++ * Version 2.0 (the 'License'). You may not use this file except in
++ * compliance with the License. The rights granted to you under the License
++ * may not be used to create, or enable the creation or redistribution of,
++ * unlawful or unlicensed copies of an Apple operating system, or to
++ * circumvent, violate, or enable the circumvention or violation of, any
++ * terms of an Apple operating system software license agreement.
++ * 
++ * Please obtain a copy of the License at
++ * http://www.opensource.apple.com/apsl/ and read it before using this file.
++ * 
++ * The Original Code and all software distributed under the License are
++ * distributed on an 'AS IS' basis, WITHOUT WARRANTY OF ANY KIND, EITHER
++ * EXPRESS OR IMPLIED, AND APPLE HEREBY DISCLAIMS ALL SUCH WARRANTIES,
++ * INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OF MERCHANTABILITY,
++ * FITNESS FOR A PARTICULAR PURPOSE, QUIET ENJOYMENT OR NON-INFRINGEMENT.
++ * Please see the License for the specific language governing rights and
++ * limitations under the License.
++ * 
++ * @APPLE_OSREFERENCE_LICENSE_HEADER_END@
++ */
++/*
++ * @OSF_COPYRIGHT@
++ */
++/* 
++ * Mach Operating System
++ * Copyright (c) 1991,1990,1989,1988,1987 Carnegie Mellon University
++ * All Rights Reserved.
++ * 
++ * Permission to use, copy, modify and distribute this software and its
++ * documentation is hereby granted, provided that both the copyright
++ * notice and this permission notice appear in all copies of the
++ * software, derivative works or modified versions, and any portions
++ * thereof, and that both notices appear in supporting documentation.
++ * 
++ * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"
++ * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND FOR
++ * ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
++ * 
++ * Carnegie Mellon requests users of this software to return to
++ * 
++ *  Software Distribution Coordinator  or  Software.Distribution@CS.CMU.EDU
++ *  School of Computer Science
++ *  Carnegie Mellon University
++ *  Pittsburgh PA 15213-3890
++ * 
++ * any improvements or extensions that they make and grant Carnegie Mellon
++ * the rights to redistribute these changes.
++ */
++/*
++ */
++/*
++ *  File: h/kern_return.h
++ *  Author: Avadis Tevanian, Jr.
++ *  Date: 1985
++ *
++ *  Kernel return codes.
++ *
++ */
++
++#ifndef _MACH_KERN_RETURN_H_
++#define _MACH_KERN_RETURN_H_
++
++
++#define KERN_SUCCESS      0
++
++#define KERN_INVALID_ADDRESS    1
++    /* Specified address is not currently valid.
++     */
++
++#define KERN_PROTECTION_FAILURE   2
++    /* Specified memory is valid, but does not permit the
++     * required forms of access.
++     */
++
++#define KERN_NO_SPACE     3
++    /* The address range specified is already in use, or
++     * no address range of the size specified could be
++     * found.
++     */
++
++#define KERN_INVALID_ARGUMENT   4
++    /* The function requested was not applicable to this
++     * type of argument, or an argument is invalid
++     */
++
++#define KERN_FAILURE      5
++    /* The function could not be performed.  A catch-all.
++     */
++
++#define KERN_RESOURCE_SHORTAGE    6
++    /* A system resource could not be allocated to fulfill
++     * this request.  This failure may not be permanent.
++     */
++
++#define KERN_NOT_RECEIVER   7
++    /* The task in question does not hold receive rights
++     * for the port argument.
++     */
++
++#define KERN_NO_ACCESS      8
++    /* Bogus access restriction.
++     */
++
++#define KERN_MEMORY_FAILURE   9
++    /* During a page fault, the target address refers to a
++     * memory object that has been destroyed.  This
++     * failure is permanent.
++     */
++
++#define KERN_MEMORY_ERROR   10
++    /* During a page fault, the memory object indicated
++     * that the data could not be returned.  This failure
++     * may be temporary; future attempts to access this
++     * same data may succeed, as defined by the memory
++     * object.
++     */
++
++#define KERN_ALREADY_IN_SET   11
++    /* The receive right is already a member of the portset.
++     */
++
++#define KERN_NOT_IN_SET     12
++    /* The receive right is not a member of a port set.
++     */
++
++#define KERN_NAME_EXISTS    13
++    /* The name already denotes a right in the task.
++     */
++
++#define KERN_ABORTED      14
++    /* The operation was aborted.  Ipc code will
++     * catch this and reflect it as a message error.
++     */
++
++#define KERN_INVALID_NAME   15
++    /* The name doesn't denote a right in the task.
++     */
++
++#define KERN_INVALID_TASK   16
++    /* Target task isn't an active task.
++     */
++
++#define KERN_INVALID_RIGHT    17
++    /* The name denotes a right, but not an appropriate right.
++     */
++
++#define KERN_INVALID_VALUE    18
++    /* A blatant range error.
++     */
++
++#define KERN_UREFS_OVERFLOW   19
++    /* Operation would overflow limit on user-references.
++     */
++
++#define KERN_INVALID_CAPABILITY   20
++    /* The supplied (port) capability is improper.
++     */
++
++#define KERN_RIGHT_EXISTS   21
++    /* The task already has send or receive rights
++     * for the port under another name.
++     */
++
++#define KERN_INVALID_HOST   22
++    /* Target host isn't actually a host.
++     */
++
++#define KERN_MEMORY_PRESENT   23
++    /* An attempt was made to supply "precious" data
++     * for memory that is already present in a
++     * memory object.
++     */
++
++#define KERN_MEMORY_DATA_MOVED    24
++    /* A page was requested of a memory manager via
++     * memory_object_data_request for an object using
++     * a MEMORY_OBJECT_COPY_CALL strategy, with the
++     * VM_PROT_WANTS_COPY flag being used to specify
++     * that the page desired is for a copy of the
++     * object, and the memory manager has detected
++     * the page was pushed into a copy of the object
++     * while the kernel was walking the shadow chain
++     * from the copy to the object. This error code
++     * is delivered via memory_object_data_error
++     * and is handled by the kernel (it forces the
++     * kernel to restart the fault). It will not be
++     * seen by users.
++     */
++
++#define KERN_MEMORY_RESTART_COPY  25
++    /* A strategic copy was attempted of an object
++     * upon which a quicker copy is now possible.
++     * The caller should retry the copy using
++     * vm_object_copy_quickly. This error code
++     * is seen only by the kernel.
++     */
++
++#define KERN_INVALID_PROCESSOR_SET  26
++    /* An argument applied to assert processor set privilege
++     * was not a processor set control port.
++     */
++
++#define KERN_POLICY_LIMIT   27
++    /* The specified scheduling attributes exceed the thread's
++     * limits.
++     */
++
++#define KERN_INVALID_POLICY   28
++    /* The specified scheduling policy is not currently
++     * enabled for the processor set.
++     */
++
++#define KERN_INVALID_OBJECT   29
++    /* The external memory manager failed to initialize the
++     * memory object.
++     */
++
++#define KERN_ALREADY_WAITING    30
++    /* A thread is attempting to wait for an event for which 
++     * there is already a waiting thread.
++     */
++
++#define KERN_DEFAULT_SET    31
++    /* An attempt was made to destroy the default processor
++     * set.
++     */
++
++#define KERN_EXCEPTION_PROTECTED  32
++    /* An attempt was made to fetch an exception port that is
++     * protected, or to abort a thread while processing a
++     * protected exception.
++     */
++
++#define KERN_INVALID_LEDGER   33
++    /* A ledger was required but not supplied.
++     */
++
++#define KERN_INVALID_MEMORY_CONTROL 34
++    /* The port was not a memory cache control port.
++     */
++
++#define KERN_INVALID_SECURITY   35
++    /* An argument supplied to assert security privilege  
++     * was not a host security port.
++     */
++    
++#define KERN_NOT_DEPRESSED    36
++    /* thread_depress_abort was called on a thread which
++     * was not currently depressed.
++     */
++    
++#define KERN_TERMINATED     37
++    /* Object has been terminated and is no longer available
++     */
++
++#define KERN_LOCK_SET_DESTROYED   38
++    /* Lock set has been destroyed and is no longer available.
++     */
++
++#define KERN_LOCK_UNSTABLE    39
++    /* The thread holding the lock terminated before releasing
++     * the lock
++     */
++
++#define KERN_LOCK_OWNED     40
++    /* The lock is already owned by another thread
++     */
++
++#define KERN_LOCK_OWNED_SELF    41
++    /* The lock is already owned by the calling thread
++     */
++
++#define KERN_SEMAPHORE_DESTROYED  42
++    /* Semaphore has been destroyed and is no longer available.
++     */
++
++#define KERN_RPC_SERVER_TERMINATED  43
++    /* Return from RPC indicating the target server was 
++     * terminated before it successfully replied 
++     */
++
++#define KERN_RPC_TERMINATE_ORPHAN 44
++    /* Terminate an orphaned activation.
++     */
++
++#define KERN_RPC_CONTINUE_ORPHAN  45
++    /* Allow an orphaned activation to continue executing.
++     */
++
++#define KERN_NOT_SUPPORTED    46
++    /* Empty thread activation (No thread linked to it)
++     */
++
++#define KERN_NODE_DOWN      47
++    /* Remote node down or inaccessible.
++     */
++
++#define KERN_NOT_WAITING    48
++    /* A signalled thread was not actually waiting. */
++
++#define KERN_OPERATION_TIMED_OUT        49
++    /* Some thread-oriented operation (semaphore_wait) timed out
++     */
++
++#define KERN_CODESIGN_ERROR   50
++    /* During a page fault, indicates that the page was rejected
++     * as a result of a signature check.
++     */
++
++#define KERN_RETURN_MAX     0x100
++    /* Maximum return value allowable
++     */
++
++#endif  /* _MACH_KERN_RETURN_H_ */
+diff -Naur ./old//magenta/ke_runtime.c ./kern//magenta/ke_runtime.c
+--- ./old//magenta/ke_runtime.c  1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/ke_runtime.c 2012-07-01 01:06:48.000000000 +0100
+@@ -0,0 +1,139 @@
++/*
++ * ke_runtime.c
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Kernel runtime support.
++ */
++
++#include "ke_runtime.h"
++#include <linux/module.h>
++#include <linux/sched.h>
++#include <linux/binfmts.h>
++#include <linux/signal.h>
++
++#include "mach_port_types.h"
++
++/* External initializers */
++extern int init_mach_ipc(void);
++extern int init_macho_binfmt(void);
++static bool _ke_initialized = false;
++extern void __ke_memtest(void);
++void* ke_alloc(size_t size)
++{
++  return kmalloc(size, GFP_KERNEL);
++}
++
++void ke_free(void* ptr)
++{
++  kfree(ptr);
++}
++
++void ke_will_signal(struct task_struct *t, int sig)
++{
++  return;
++  if (sig == SIGKILL || sig == SIGILL || sig == SIGSEGV || sig == SIGBUS)
++  {
++    task_port_t* port = ke_get_task_port(t);
++
++    ke_log("task %p received critical signal %d, forcing teardown!\n", t, sig);
++    ke_teardown_task(port);
++
++    PortRelease(port);
++  }
++}
++
++void* ke_realloc(void* ptr, size_t size)
++{
++  return krealloc(ptr, size, GFP_KERNEL);
++}
++
++/*
++ * Called when the darwin system call number is invalid.
++ */
++void ke_darwin_syscall_error(int c)
++{
++  panic("ke_darwin_syscall_error(): invalid trap #: %d", c);
++}
++
++void ke_at_fork(struct task_struct *task, struct task_struct *parent, unsigned long clone_flags)
++{
++  if (!_ke_initialized) {
++    return;
++  }
++
++  if (task->mm && !(clone_flags & CLONE_THREAD))
++  {
++    /* 
++     * Only userspace tasks need new task ports.
++     * Kernel tasks don't need them. Clone threads inherit
++     * them from parents.
++     */
++    
++    ke_log("ke_at_fork(): creating task port\n");
++    ke_setup_task_port(task);
++  }
++}
++
++/**/
++void ke_setup_exec(struct linux_binprm* bprm)
++{
++  if (!_ke_initialized) {
++    return;
++  }
++
++  if (current->pid == 1)
++  {
++    /*
++     * Task 1 doesn't have a mm in at_fork, so do
++     * port init in the execve hook instead.
++     */
++
++    if (current->task_port) {
++      panic("ke_setup_exec(): pid 1 has a task port already");
++    }
++
++    ke_log("ke_setup_exec(): creating task port for pid 1\n");
++    ke_setup_task_port(current);
++
++    __ke_memtest();
++  }
++
++  ke_log("ke_setup_exec(): setup\n");
++}
++
++void ke_process_exit(struct task_struct *tsk)
++{
++  if (!_ke_initialized) {
++    return;
++  }
++
++  ke_log("ke_process_exit(): exit\n");
++}
++
++static void __ke_runtime_test(void)
++{
++  ke_array_t arr = ke_array_with_capacity(10);
++
++  ke_array_set_at(arr, 0, (ke_storage_type)1234);
++  ke_array_set_at(arr, 1, (ke_storage_type)4321);
++  ke_array_set_at(arr, 2, (ke_storage_type)5555);
++  ke_array_set_at(arr, 3, (ke_storage_type)777);
++
++  ke_log("2: %d 3: %d \n", (int)ke_array_get(arr, 2), (int)ke_array_get(arr, 3));
++
++  return;
++}
++
++int __init __ke_runtime_init(void)
++{
++  init_mach_ipc();
++  init_macho_binfmt();
++  
++  __ke_runtime_test();
++
++  _ke_initialized = true;
++
++  ke_log("ke_runtime_init(): runtime started\n");
++  return 0;
++}
++
+diff -Naur ./old//magenta/ke_runtime.h ./kern//magenta/ke_runtime.h
+--- ./old//magenta/ke_runtime.h  1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/ke_runtime.h 2012-06-30 23:29:03.000000000 +0100
+@@ -0,0 +1,65 @@
++/*
++ * ke_runtime.h
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Kernel runtime support.
++ */
++
++#ifndef _H_MG_KE_RUNTIME_
++#define _H_MG_KE_RUNTIME_
++
++
++#include <linux/kernel.h>
++#include <linux/string.h>
++#include <linux/slab.h>
++
++#include <DarwinTypes.h>
++#include <MachO.h>
++
++#define KE_TYPE_UNKNOWN 0
++#define KE_TYPE_ARRAY 1
++
++/* void bzero(void *s, size_t n); */
++#define bzero(ptr, sz) memset(ptr, 0, sz)
++
++/**/
++#define ke_storage_type void*
++#define Boolean int
++
++typedef struct {
++  uint16_t type;
++} ke_type_impl;
++
++typedef struct {
++  ke_type_impl base;
++
++  unsigned int count;
++  unsigned int capacity;
++  unsigned int capacityIncrement;
++
++  ke_storage_type* array;
++} ke_array_impl;
++
++typedef void* ke_type_t;
++typedef ke_type_t ke_array_t;
++
++/* Memory */
++void* ke_alloc(size_t size);
++void ke_free(void* ptr);
++void* ke_realloc(void* ptr, size_t size);
++
++/* Array */
++ke_array_t ke_array_with_capacity(unsigned int capacity);
++bool ke_array_init(ke_array_t arr, unsigned int capacity);
++ke_storage_type ke_array_get(ke_array_t arr, unsigned int index);
++bool ke_array_set_at(ke_array_t arr, unsigned int index, ke_storage_type anObject);
++unsigned int ke_array_get_count(ke_array_t arr);
++bool ke_array_add(ke_array_t arr, ke_storage_type anObject);
++int ke_log(const char *fmt, ...);
++
++/* Port */
++void ke_setup_task_port(struct task_struct* task);
++
++#define ke_critical panic
++
++#endif
+diff -Naur ./old//magenta/ke_task.c ./kern//magenta/ke_task.c
+--- ./old//magenta/ke_task.c 1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/ke_task.c  2012-06-24 16:10:59.000000000 +0100
+@@ -0,0 +1,255 @@
++/*
++ * ke_task.c
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Task related routines.
++ */
++
++#include <linux/module.h>
++
++#include <linux/time.h>
++#include <linux/kernel.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/string.h>
++#include <linux/fs.h>
++#include <linux/file.h>
++#include <linux/stat.h>
++#include <linux/fcntl.h>
++#include <linux/ptrace.h>
++#include <linux/user.h>
++#include <linux/binfmts.h>
++#include <linux/personality.h>
++#include <linux/init.h>
++#include <linux/coredump.h>
++#include <linux/slab.h>
++#include <linux/namei.h>
++#include <linux/security.h>
++#include <linux/syscalls.h>
++#include <linux/kfifo.h>
++#include <linux/sched.h>
++
++
++#include <asm/system.h>
++#include <asm/uaccess.h>
++#include <asm/cacheflush.h>
++#include <linux/linkage.h>
++
++#include "ke_runtime.h"
++
++#include "ipc_types.h"
++#include "mach_kmsg.h"
++
++/* extended version that can map stuff in different tasks */
++extern
++unsigned long mmap_region_ex(struct file *file, unsigned long addr,
++        unsigned long len, unsigned long flags,
++        unsigned int vm_flags, unsigned long pgoff,
++        struct task_struct* tsk);
++
++static struct task_struct* ke_task_from_port(task_port_t* space)
++{
++  return space->task;
++}
++
++unsigned long ke_mm_get_unmapped(struct mm_struct* mm,
++  unsigned long addr,
++  unsigned long len,
++  unsigned long flags)
++{
++  unsigned long error = arch_mmap_check(addr, len, flags);
++  unsigned long (*get_area)(struct file *, unsigned long,
++          unsigned long, unsigned long, unsigned long);
++
++  /* arch specific checks */
++  if (error)
++    return error;
++
++  /* overflow checks */
++  if (len > TASK_SIZE)
++    return -ENOMEM;
++
++  get_area = mm->get_unmapped_area;
++  addr = get_area(NULL, addr, len, 0, flags);
++
++  if (IS_ERR_VALUE(addr))
++    return addr;
++
++  if (addr > TASK_SIZE - len)
++    return -ENOMEM;
++  if (addr & ~PAGE_MASK)
++    return -EINVAL;
++
++  /* arm only */
++  return addr;
++}
++
++kern_return_t ke_task_vm_allocate(task_port_t* port,
++  uintptr_t* addr,
++  size_t size,
++  boolean_t anywhere)
++{
++  struct task_struct* ts = ke_task_from_port(port);
++  struct mm_struct* mm = ts->mm;
++  unsigned long flags = 0;
++  unsigned long pgoff = 0;
++  unsigned int vm_flags = 0;
++  unsigned int prot = PROT_READ | PROT_WRITE | PROT_EXEC;
++  unsigned long ret = 0;
++  unsigned long reqprot = prot;
++  uintptr_t iaddr = *addr;
++
++  if (!anywhere) {
++    flags |= MAP_FIXED;
++  }
++  else {
++    iaddr = 0;
++  }
++
++  down_write(&mm->mmap_sem);
++
++  vm_flags = calc_vm_prot_bits(prot) | calc_vm_flag_bits(flags) |
++      mm->def_flags | VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC;
++
++  ret = 
++  ke_mm_get_unmapped(current->mm,
++    (unsigned long)iaddr,
++    (unsigned long)size,
++    flags);
++
++  if (IS_ERR_VALUE(ret)) {
++    printk("mmap_region_ex(): ke_mm_get_unmapped returned %ld \n", ret);
++    up_write(&mm->mmap_sem);
++    return KERN_FAILURE;
++  }
++  else {
++    iaddr = (uintptr_t)ret;
++  }
++
++  pgoff = iaddr >> PAGE_SHIFT;
++
++  ret = 
++  mmap_region_ex(NULL, iaddr, (unsigned long)size, flags, vm_flags, pgoff, ts);
++
++  ke_log("mmap_region_ex = %ld \n", ret);
++
++  up_write(&mm->mmap_sem);
++
++  *addr = iaddr;
++
++  return KERN_SUCCESS;
++}
++
++mach_port_t _user_task_self(void)
++{
++  /* We should already hold the send right*/
++  task_port_t* tp = ke_get_current_task();
++  ke_port_right_t* rcv = ke_get_right_in_space(tp, (ke_port_t*)tp, false);
++
++  if (rcv) {
++    mach_port_t nm = rcv->name;
++    PortRelease(tp);
++    return nm;
++  }
++  else {
++    /*
++     * This shouldn't ever happen.
++     */
++    printk(KERN_ALERT "_user_task_self: mach task port invalid for task %p", current);
++    return 0;
++  }
++}
++
++kern_return_t _user_pid_for_task(mach_port_name_t t, int *x)
++{
++  task_port_t* tp;
++  struct task_struct* tsk;
++
++
++  tp = (task_port_t*)ke_port_find_named(t);
++
++  if (!tp) {
++    return KERN_INVALID_NAME;
++  }
++
++  tsk = tp->task;
++
++  if (!tsk) {
++    panic("task port %p doesn't have a task!", tp);
++  }
++
++  /* I hope pid_t is an int ... */
++  __put_user(tsk->pid, x);
++  PortRelease(tp);
++
++  return KERN_SUCCESS;
++}
++
++kern_return_t _user_task_for_pid(mach_port_t target_tport, int pid, mach_port_t *t)
++{
++  ke_port_right_t* snd;
++  task_port_t* tp;
++  struct task_struct* rem;
++  ke_port_t* rp;
++
++  tp = (task_port_t*)ke_port_find_named(target_tport);
++
++  if (!tp) {
++    return KERN_INVALID_NAME;
++  }
++
++  rem = find_task_by_vpid(pid);
++  if (!rem) {
++    return KERN_FAILURE;
++  }
++
++  rp = (ke_port_t*)(rem->task_port);
++  if (!rp) {
++    panic("task %p doesn't have a task port!", rem);
++  }
++
++  snd = ke_get_right_in_space(tp, rp, false);
++  if (!snd) {
++    PortRelease(tp);
++    return KERN_FAILURE;
++  }
++
++  RightIncrementRefCount(snd, r_send);
++
++  __put_user(snd->name, t);
++
++  PortRelease(tp);
++
++  return KERN_SUCCESS;
++}
++
++kern_return_t _user_vm_allocate(mach_port_t task,
++  uintptr_t* addr, /* __user */
++  size_t size,
++  boolean_t anywhere)
++{
++  task_port_t* port;
++  kern_return_t ret;
++  uintptr_t iaddr;
++
++  __get_user(iaddr, addr);
++
++  port = (task_port_t*)ke_port_find_named(task);
++  if (!port) {
++    return KERN_INVALID_NAME;
++  }
++
++  ret = ke_task_vm_allocate(port, &iaddr, size, anywhere);
++
++  __put_user(iaddr, addr);
++
++  PortRelease(port);
++  return ret;
++}
++
++void __ke_memtest(void)
++{
++  
++}
+diff -Naur ./old//magenta/kext.c ./kern//magenta/kext.c
+--- ./old//magenta/kext.c  1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/kext.c 2012-06-24 16:09:20.000000000 +0100
+@@ -0,0 +1,661 @@
++/*
++ * kext.c
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * What is this, I don't even ...
++ */
++
++#include <linux/time.h>
++#include <linux/kernel.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/string.h>
++#include <linux/fs.h>
++#include <linux/file.h>
++#include <linux/stat.h>
++#include <linux/fcntl.h>
++#include <linux/ptrace.h>
++#include <linux/user.h>
++#include <linux/binfmts.h>
++#include <linux/personality.h>
++#include <linux/init.h>
++#include <linux/coredump.h>
++#include <linux/slab.h>
++#include <linux/namei.h>
++#include <linux/security.h>
++#include <linux/syscalls.h>
++#include <linux/kfifo.h>
++
++#include <asm/system.h>
++#include <asm/uaccess.h>
++#include <asm/cacheflush.h>
++#include <linux/linkage.h>
++#include <linux/module.h>
++
++#include "ipc_types.h"
++#include "mach_kmsg.h"
++#include "ke_runtime.h"
++#include "loader.h"
++
++typedef struct kernel_symbol ksym_t;
++
++/*
++ * Symbols in the main image's symbtab.
++ */
++extern const ksym_t __start___ksymtab[];
++extern const ksym_t __stop___ksymtab[];
++extern const ksym_t __start___ksymtab_gpl[];
++extern const ksym_t __stop___ksymtab_gpl[];
++extern const ksym_t __start___ksymtab_gpl_future[];
++extern const ksym_t __stop___ksymtab_gpl_future[];
++
++static Boolean _verbose_log = true;
++
++#define doIfVerbose() if (_verbose_log)
++
++typedef struct __KXFile {
++  unsigned char *fMachO;
++  struct symtab_command *fSymtab;
++  
++  uintptr_t fSegmentOffset;
++  char *fStringBase;
++  struct nlist *fSymbolBase;
++  const struct nlist *fLocalSyms;
++  int fStringSectionOrdinal;
++
++  unsigned char* fSegmentBase;
++} KXFile;
++
++void *kmalloc_non_inline(size_t size, gfp_t flags)
++{
++  return kmalloc(size, flags);
++}
++EXPORT_SYMBOL(kmalloc_non_inline);
++
++const ksym_t*
++find_kernel_symbol_in(const char* name, const ksym_t* start, const ksym_t* end)
++{
++  const ksym_t* sym = start;
++
++  while (1) {
++    if (strcmp(sym->name, name) == 0) {
++      /* Found */
++      return sym;
++    }
++
++    sym++;
++
++    if (sym > end) {
++      break;
++    }
++  }
++
++  return FALSE;
++}
++
++ksym_t*
++find_kernel_symbol(const char* name)
++{
++  const ksym_t* sym = NULL;
++
++  if (!sym) {
++    sym = find_kernel_symbol_in(name, __start___ksymtab, __stop___ksymtab);
++  }
++
++  return (ksym_t*)sym;
++}
++
++static const struct nlist *
++kld_find_symbol_by_name(KXFile *file, const char* name)
++{
++  /*
++   This is slow, but I don't care.
++   */
++  
++  const struct nlist *sym;
++  int nsyms;
++  
++  nsyms = file->fSymtab->nsyms;
++  sym = file->fSymbolBase;
++  
++  while (nsyms--) {
++    /*
++     if ((sym->n_type & N_EXT))
++     return NULL;
++     */
++    
++    long strx = sym->n_un.n_strx;
++    const char *symname = file->fStringBase + strx;
++    
++    if (strcmp(name, symname) == 0 && !(sym->n_type & N_STAB))
++      return sym;
++    
++    sym += 1;
++  }
++  
++  return NULL;
++}
++
++static const struct nlist *
++kld_find_symbol_by_address(KXFile *file, void *entry)
++{
++  /*
++    This is slow, but I don't care.
++   */
++  
++  const struct nlist *sym;
++  int nsyms;
++  
++  nsyms = file->fSymtab->nsyms;
++  sym = file->fSymbolBase;
++  
++  while (nsyms--) {
++    uint32_t addr = (uint32_t)entry;
++    /*
++    if ((sym->n_type & N_EXT))
++      return NULL;
++    */
++    
++    if (sym->n_desc & N_ARM_THUMB_DEF) {
++      addr = addr & ~1;
++    }
++
++    if (sym->n_value == addr && !(sym->n_type & N_STAB)) {
++      return sym;
++    }
++    
++    sym += 1;
++  }
++
++  return NULL;
++}
++
++Boolean kld_relocate_section(KXFile* file , struct section* sect, vm_offset_t delta)
++{
++  uint8_t* sbase;
++  uint32_t nreloc;
++  struct relocation_info *rinfo;
++  
++  sbase = (uint8_t*)sect->addr;
++  nreloc = sect->nreloc;
++  rinfo = (struct relocation_info *)(file->fMachO + sect->reloff);
++  
++  while (nreloc--) {
++    void** entry;
++    void** abs_entry;
++    unsigned long r_symbolnum, r_length;
++    const struct nlist *symbol = NULL;
++    enum reloc_type_generic r_type;
++    void *addr = NULL;
++    
++    /* Ignore scattered relocations */
++    if ((rinfo->r_address & R_SCATTERED))
++      continue;
++    
++    /* This is why we can't have nice things */
++    entry = (void**)( (uintptr_t)rinfo->r_address + (uintptr_t)sbase );
++    abs_entry = ((void**)( (uintptr_t)file->fSegmentBase + (uintptr_t)entry ));
++    
++    r_type = (enum reloc_type_generic)rinfo->r_type;
++    r_length = rinfo->r_length;
++    
++    /*
++      In r_length, 2 stands for long.
++     */
++    if (r_type != GENERIC_RELOC_VANILLA || r_length != 2)
++      continue;
++    
++    r_symbolnum = rinfo->r_symbolnum;
++    
++    #if 0
++    ke_log("kld_relocate_section: {t=%d, ba=%p, aa=%p, ln=%d, n=%ld}\n",
++         rinfo->r_type,
++         (void*)rinfo->r_address, /* relative */
++         entry, /* absolute (within the file) */
++         rinfo->r_length,
++         r_symbolnum);
++    #endif
++
++    if (rinfo->r_extern) {
++      /* External symbol entry */
++      long strx;
++      const char *symname;
++      ksym_t* ks; 
++
++      if(r_symbolnum >= file->fSymtab->nsyms)
++      {
++        ke_log("kld_relocate_section: invalid reloc entry\n");
++        return false;
++      }
++      
++      symbol = file->fSymbolBase;
++      
++      if ((symbol[r_symbolnum].n_type & N_TYPE) == N_INDR) {
++        /*
++          This is an indirect symbol, so get the value
++          for the actual thing.
++         */
++        r_symbolnum = symbol[r_symbolnum].n_value;
++      }
++      
++      symbol = &symbol[r_symbolnum];
++      
++      if (symbol->n_type != (N_EXT | N_UNDF)) {
++        ke_log("kld_relocate_section: invalid reloc symbol type - !(N_EXT | N_UNDF)\n");
++        return false;
++      }
++
++      strx = symbol->n_un.n_strx;
++      symname = file->fStringBase + strx;
++      
++      if (symname[0] == '_') {
++        symname++;
++      }
++      else {
++        ke_log("kld_relocate_section: '%s' doesn't start with '_'\n", symname);
++        return false;
++      }
++
++      ks = find_kernel_symbol(symname);
++      if (!ks) {
++        ke_log("kld_relocate_section: failed to resolve '%s'\n", symname);
++        return false;
++      }
++
++      doIfVerbose() {
++        ke_log("\t[extern] sym_addr: %p, r_addr: %p, l_addr: %p, nm: '%s', ks: %p\n",
++          (void*)symbol,
++          (void*)rinfo->r_address,
++          (void*)addr,
++          symname,
++          (void*)ks);
++      } 
++
++      *abs_entry = (void*)(ks->value);
++    }
++    else {
++      /*
++       * Relocate a local symbol. Local symbols in object files
++       * are not attached to each other which means that all jumps
++       * have to be fixed up.
++       */
++
++      /* Derp */
++      if (r_symbolnum == R_ABS)
++      {
++        rinfo++;
++        continue;
++      }
++      
++      /* Not this pointer crap again */
++      addr = *abs_entry;
++
++      if (r_symbolnum == file->fStringSectionOrdinal)
++      {
++        /* This is a string section*/
++
++        doIfVerbose() {
++          ke_log("\t[local] (cstr) l_addr: %p, val: %p\n",
++            (void*)symbol,
++            (void*)addr);
++        }
++
++        *abs_entry = ((void*)( (uintptr_t)file->fSegmentBase + (uintptr_t)addr) );
++
++        rinfo++;
++        continue;
++      }
++
++      symbol = kld_find_symbol_by_address(file, addr);
++      
++      if (symbol) {
++        uint32_t val = symbol->n_value;
++
++        doIfVerbose() {
++          ke_log("\t[local] sym_addr: %p, r_addr: %p, l_addr: %p, val: %p\n",
++            (void*)symbol,
++            (void*)rinfo->r_address,
++            (void*)addr,
++            (void*)val);
++        }
++
++        if (symbol->n_desc & N_ARM_THUMB_DEF) {
++          val |= 1;
++        }
++
++        /* reloc */
++        *abs_entry = ((void*)( (uintptr_t)file->fSegmentBase + (uintptr_t)sbase + (uintptr_t)val ));
++      }
++      else {
++
++        doIfVerbose() {
++          ke_log("kld_relocate_section: can't find symbol at %p (ord: %d)\n",
++            (void*)addr,
++            (int)r_symbolnum);
++        }
++
++        return false;
++      }
++    }
++
++    rinfo++;
++  }
++  
++  return true;
++}
++
++Boolean kld_parse_symtab(KXFile* file)
++{
++  const struct nlist *sym;
++  unsigned int i, firstlocal = 0, nsyms;
++  const char *strbase;
++  unsigned int strsize;
++
++  file->fSymbolBase = 
++  (struct nlist *)(file->fMachO + file->fSymtab->symoff); 
++  
++  file->fStringBase = 
++  (char *)(file->fMachO + file->fSymtab->stroff);
++  
++  i = 0;
++  nsyms = file->fSymtab->nsyms;
++  strsize = file->fSymtab->strsize;
++  strbase = file->fStringBase;
++  sym = file->fSymbolBase;
++  
++  while (i < nsyms) {
++    long strx = sym->n_un.n_strx;
++    const char *symname = strbase + strx;
++    unsigned char n_type = sym->n_type & N_TYPE;
++    
++    doIfVerbose() {
++      ke_log("kld_parse_symtab: type=%d, val=%p, name='%s'\n",
++           n_type,
++           (void*)sym->n_value,
++           symname);
++    }
++
++    n_type = sym->n_type & (N_TYPE | N_EXT);
++    
++    /*
++     * First exported symbol 
++     * This is done for the sake of performance
++     */
++    if ( !firstlocal && (n_type & N_EXT) ) {
++      firstlocal = i;
++      file->fLocalSyms = sym;
++    }
++    
++    /* Increment stuff */
++    i += 1;
++    sym += 1;
++  }
++  
++  if (!file->fLocalSyms) {
++    ke_log("kld_parse_symtab: no symbols found\n");
++    return false;
++  }
++  
++  doIfVerbose() {
++    ke_log("kld_parse_symtab: {loc=%p}\n",
++        file->fLocalSyms);
++  }
++
++  return true;
++}
++
++Boolean kld_map_sect(KXFile* file, struct section* sect)
++{
++  uintptr_t sect_mem_addr = 
++  ((uintptr_t)( (uintptr_t)file->fSegmentBase + (uintptr_t)sect->addr ));
++
++  uintptr_t sect_file_addr = 
++  ((uintptr_t)( (uintptr_t)file->fMachO + (uintptr_t)sect->offset ));
++
++  doIfVerbose() {
++    ke_log("kld_map_sect: addr: %p, name: '%s', type: %d, size: %d\n",
++           (void*)sect->addr,
++           sect->sectname,
++           (int)(sect->flags & SECTION_TYPE),
++           (int)sect->size);
++  }
++
++  if ((sect->flags & SECTION_TYPE) == S_ZEROFILL)
++  {
++    memset((void*)sect_mem_addr, 0, sect->size);
++  }
++  else {
++    memcpy((void*)sect_mem_addr, (void*)sect_file_addr, sect->size);
++  }
++
++  return true;
++}
++
++Boolean kld_process_segment(KXFile* file, struct segment_command* seg) 
++{
++  struct section* sect = NULL;
++  uint32_t nsects = seg->nsects;
++  uint32_t total_size = 0;
++  int i = 0;
++
++#define iterate_sections()  \
++  sect = (struct section*)((uintptr_t)seg + sizeof(struct segment_command)); \
++  for (i = 0; i < nsects; i++, sect++) \
++
++  /* calculate total size */
++  iterate_sections()
++  {
++    total_size += sect->size;
++  }
++
++  file->fSegmentBase = ke_alloc(total_size);
++
++  /* map sections */
++  iterate_sections()
++  {
++    kld_map_sect(file, sect);
++    
++    if ((sect->flags & SECTION_TYPE) == S_CSTRING_LITERALS)
++    {
++      file->fStringSectionOrdinal = i+1;
++    }
++  }
++
++  /* perform relocation */
++  iterate_sections() 
++  {
++    if (!kld_relocate_section(file, sect, 0))
++    {
++      return false;
++    }
++  }
++  
++  return true;
++}
++
++Boolean kld_file_map(void* buffer, long size, KXFile* file)
++{
++  size_t macho_header_sz = sizeof(struct mach_header);
++  uint8_t* load_commands;
++  struct mach_header* head;
++  
++  /* command parser */
++  boolean_t has_segment = FALSE;
++  size_t offset;
++  size_t oldoffset;
++  uint32_t ncmds;
++  
++  /* segment */
++  struct segment_command *seg_hdr;
++  uintptr_t sect_offset = 0;
++  uint32_t nsects = 0;
++  
++  bzero(file, sizeof(file));
++
++  head = buffer;
++  load_commands = buffer + macho_header_sz;
++  
++  offset = 0;
++  ncmds = head->ncmds;
++  
++  file->fMachO = buffer;
++  
++  doIfVerbose() {
++    ke_log("kld_file_map: macho {fl=%d}\n", head->flags);
++  }
++
++  while (ncmds--) {
++    struct load_command *lcp = 
++    (struct load_command *)(load_commands + offset);
++    
++    oldoffset = offset;
++    offset += lcp->cmdsize;
++    
++    if (oldoffset > offset ||
++        lcp->cmdsize < sizeof(struct load_command) ||
++        offset > head->sizeofcmds + macho_header_sz)
++    {
++      ke_log("kld_file_map: malformed load command\n");
++      return false;
++    }
++    
++    /*
++      Mach objects (MH_OBJECT) are only meant to have one segment that has all the bits.
++     */
++    switch(lcp->cmd) {
++      case LC_SEGMENT:
++      {
++        if (has_segment) {
++          ke_log("kld_file_map: more than one segment in the file \n");
++          return false;
++        }
++        
++        seg_hdr = (struct segment_command *)lcp;
++        
++        nsects = seg_hdr->nsects;
++        sect_offset = (uintptr_t)(seg_hdr + sizeof(struct segment_command));
++        
++        file->fSegmentOffset = seg_hdr->fileoff;
++        
++        doIfVerbose() {
++          ke_log("kld_file_map: LC_SEGMENT {nsects=%d} \n",
++               seg_hdr->nsects);
++        }
++        
++        has_segment = TRUE;
++        
++        break;
++      }
++      case LC_UUID:
++      case LC_DYSYMTAB:
++      {
++        /* Do. Not. Care. */
++        break;
++      }
++      case LC_SYMTAB:
++      {
++        file->fSymtab = (struct symtab_command*)lcp;
++        break;
++      }
++      default:
++      {
++        ke_log("kld_file_map: unsupported load command %d \n",
++            lcp->cmd);
++        
++        return false;
++        break;
++      }
++    }
++  }
++  
++  if (!file->fSymtab) {
++    ke_log("kld_file_map: object file missing symbols \n");
++    return false;
++  }
++  else {
++    kld_parse_symtab(file);
++  }
++  
++  if (!has_segment) {
++    ke_log("kld_file_map: object file missing segment \n");
++    return false;
++  }
++  else {
++    if (!kld_process_segment(file, seg_hdr))
++    {
++      return false;
++    }
++  }
++  
++  return true;
++}
++
++void abi_test(int aa, long long aaa)
++{
++  ke_log("ABI_TEST: int: %d, long: %lld\n", aa, aaa);
++}
++EXPORT_SYMBOL(abi_test);
++
++void lol_test(void)
++{
++  ke_log("LOL, TEST!!! \n");
++}
++EXPORT_SYMBOL(lol_test);
++
++void _user_load_kext(void* buffer, size_t size)
++{
++  /* 
++   *  mach_msg_header_t head;
++   *  void* buffer;
++   *  unsigned int buffer_len;
++   */
++
++  Boolean ret;
++  void* buf;
++
++  const struct nlist* nl;
++  KXFile file;
++
++  buf = ke_alloc(size);
++
++  if (copy_from_user(buf, buffer, size))
++  {
++    ke_log("kmsg_load_kext: goof \n");
++    return;
++  }
++  
++  if (kld_file_map(buf, size, &file))
++  {
++    uintptr_t val;
++    uint16_t* addr;
++    int (*kmod_init)(void);
++    int kret = 0;
++
++    nl = kld_find_symbol_by_name(&file, "_kmod_start");
++    
++    if (nl == NULL) {
++      ke_log("kmsg_load_kext: symbol not found \n");
++      return;
++    }
++
++    val = nl->n_value;
++    addr = (uint16_t*)((val + (uintptr_t)file.fSegmentBase));
++    
++    if (nl->n_desc & N_ARM_THUMB_DEF) {
++      addr = (uint16_t*)((unsigned int)addr | 1);
++    }
++
++    kmod_init = (void*)addr;
++      
++    /* Branch into the unknown */
++    kret = kmod_init();
++
++    ke_log("kmsg_load_kext: kmod returned %d\n", kret);
++  }
++  else
++  {
++    panic("kext loading failure!");
++  }
++}
+diff -Naur ./old//magenta/loader.h ./kern//magenta/loader.h
+--- ./old//magenta/loader.h  1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/loader.h 2012-06-16 22:04:07.000000000 +0100
+@@ -0,0 +1,120 @@
++/*
++ * loader.h
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Loader types.
++ */
++
++#ifndef _H_MG_LOADER_
++#define _H_MG_LOADER_
++
++#include "ipc_types.h"
++#include <DarwinTypes.h>
++#include <MachO.h>
++
++/* Section */
++
++ /*
++ * The flags field of a section structure is separated into two parts a section
++ * type and section attributes.  The section types are mutually exclusive (it
++ * can only have one type) but the section attributes are not (it may have more
++ * than one attribute).
++ */
++#define SECTION_TYPE     0x000000ff /* 256 section types */
++#define SECTION_ATTRIBUTES   0xffffff00 /*  24 section attributes */
++
++/* Constants for the type of a section */
++#define S_REGULAR   0x0 /* regular section */
++#define S_ZEROFILL    0x1 /* zero fill on demand section */
++#define S_CSTRING_LITERALS  0x2 /* section with only literal C strings*/
++#define S_4BYTE_LITERALS  0x3 /* section with only 4 byte literals */
++#define S_8BYTE_LITERALS  0x4 /* section with only 8 byte literals */
++#define S_LITERAL_POINTERS  0x5 /* section with only pointers to */
++          /*  literals */
++
++
++/* Nlist */
++
++#define N_STAB  0xe0  /* if any of these bits set, a symbolic debugging entry */
++#define N_PEXT  0x10  /* private external symbol bit */
++#define N_TYPE  0x0e  /* mask for the type bits */
++#define N_EXT 0x01  /* external symbol bit, set for external symbols */
++
++/*
++ * Only symbolic debugging entries have some of the N_STAB bits set and if any
++ * of these bits are set then it is a symbolic debugging entry (a stab).  In
++ * which case then the values of the n_type field (the entire field) are given
++ * in <mach-o/stab.h>
++ */
++
++/*
++ * Values for N_TYPE bits of the n_type field.
++ */
++#define N_UNDF  0x0   /* undefined, n_sect == NO_SECT */
++#define N_ABS 0x2   /* absolute, n_sect == NO_SECT */
++#define N_SECT  0xe   /* defined in section number n_sect */
++#define N_PBUD  0xc   /* prebound undefined (defined in a dylib) */
++#define N_INDR  0xa   /* indirect */
++
++struct nlist {
++  union {
++#ifndef __LP64__
++    char *n_name; /* for use when in-core */
++#endif
++    int32_t n_strx; /* index into the string table */
++  } n_un;
++  uint8_t n_type;   /* type flag, see below */
++  uint8_t n_sect;   /* section number or NO_SECT */
++  int16_t n_desc;   /* see <mach-o/stab.h> */
++  uint32_t n_value; /* value of this symbol (or stab offset) */
++};
++
++#define N_NO_DEAD_STRIP 0x0020 /* symbol is not to be dead stripped */
++#define N_DESC_DISCARDED 0x0020 /* symbol is discarded */
++#define N_WEAK_REF  0x0040 /* symbol is weak referenced */
++#define N_WEAK_DEF  0x0080 /* coalesed symbol is a weak definition */
++#define N_REF_TO_WEAK 0x0080 /* reference to a weak symbol */
++#define N_ARM_THUMB_DEF 0x0008 /* symbol is a Thumb function (ARM) */
++#define N_SYMBOL_RESOLVER  0x0100 
++
++/* Reloc stuff */
++
++ #define R_SCATTERED 0x80000000 /* mask to be applied to the r_address field 
++           of a relocation_info structure to tell that
++           is is really a scattered_relocation_info
++           stucture */
++
++enum reloc_type_generic
++{
++    GENERIC_RELOC_VANILLA,  /* generic relocation as discribed above */
++    GENERIC_RELOC_PAIR,   /* Only follows a GENERIC_RELOC_SECTDIFF */
++    GENERIC_RELOC_SECTDIFF,
++    GENERIC_RELOC_PB_LA_PTR,  /* prebound lazy pointer */
++    GENERIC_RELOC_LOCAL_SECTDIFF,
++    GENERIC_RELOC_TLV   /* thread local variables */
++};
++
++struct relocation_info {
++   int32_t  r_address;  /* offset in the section to what is being
++           relocated */
++   uint32_t     r_symbolnum:24, /* symbol index if r_extern == 1 or section
++           ordinal if r_extern == 0 */
++    r_pcrel:1,  /* was relocated pc relative already */
++    r_length:2, /* 0=byte, 1=word, 2=long, 3=quad */
++    r_extern:1, /* does not include value of sym referenced */
++    r_type:4; /* if not 0, machine specific relocation type */
++};
++
++#define R_ABS 0   /* absolute relocation type for Mach-O files */
++
++/* Actual loader stuff */
++struct symtab_command {
++  uint32_t  cmd;    /* LC_SYMTAB */
++  uint32_t  cmdsize;  /* sizeof(struct symtab_command) */
++  uint32_t  symoff;   /* symbol table offset */
++  uint32_t  nsyms;    /* number of symbol table entries */
++  uint32_t  stroff;   /* string table offset */
++  uint32_t  strsize;  /* string table size in bytes */
++};
++
++#endif
+diff -Naur ./old//magenta/mach.c ./kern//magenta/mach.c
+--- ./old//magenta/mach.c  1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/mach.c 2012-07-01 00:02:22.000000000 +0100
+@@ -0,0 +1,579 @@
++/*
++ * mach.c
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Mach routines.
++ */
++
++#include <linux/module.h>
++
++#include <linux/time.h>
++#include <linux/kernel.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/string.h>
++#include <linux/fs.h>
++#include <linux/file.h>
++#include <linux/stat.h>
++#include <linux/fcntl.h>
++#include <linux/ptrace.h>
++#include <linux/user.h>
++#include <linux/binfmts.h>
++#include <linux/personality.h>
++#include <linux/init.h>
++#include <linux/coredump.h>
++#include <linux/slab.h>
++#include <linux/namei.h>
++#include <linux/security.h>
++#include <linux/syscalls.h>
++#include <linux/kfifo.h>
++
++#include <asm/system.h>
++#include <asm/uaccess.h>
++#include <asm/cacheflush.h>
++#include <linux/linkage.h>
++
++#include "ipc_types.h"
++#include "mach_kmsg.h"
++
++/*
++  Port list.
++*/
++static DECLARE_RWSEM(ports_sem);
++static task_port_t* kernel_task;
++static DEFINE_MUTEX(port_ref_modify_lock);
++
++#define RefModifyLockDown() mutex_lock(&port_ref_modify_lock)
++#define RefModifyLockUp() mutex_unlock(&port_ref_modify_lock)
++
++/*
++ * Zones used by the slab allocators.
++ */
++static struct kmem_cache* zone_port_rights;
++
++/* Handler for kernel messages */
++extern int kmsg_handle(mach_msg_header_t* msg);
++extern kern_return_t ipc_message_handle(void* payload);
++
++/*
++  Mutex for kmsgs.
++*/
++DEFINE_MUTEX(kmsg_exec_mutex);
++
++/*
++ * Logging routine.
++ */
++#define ChristinasSillyUartDebugging 1
++#define BRIGHT    1
++#define BLUE    4
++#define WHITE   7
++#define default_attributes "\33[0m"
++
++int ke_log(const char *fmt, ...)
++{
++  va_list args;
++  int r;
++
++#if defined(ChristinasSillyUartDebugging)
++  char pre[13];
++  sprintf(pre, "%c[%d;%d;%dm", 0x1B, BRIGHT, WHITE + 30, BLUE + 40);
++  printk("%s[kern]%s: ", pre, default_attributes);
++#endif
++
++  va_start(args, fmt);
++  r = vprintk(fmt, args);
++  va_end(args);
++
++  return r;
++}
++
++/*
++ * Returns a new kernel port.
++ */
++ke_port_t* ke_port_allocate(uint16_t type)
++{
++  ke_port_t* prt = NULL;
++  int i = 0;
++  size_t port_size;
++
++  if (type == KE_PORT_TYPE_TASK) {
++    port_size = sizeof(task_port_t);
++  }
++  else if (type == KE_PORT_TYPE_IPC) {
++    port_size = sizeof(ipc_port);
++  }
++  else {
++    panic("ke_port_allocate(): unknown port type");
++  }
++
++  down_write(&ports_sem);
++  up_write(&ports_sem);
++
++  prt = (ke_port_t*)kmalloc(port_size, GFP_KERNEL);
++
++  prt->type = type;
++  prt->active = true;
++  mutex_init(&prt->mtx);
++  atomic_set(&prt->refs, 0);
++
++  return prt;
++}
++
++boolean_t ke_port_active(ke_port_t* port)
++{
++  boolean_t active;
++  active = port->active;
++
++  return active;
++}
++
++void ke_port_up(ke_port_t* port)
++{
++  int ar;
++  ar = atomic_dec_return(&port->refs);
++
++  ke_log("ke_port_up(%p): refcount %d\n", port, ar);
++
++  if (ar < 0) {
++    panic("port refcount is smaller than 0, something is broken!");
++  }
++}
++
++boolean_t ke_port_down(ke_port_t* port)
++{
++  //if (!PortActive(port)) {
++  //  return false;
++  //}
++  //else {
++    int ar;
++    ar = atomic_inc_return(&port->refs);
++
++    ke_log("ke_port_down(%p): refcount %d\n", port, ar);
++
++    return true;
++  //}
++}
++
++ke_port_right_t* ke_create_right(void)
++{
++  ke_port_right_t* right;
++
++  right = (ke_port_right_t*)kmem_cache_alloc(zone_port_rights, GFP_KERNEL);
++
++  atomic_set(&(right->r_receive), 0);
++  atomic_set(&(right->r_send), 0);
++  atomic_set(&(right->r_port_set), 0);
++  atomic_set(&(right->r_send), 0);
++  atomic_set(&(right->r_kernel), 0);
++}
++
++void ke_add_right_to_space(task_port_t* space, ke_port_right_t* rr)
++{
++  PortLock(space);
++
++  list_add(&(rr->list), &(space->port_rights));
++
++  PortUnlock(space);
++}
++
++void ke_teardown_task(task_port_t* space)
++{
++  struct list_head *p;
++  ke_port_right_t* rr = NULL;
++
++  PortLock(space);
++  space->port.active = false;
++
++  list_for_each (p, &(space->port_rights)) {
++    int count;
++    ke_port_t* port;
++
++    RefModifyLockDown();
++    rr = list_entry(p, ke_port_right_t, list);
++    port = rr->port;
++    RightIncrementRefCount(rr, r_kernel);
++    PortRetain(port);
++    RefModifyLockUp();
++
++    count = atomic_read(&(rr->r_receive));
++
++    if (count == 1) {
++      ke_log("tearing down receive right %d\n", rr->name);
++      if (port->type == KE_PORT_TYPE_IPC)
++      {
++        ipc_port* iport = (ipc_port*)port;
++
++        /* release the completion variable */
++        iport->dead = true;
++        complete(&(iport->wait_for_enqueued_data));
++      }
++
++      port->active = false;
++    }
++    else if (count > 1) {
++      panic("port right %d has more than one receive ref!", rr->name);
++    }
++    else {
++      /* 0 */
++    }
++
++    RightDecrementRefCount(rr, r_kernel);
++    PortRelease(port);
++  }
++
++  PortUnlock(space);
++}
++
++task_port_t* ke_get_task_port(struct task_struct* task)
++{
++  RefModifyLockDown();
++
++  task_port_t* tp = (task_port_t*)task->task_port;
++  PortRetain(tp);
++
++  RefModifyLockUp();
++
++  return tp;
++}
++
++task_port_t* ke_get_current_task(void)
++{
++  return ke_get_task_port(current);
++}
++
++/*
++ * Either gets an existing port right or adds it to the 
++ * ipc space (if add is specified).
++ */
++ke_port_right_t* ke_get_right_in_space(task_port_t* space, ke_port_t* fprt, boolean_t add)
++{
++  struct list_head *p;
++  ke_port_right_t* rr = NULL;
++
++  PortLock(space);
++
++  if (space->port.type != KE_PORT_TYPE_TASK) {
++    /* Only tasks can store rights */
++    PortUnlock(space);
++    goto out;
++  }
++
++  list_for_each (p, &(space->port_rights)) {
++    rr = list_entry(p, ke_port_right_t, list);
++    if (rr->port == fprt) {
++      PortUnlock(space);
++      goto out;
++    }
++  }
++
++  PortUnlock(space);
++
++  /*
++   * Right not found in the list, we need to add
++   * a new one to it.
++   */
++  rr = ke_create_right();
++  rr->port = fprt;
++  ke_add_right_to_space(space, rr);
++
++out:
++  if (rr) {
++    RightIncrementRefCount(rr, r_kernel);
++  }
++  return rr;
++}
++
++/*
++ * Creates a brand new port (not a right, an actual port)
++ * in the space. Also sets up a empty right for the port.
++ * The unassosciated right is returned.
++ * This function sets up a new port name for the port.
++ */
++ke_port_right_t* ke_new_port(uint16_t type)
++{
++  ke_port_right_t* rr;
++  ke_port_t* kprt;
++
++  kprt = ke_port_allocate(type);
++
++  /* Set up the first right */
++  rr = ke_create_right();
++  rr->port = kprt;
++  rr->urefs = 1;
++
++  return rr;
++}
++
++
++/*
++ * Finds a port right.
++ */
++ke_port_right_t* ke_right_find_named(mach_port_t name)
++{
++  ke_port_right_t* prt = NULL;
++  task_port_t* space;
++  ke_port_right_t* rr;
++  struct list_head *p;
++
++  space = ke_get_current_task();
++
++  RefModifyLockDown();
++
++  PortLock(space);
++  list_for_each (p, &(space->port_rights)) {
++    rr = list_entry(p, ke_port_right_t, list);
++    if (rr->name == name) {
++      prt = rr;
++    }
++  }
++  PortUnlock(space);
++
++  PortRelease(space);
++  
++  if (prt) {
++    if (PortRetain(prt->port)) {
++      /* Nothing */
++    }
++    else {
++      /*
++       * Right points to an inactive port.
++       * Pretend it doesn't exist.
++       */
++      RefModifyLockUp();
++      return NULL;
++    }
++  }
++
++  RefModifyLockUp();
++
++  if (prt) {
++    RightIncrementRefCount(rr, r_kernel);
++  }
++  return prt;
++}
++
++/*
++ * Finds a port by its port name in the local
++ * ipc space. If it is not found, returns NULL.
++ */
++ke_port_t* ke_port_find_named(mach_port_t name)
++{
++  ke_port_t* prt = NULL;
++  ke_port_right_t* rr;
++
++  rr = ke_right_find_named(name);
++  if (rr) {
++    prt = rr->port;
++    RightDecrementRefCount(rr, r_kernel);
++  }
++
++  return prt;
++}
++
++mach_port_t ke_get_new_port_name_in_space(task_port_t* space)
++{
++  int id = 0;
++  int res = 0;
++  if (idr_pre_get(&(space->name_pool), GFP_KERNEL) == 0) {
++    panic("ke_get_new_port_name_in_space(): idr failure");
++  }
++
++  res = idr_get_new_above(&(space->name_pool), NULL, 20, &id);
++
++  if (res != 0)
++  {
++    panic("ke_get_new_port_name_in_space(): idr failure 2");
++  } 
++
++  return id;
++}
++
++kern_return_t task_message_handle(void* payload, void* trap_data)
++{
++  panic("task_message_handle");
++}
++
++ke_port_right_t* ke_create_ipc_space(void)
++{
++  task_port_t* kprt = NULL;
++  ke_port_right_t* rr = NULL;
++
++  rr = ke_new_port(KE_PORT_TYPE_TASK);
++  if (!rr || !rr->port) {
++    panic("ke_create_ipc_space(): unable to create a new ipc space");
++  }
++  kprt = (task_port_t*)rr->port;
++
++  kprt->port.msg_handler = task_message_handle;
++
++  /* Initalize the port right list */
++  INIT_LIST_HEAD(&(kprt->port_rights));
++
++  /* Initialize IDR for allocating port names */
++  idr_init(&(kprt->name_pool));
++
++  return rr;
++}
++
++void ke_setup_task_port(struct task_struct* task)
++{
++  ke_port_right_t* rr = ke_create_ipc_space();
++  task_port_t* kprt = (task_port_t*)rr->port;
++
++  /* Set the task descriptor */
++  kprt->task = task;
++
++  /* And set the port */
++  task->task_port = (void*)kprt;
++
++  /* Add a receive right for the kernel */
++  rr->name = ke_get_new_port_name_in_space(kernel_task);
++  RightIncrementRefCount(rr, r_receive);
++  ke_add_right_to_space(kernel_task, rr);
++
++  /* Add a send right to the task */
++  rr = ke_create_right();
++  rr->port = (ke_port_t*)kprt;
++  rr->name = ke_get_new_port_name_in_space(kprt);
++  RightIncrementRefCount(rr, r_send);
++  ke_add_right_to_space(kprt, rr);
++
++  ke_log("ke_setup_task_port(): task %p got port %d\n", task, rr->name);
++}
++
++static void dump_mach_msg_hdr(mach_msg_header_t* head) {
++  return;
++
++  printk(KERN_WARNING "Mach Message:\n"
++  "\tbits: %p\n\tsize: %d\n\tremote: %d\n\tlocal: %d\n\tid : %d\n"
++  ,(void*)head->msgh_bits, head->msgh_size, head->msgh_remote_port, head->msgh_local_port, head->msgh_id);
++}
++
++kern_return_t mach_port_destroy(ipc_space_t task, mach_port_name_t name)
++{
++  return KERN_FAILURE;
++}
++
++SYSCALL_DEFINE1(mach_msg_trap, struct mach_msg_trap_data __user *, usr_data)
++{
++  printk("sys_mach_msg_trap(): obsolete, do not use!");
++  return KERN_FAILURE;
++}
++
++kern_return_t _user_mach_msg_trap(struct mach_msg_trap_data __user* usr_data)
++{
++  mach_msg_trap_data_t trap_data;
++  kern_return_t ret;
++  ke_port_t* receiver;
++  ke_port_right_t* receiver_right;
++
++  /* For the message we will read in */
++  mach_msg_header_t tmsg;
++  mach_msg_header_t* msg;
++  mach_port_t receive_name;
++
++  if (!current) {
++    panic("mach_msg_trap(): used without user context");
++  }
++
++  /* read in the trap data */
++  if (copy_from_user(&trap_data, usr_data, sizeof(mach_msg_trap_data_t)))
++  {
++    ret = KERN_FAILURE;
++    goto out;
++  }
++
++  /* read in the temp message header */ 
++  if (copy_from_user(&tmsg, trap_data.msg, sizeof(mach_msg_header_t)))
++  {
++    ret = KERN_FAILURE;
++    goto out;
++  }
++
++  receive_name = trap_data.receive_name;
++  if (receive_name == 0) {
++    /* send only */
++    receive_name = tmsg.msgh_remote_port;
++  }
++
++  ke_log("mach_msg(): using port %d\n", receive_name);
++
++  /*
++   * Read in the entire inline message. We leave an empty space
++   * at the end so we can place the message trailer there.
++   *
++   *  XXX: Needs some sort of a bounds check for kalloc.
++  */
++  msg = (mach_msg_header_t*)kmalloc(tmsg.msgh_size + LARGEST_TRAILER_SIZE, GFP_KERNEL);
++  if (copy_from_user(msg, trap_data.msg, tmsg.msgh_size)) {
++    ret = KERN_FAILURE;
++    goto out;
++  }
++
++  dump_mach_msg_hdr(msg);
++
++  receiver_right = ke_right_find_named(receive_name);
++
++  if (!receiver_right)
++  {
++    printk("mach_msg_trap(): port name %d not found in ipc space\n", receive_name);
++    ret = KERN_FAILURE;
++    goto out;
++  }
++
++  receiver = receiver_right->port;
++  RightDecrementRefCount(receiver_right, r_kernel);
++
++  if (!receiver)
++  {
++    printk("mach_msg_trap(): %d, internal error\n", receive_name);
++    ret = KERN_FAILURE;
++    goto out;
++  }
++
++  if (receiver->msg_handler != NULL)
++  {
++    ret = receiver->msg_handler((void*)msg, (void*)(&trap_data));
++    PortRelease(receiver);
++  }
++  else
++  {
++    PortRelease(receiver);
++    ke_log("mach_msg_trap(): mach port %p can't receive messages\n", receiver);
++    ret = KERN_FAILURE;
++    goto out;
++  }
++
++out:
++  if (ret != KERN_SUCCESS) {
++    ke_log("mach_msg_trap(): returning with error %d\n", ret);
++  }
++
++  return ret;
++}
++
++int init_mach_ipc(void)
++{
++  ke_port_right_t* rr = NULL;
++  ke_port_t* kprt = NULL;
++
++  zone_port_rights = 
++  kmem_cache_create("zone_port_rights", sizeof(ke_port_right_t), 0, SLAB_PANIC, NULL);
++
++  if (!zone_port_rights) {
++    panic("init_mach_ipc(): failed to create port right slab");
++  }
++
++  /*
++   * Create an IPC space for the kernel.
++   */
++  rr = ke_create_ipc_space();
++  kprt = rr->port;
++  kernel_task = (task_port_t*)kprt;
++
++  ke_log("init_mach_ipc(): started mach ipc subsystem {max_ports=%d}\n", MAX_PORT_COUNT);
++
++  return 0;
++}
+diff -Naur ./old//magenta/mach_kmsg.c ./kern//magenta/mach_kmsg.c
+--- ./old//magenta/mach_kmsg.c 1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/mach_kmsg.c  2012-06-24 13:29:50.000000000 +0100
+@@ -0,0 +1,52 @@
++#include <linux/time.h>
++#include <linux/kernel.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/string.h>
++#include <linux/fs.h>
++#include <linux/file.h>
++#include <linux/stat.h>
++#include <linux/fcntl.h>
++#include <linux/ptrace.h>
++#include <linux/user.h>
++#include <linux/binfmts.h>
++#include <linux/personality.h>
++#include <linux/init.h>
++#include <linux/coredump.h>
++#include <linux/slab.h>
++#include <linux/namei.h>
++#include <linux/security.h>
++#include <linux/syscalls.h>
++#include <linux/kfifo.h>
++
++#include <asm/system.h>
++#include <asm/uaccess.h>
++#include <asm/cacheflush.h>
++#include <linux/linkage.h>
++
++#include "ipc_types.h"
++#include "mach_kmsg.h"
++
++void get_dents_darwin(kmsg_get_directory_entries_t* km);
++void kmsg_load_kext(kmsg_load_kext_msg_t* msg);
++
++#define MsgToKmsg(type) type* km = (type*)msg;
++
++void kmsg_mach_task_self(kmsg_mach_task_self_msg_t* km)
++{
++  panic("kmsg_mach_task_self");
++}
++
++int kmsg_handle(mach_msg_header_t* msg)
++{
++  switch (msg->msgh_id)
++  {
++    default:
++    {
++      printk("kmsg_handle(): invalid kernel message (id: %d)\n", msg->msgh_id);
++      return -EINVAL;
++    }
++  }
++}
+diff -Naur ./old//magenta/mach_kmsg.h ./kern//magenta/mach_kmsg.h
+--- ./old//magenta/mach_kmsg.h 1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/mach_kmsg.h  2012-06-03 17:06:16.000000000 +0100
+@@ -0,0 +1,53 @@
++/*
++ * mach_kmsg.h
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Special mach messages that get interpreted by the
++ * kernel.
++ */
++
++#ifndef _H_MG_MACH_KMSG_
++#define _H_MG_MACH_KMSG_
++
++#include "ipc_types.h"
++
++#define KMSG_MACH_PORT_ALLOCATE 2000
++#define KMSG_LOAD_KEXT 2001
++#define KMSG_GET_DIRECTORY_ENTRIES 2002
++
++typedef struct 
++{
++  mach_msg_header_t head;
++  mach_port_right_t rights;
++  mach_port_t* port_out;
++} kmsg_mach_port_allocate_msg_t;
++
++typedef struct 
++{
++  mach_msg_header_t head;
++  void* buffer;
++  unsigned int buffer_len;
++} kmsg_load_kext_msg_t;
++
++typedef struct 
++{
++  mach_msg_header_t head;
++  int fd;
++  int* out_error;
++  void* buffer;
++  unsigned int buffer_len;
++} kmsg_get_directory_entries_t;
++
++
++/*
++ * 2100: Mach routines
++ */
++#define KMSG_MACH_TASK_SELF 2100
++
++typedef struct 
++{
++  mach_msg_header_t head;
++  mach_port_t* out_port;
++} kmsg_mach_task_self_msg_t;
++
++#endif
+diff -Naur ./old//magenta/macho_loader.c ./kern//magenta/macho_loader.c
+--- ./old//magenta/macho_loader.c  1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/macho_loader.c 2012-06-24 14:24:44.000000000 +0100
+@@ -0,0 +1,1216 @@
++/*
++ * MachO Binary Format Support
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * A standalone kernel module responsible for loading MachO binaries
++ * into the kernel. Right now this only supports ARM binaries.
++ */
++
++/*
++ * Incl.
++ */
++#include <linux/module.h>
++#include <linux/kernel.h>
++#include <linux/fs.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/binfmts.h>
++#include <linux/string.h>
++#include <linux/file.h>
++#include <linux/slab.h>
++#include <linux/personality.h>
++#include <linux/elfcore.h>
++#include <linux/init.h>
++#include <linux/highuid.h>
++#include <linux/compiler.h>
++#include <linux/highmem.h>
++#include <linux/pagemap.h>
++#include <linux/security.h>
++#include <linux/random.h>
++#include <linux/elf.h>
++#include <linux/utsname.h>
++#include <linux/coredump.h>
++#include <asm/uaccess.h>
++#include <asm/param.h>
++#include <asm/page.h>
++
++#include <DarwinTypes.h>
++#include <MachO.h>
++
++
++/* 
++  This needs to be in the MachO.h header.
++  #####################################################
++*/
++#define SEG_TEXT  "__TEXT"
++
++/* mach_loader.h */
++#define LOAD_SUCCESS            0
++#define LOAD_BADARCH            1       /* CPU type/subtype not found */
++#define LOAD_BADMACHO           2       /* malformed mach-o file */
++#define LOAD_SHLIB              3       /* shlib version mismatch */
++#define LOAD_FAILURE            4       /* Miscellaneous error */
++#define LOAD_NOSPACE            5       /* No VM available */
++#define LOAD_PROTECT            6       /* protection violation */
++#define LOAD_RESOURCE           7       /* resource allocation failure */
++
++#define ARM_THREAD_STATE 1
++
++#ifndef CPU_TYPE_ARM
++#define CPU_TYPE_ARM            ((cpu_type_t) 12)
++#define CPU_SUBTYPE_ARM_V4T   ((cpu_subtype_t) 5)
++#define CPU_SUBTYPE_ARM_V6    ((cpu_subtype_t) 6)
++#endif
++
++#ifndef CPU_SUBTYPE_ARM_V5TEJ
++#define CPU_SUBTYPE_ARM_V5TEJ           ((cpu_subtype_t) 7)
++#endif
++
++#ifndef CPU_SUBTYPE_ARM_V7
++#define CPU_SUBTYPE_ARM_V7    ((cpu_subtype_t) 9)
++#endif
++
++/* ARM ONLY! */
++#define trunc_page(x)           ((x) & ~PAGE_MASK)
++
++
++
++/* 
++  Forward declarations
++  #####################################################
++*/
++static int fucking_core_dumper(struct coredump_params *cprm);
++static int load_macho_binary(struct linux_binprm *bprm, struct pt_regs *regs);
++static int load_macho_library(struct file *);
++static unsigned long macho_map(struct file *, unsigned long, struct elf_phdr *,
++        int, int, unsigned long);
++
++
++/* 
++  Impl
++  #####################################################
++*/
++#define round_page(_v) (((_v) + PAGE_SIZE - 1) & ~(PAGE_SIZE - 1))
++
++#define LINK_TABLE_ADDR 0x80014000
++#define LINK_TABLE_SIZE PAGE_SIZE*2
++
++typedef struct {
++  uint32_t entry_count;
++  size_t table_size;
++} linker_image_table_header_t;
++
++typedef struct {
++  uintptr_t load_addr;
++  size_t size;
++  const char* name;
++} linker_image_entry_t;
++
++static struct linux_binfmt macho_format = {
++    .module   = THIS_MODULE,
++    .load_binary  = load_macho_binary,
++    .load_shlib = load_macho_library,
++    .core_dump  = fucking_core_dumper, /* YOU GET NOTHING! */
++    .min_coredump = 0,
++    .hasvdso  = 0
++};
++
++#define BAD_ADDR(x) ((unsigned long)(x) >= TASK_SIZE)
++
++/* Let's use some macros to make this stack manipulation a little clearer */
++#ifdef CONFIG_STACK_GROWSUP
++#define STACK_ADD(sp, items) ((elf_addr_t __user *)(sp) + (items))
++#define STACK_ROUND(sp, items) \
++  ((15 + (unsigned long) ((sp) + (items))) &~ 15UL)
++#define STACK_ALLOC(sp, len) ({ \
++  elf_addr_t __user *old_sp = (elf_addr_t __user *)sp; sp += len; \
++  old_sp; })
++#else
++#define STACK_ADD(sp, items) ((elf_addr_t __user *)(sp) - (items))
++#define STACK_ROUND(sp, items) \
++  (((unsigned long) (sp - items)) &~ 15UL)
++#define STACK_ALLOC(sp, len) ({ sp -= len ; sp; })
++#endif
++
++static unsigned long load_macho_interp(struct elfhdr *interp_elf_ex,
++    struct file *interpreter, unsigned long *interp_map_addr,
++    unsigned long no_base)
++{
++  panic("load_macho_interp: not implemented, use macho_get_dylinker instead. ");
++}
++
++
++static unsigned long randomize_stack_top(unsigned long stack_top)
++{
++  return stack_top;
++}
++
++static int ml_setBrk(unsigned long start, unsigned long end)
++{
++  start = PAGE_ALIGN(start);
++  end = PAGE_ALIGN(end);
++  if (end > start) {
++    unsigned long addr;
++    down_write(&current->mm->mmap_sem);
++    addr = do_brk(start, end - start);
++    up_write(&current->mm->mmap_sem);
++    if (BAD_ADDR(addr))
++      return addr;
++  }
++  current->mm->start_brk = current->mm->brk = start;
++  return 0;
++}
++
++static int _verboseLog = 0;
++
++/* 
++  LOADER
++  #####################################################
++*/
++typedef int vm_offset_t;
++typedef int vm_size_t;
++
++static int macho_get_dylinker(struct linux_binprm *bprm, int file_size, struct dylinker_command * lcp, struct file **linker_file) {
++  /*
++    Setup the dynamic linker.
++  */
++  char *name;
++  char *p;
++  
++  if (lcp->cmdsize < sizeof(*lcp))
++    return (LOAD_BADMACHO);
++
++  name = (char *)lcp + lcp->name.offset;
++
++  /* Make sure the linker path is null terminated */
++  p = name;
++  do {
++    if (p >= (char *)lcp + lcp->cmdsize)
++      return(LOAD_BADMACHO);
++  } while (*p++);
++
++  if (_verboseLog) 
++    printk(KERN_WARNING "macho_get_dylinker: dynamic linker is @'%s'\n", name);
++
++  /*
++    Load the linker executable file.
++  */
++  *linker_file = open_exec(name);
++  if (IS_ERR(*linker_file)) {
++    printk(KERN_WARNING "macho_get_dylinker: can't execute the dynamic linker\n");
++    return(LOAD_BADMACHO);
++  }
++
++  return LOAD_SUCCESS;
++}
++
++static int macho_load_unix_thread(struct linux_binprm *bprm, int file_size, struct arm_thread_command * tcp, void** entry) {
++  /*
++    Setup the main thread.
++  */
++  
++  /* sanity */
++  if (tcp->flavor != ARM_THREAD_STATE) {
++    printk(KERN_WARNING "macho_load_unix_thread: main thread is of the wrong type %d (need %d)\n",
++        tcp->flavor,
++        ARM_THREAD_STATE);
++  }
++  else if (tcp->count != 17) {
++    printk(KERN_WARNING "macho_load_unix_thread: has the wrong number of arm registers %d (need %d)\n",
++        tcp->count,
++        17);
++  }
++  else {
++    /**/
++    
++    /* Entry point */
++    if (_verboseLog)
++      printk(KERN_WARNING "macho_load_unix_thread: success, pc @ %d\n", tcp->state.r15);
++    
++    *entry = (void*)tcp->state.r15;
++  }
++  
++  return LOAD_SUCCESS;
++}
++
++static int macho_load_segment(struct linux_binprm *bprm,
++              int file_size,
++              struct segment_command* scp,
++              int* top,
++              void** first_text,
++              vm_offset_t slide)
++{
++  /*
++    Bootstrap a macho segment.
++  */
++  
++  /***/
++  size_t segment_command_size = sizeof(struct segment_command);
++  size_t total_section_size = scp->cmdsize - segment_command_size;
++  size_t single_section_size  = sizeof(struct section);
++  
++  int ret;
++  
++  /* setup mapping vars */
++  vm_offset_t map_addr = round_page(scp->vmaddr);
++  vm_size_t map_size = round_page(scp->filesize);
++  vm_size_t seg_size = round_page(scp->vmsize);
++  vm_offset_t map_offset = scp->fileoff;
++  vm_size_t delta_size;
++  vm_offset_t addr;
++  /*
++    Segment sanity checks.
++  */
++  /* is the command right? */
++  if (scp->cmdsize < segment_command_size) {
++    printk(KERN_WARNING "macho_load_segment(%.*s): malformed command", 16, scp->segname);
++    return (LOAD_BADMACHO);
++  }
++  /* is the segment in range? */
++  if (scp->fileoff + scp->filesize < scp->fileoff ||
++    scp->fileoff + scp->filesize > (uint64_t)file_size) {
++    printk(KERN_WARNING "macho_load_segment(%.*s): out of range", 16, scp->segname);
++    return (LOAD_BADMACHO);
++  }
++  /* is page aligned? */
++  if ((scp->fileoff & (PAGE_SIZE-1)) != 0) {
++    printk(KERN_WARNING "macho_load_segment(%.*s): not page aligned", 16, scp->segname);
++    return (LOAD_BADMACHO);
++  }
++  
++  
++  
++  /*
++    Print some info about the segment.
++  */
++  if (_verboseLog)
++    printk(KERN_WARNING "macho_load_segment(%.*s): addr %d, filesize %d, vmsize %d\n",
++        16,
++        scp->segname,
++        map_addr,
++        map_size,
++        seg_size);
++  
++  /*
++  do_mmap(struct file *file,
++      unsigned long addr,
++      unsigned long len,
++      unsigned long prot,
++      unsigned long flag,
++      unsigned long offset)
++  */
++  
++  /* Actually map in the segment into the correct location.
++   */
++  if (map_size > 0) {
++    /* There is something from the file to map */
++    
++    addr = PAGE_ALIGN(map_addr + slide);
++    
++    if (_verboseLog)
++      printk(KERN_WARNING "macho_load_segment(%.*s): seg mmap @ %d, offset %d \n",
++          16,
++          scp->segname,
++          addr,
++          map_offset);
++    
++    /* lock */
++    down_write(&current->mm->mmap_sem);
++    void* mapped =    
++    do_mmap(bprm->file,
++        addr,
++        map_size,
++        PROT_WRITE | PROT_READ | PROT_EXEC,
++        MAP_PRIVATE | MAP_FIXED,
++        map_offset);
++    /* unlock */
++    up_write(&current->mm->mmap_sem);
++    
++    if (strncmp(scp->segname, SEG_TEXT, 16) == 0) {
++      /*
++        This is a text segment, check if it's mapped from zero and then
++        bump up the first_text variable to make sure it points to its start.
++      */
++      if (map_offset == 0) {
++        if (_verboseLog)
++          printk(KERN_WARNING "macho_load_segment(%.*s): this is the base segment \n", 16, scp->segname);
++        
++        *first_text = (void*)(addr);
++      }
++    }
++    
++    if ((mapped) <= 0) {
++      printk(KERN_WARNING "macho_load_segment(%.*s): map file seg failed \n", 16, scp->segname);
++      ret = LOAD_RESOURCE;
++      goto out;
++    }
++    else {
++      if (_verboseLog)
++        printk(KERN_WARNING "macho_load_segment(%.*s): mapped in @ %d \n", 16, scp->segname, (void*)mapped);
++    }
++    
++    /*
++     *  If the file didn't end on a page boundary,
++     *  we need to zero the leftover.
++     */
++    delta_size = map_size - scp->filesize;
++    if (delta_size > 0) {
++      if (_verboseLog)
++        printk(KERN_WARNING "macho_load_segment(%.*s): fixxuuup \n", 16, scp->segname); 
++    }
++  }
++  
++  /*  If the virtual size of the segment is greater
++   *  than the size from the file, we need to allocate
++   *  anonymous zero fill memory for the rest. 
++   */
++  delta_size = seg_size - map_size;
++  if (delta_size > 0) {
++    addr = PAGE_ALIGN(map_addr + map_size + slide);
++    
++    if (_verboseLog)
++      printk(KERN_WARNING "macho_load_segment(%.*s): mmap @ %d, size: %d\n", 16, scp->segname, addr, delta_size);
++    
++    /* lock */
++    down_write(&current->mm->mmap_sem);
++    void* mapped =    
++    do_mmap(NULL,
++        addr,
++        delta_size,
++        PROT_WRITE | PROT_READ | PROT_EXEC,
++        MAP_FIXED | MAP_PRIVATE,
++        0);
++    /* unlock */
++    up_write(&current->mm->mmap_sem);
++    
++    if ((mapped) <= 0) {
++      printk(KERN_WARNING "macho_load_segment(%.*s): map anon failed \n", 16, scp->segname);
++      ret = LOAD_RESOURCE;
++      goto out;
++    }
++    else {
++      if (_verboseLog)
++        printk(KERN_WARNING "macho_load_segment(%.*s): anon chunk mapped in @%p \n", 16, scp->segname, (void*)mapped);
++    }
++  }
++  
++  if (*top < (map_addr + slide + seg_size)) {
++    /* highest address so far, update the top variable */
++    *top = ((map_addr + slide + seg_size));
++  }
++  
++  /* mapped in successfully */
++  ret = LOAD_SUCCESS;
++  
++out:    
++  return ret;
++}
++
++static int macho_get_file_size(struct file* file) {
++  /* file size from struct file */
++  
++  /* sanity checks */
++  if (!file)
++    return -1;
++  if (!file->f_path.dentry)
++    return -1;
++  if (!file->f_path.dentry->d_inode) 
++    return -1;
++    
++  return file->f_path.dentry->d_inode->i_size;
++}
++
++static int macho_validate_image(struct file* file, macho_header* head) 
++{
++  /*
++    Sanity checks.
++  */
++  int retval = -ENOEXEC;
++  int file_size = 0;
++  size_t macho_header_sz = sizeof(macho_header);
++  
++  if (head->magic != MH_MAGIC) {
++    printk(KERN_WARNING "macho_validate_image: binary is not a macho binary (magic: 0x%p) \n", (void*)head->magic);
++    retval = -ENOEXEC;
++    goto out_ret;
++  }
++  
++  /*
++    Validate architecture.
++  */
++  if (head->cputype != CPU_TYPE_ARM) {
++    printk(KERN_WARNING "macho_validate_image: wrong architecture in the executable\n");
++    retval = -EINVAL;
++    goto out_ret;
++  }
++  
++  /*
++    Run ARM-specific validation checks
++  */
++  if (head->cputype == CPU_TYPE_ARM) {
++    if (head->cpusubtype == CPU_SUBTYPE_ARM_V7)
++    {
++      if (cpu_architecture() != CPU_ARCH_ARMv7) {
++        printk(KERN_WARNING "macho_validate_image: armv7 executables are not supported by the current platform\n");
++        retval = -EINVAL;
++        goto out_ret;
++      }
++    }
++    else if (head->cpusubtype == CPU_SUBTYPE_ARM_V6)
++    {
++      if (cpu_architecture() != CPU_ARCH_ARMv6 && cpu_architecture() != CPU_ARCH_ARMv7) {
++        printk(KERN_WARNING "macho_validate_image: armv6 executables are not supported by the current platform\n");
++        retval = -EINVAL;
++        goto out_ret;
++      }
++    }
++    else {
++      printk(KERN_WARNING "macho_validate_image: unrecognized arm version in the executable (%d)\n", head->cpusubtype);
++      retval = -EINVAL;
++      goto out_ret;
++    }
++  }
++  
++  
++  /*
++    Make sure the file size can be retrieved in order 
++      to perform sanity checks on the file.
++   */
++  file_size = macho_get_file_size(file);
++  if (file_size < 0) {
++    printk(KERN_WARNING "macho_validate_image: can't retrieve binary size \n");
++    retval = -EINVAL;
++    goto out_ret;
++  }
++  
++  /*
++    Main portion of the sanity checks for the macho file.
++  */
++  
++  retval = -EINVAL;
++  /* can we map it? */
++  if (!file->f_op||!file->f_op->mmap) {
++    printk(KERN_WARNING "macho_validate_image: binary file can't be mapped in \n");
++    goto out_ret;
++  }
++  /* sane lc size? */
++  if ((off_t)(macho_header_sz + head->sizeofcmds) > file_size) {
++    printk(KERN_WARNING "macho_validate_image: malformed load commands size \n");
++    goto out_ret;
++  }
++  if (head->filetype != MH_EXECUTE) {
++    printk(KERN_WARNING "IGN:macho_validate_image: macho file is not executable \n");
++    //goto out_ret;
++  }
++  
++  /* Print some info about the macho file */
++  if (_verboseLog)
++    printk(KERN_WARNING "macho_validate_image: valid macho file: \n\tmagic: 0x%p \n\tsize: %d\n",
++        (void*)head->magic,
++        file_size);
++  
++  retval = 0;
++  
++out_ret:  
++  return retval;
++}
++
++static int macho_load_dylinker(struct file* file, /* file for the dylinker*/
++                int* top_data, /* top of image data */
++                void** first_text,
++                void** entry_point) /* first text segment of the linker */
++                
++{
++  /* fake bprm for the segment loader*/
++  struct linux_binprm bprm;
++  
++  int retval;
++  int load_addr = *top_data;
++  size_t macho_header_sz = sizeof(macho_header);
++  macho_header* head = kmalloc(macho_header_sz, GFP_KERNEL);
++  int file_size = 0;
++
++  /* this is for LC loader */
++  int ret = 0;
++  size_t offset;
++  size_t oldoffset;
++  uint32_t ncmds;
++  uint8_t* addr;
++  
++  if (_verboseLog)
++    printk(KERN_WARNING "macho_load_dylinker: loading dynamic linker @ %d\n", load_addr);
++
++  /*
++    Read in the macho header.
++  */
++  kernel_read(file, 0, head, macho_header_sz);
++
++  retval = macho_validate_image(file, head);
++  if (retval) {
++    retval = LOAD_BADMACHO;
++    printk(KERN_WARNING "macho_load_dylinker: dylinker image failed sanity checks, not loading \n");
++    goto out_ret;
++  }
++  
++  /*
++    XXX: this should be retrieved by macho_validate_image()
++  */
++  file_size = macho_get_file_size(file);
++  
++  /*
++    Read the load commands from the file.
++  */
++  offset = 0;
++  ncmds = head->ncmds;
++  addr = kmalloc(head->sizeofcmds, GFP_KERNEL); /***/
++  retval = -EINVAL;
++  
++  /* read in load commands */
++  kernel_read(file, macho_header_sz, addr, head->sizeofcmds);
++  
++  bprm.file = file;
++  
++  while (ncmds--) {
++    /* LC pointer */
++    struct load_command *lcp = 
++    (struct load_command *)(addr + offset);
++    
++    oldoffset = offset;
++    offset += lcp->cmdsize;
++    
++    if (oldoffset > offset ||
++        lcp->cmdsize < sizeof(struct load_command) ||
++        offset > head->sizeofcmds + macho_header_sz)
++    {
++      printk(KERN_WARNING "macho_load_dylinker: malformed binary - lc overflow \n");
++      goto lc_ret;
++    }
++    
++    /*  Parse load commands.
++     
++      We only need a bare minimum to get the image up an running. Dyld will
++      take care of all the other stuff.
++     */
++    switch(lcp->cmd) {
++      case LC_SEGMENT:
++      {
++        /*
++          Load and slide a dylinker segment.
++        */
++        ret = macho_load_segment(&bprm,
++                  file_size,
++                  (struct segment_command*)lcp,
++                  top_data, /* keep bumping the same top_data */
++                  first_text, /* first text segment */
++                  load_addr); /* slide up */
++        
++        if (ret != LOAD_SUCCESS) {
++          printk(KERN_WARNING "macho_load_dylinker: segment loading failure \n");
++          goto lc_ret;
++        }
++        break;
++      }
++      case LC_UNIXTHREAD:
++      {
++        ret = macho_load_unix_thread(&bprm,
++                    file_size,
++                    (struct arm_thread_command*)lcp,
++                    entry_point);
++                    
++        if (ret != LOAD_SUCCESS) {
++          printk(KERN_WARNING "macho_load_dylinker: unix thread loading failure \n");
++          goto lc_ret;
++        }
++        break;
++      }
++      default: 
++      {
++        if (_verboseLog)
++          printk(KERN_WARNING "macho_load_dylinker: unsupported lc 0x%p \n", (void*)lcp->cmd);
++        
++        break;
++      }
++    }
++  }
++
++
++  /* loaded successfully */
++  retval = LOAD_SUCCESS;
++  
++  /* free resources */
++  lc_ret:
++    kfree(addr);
++  
++  out_ret:  
++    kfree(head);
++    return retval;
++}
++
++static struct page* dpages[1] = {NULL};
++
++static void wire_weird_pages(void)
++{
++  int ret;
++  void* addr;
++
++  /* 0x80000000 */
++  if (dpages[0] == NULL)
++  {
++    dpages[0] = alloc_pages(GFP_KERNEL, 0);
++  }
++
++
++  down_write(&current->mm->mmap_sem);
++  ret = 
++  install_special_mapping(current->mm,
++    0x80000000,
++    PAGE_SIZE,
++    VM_READ | VM_WRITE | VM_SHARED | VM_DONTCOPY,
++    dpages);
++  up_write(&current->mm->mmap_sem);
++
++  addr = page_address(dpages[0]);
++
++  memset(addr, 'w', PAGE_SIZE);
++
++  printk("wired weird page! (%p, %d, %p)\n", dpages[0], ret, addr);
++}
++
++static void macho_setup_link_table(void)
++{
++  void* mapped = LINK_TABLE_ADDR;
++  size_t sz = LINK_TABLE_SIZE;
++  linker_image_table_header_t* th;
++
++  down_write(&current->mm->mmap_sem);
++
++  mapped =    
++  do_mmap(NULL,
++      mapped,
++      sz,
++      PROT_WRITE | PROT_READ,
++      MAP_FIXED | MAP_PRIVATE,
++      0);
++
++  up_write(&current->mm->mmap_sem);
++
++  th = (linker_image_table_header_t*)mapped;
++
++  __put_user((uint32_t)2, &th->entry_count);
++  __put_user((size_t)sz, &th->table_size);
++  
++  printk("mapped link table @ %p\n", mapped);
++}
++
++static int load_macho_binary(struct linux_binprm *bprm, struct pt_regs *regs)
++{ 
++  unsigned long def_flags = 0;
++  void* entry_point = 0;
++  int retval = -ENOEXEC;
++  int file_size = 0;
++  int executable_stack = EXSTACK_DEFAULT;
++  size_t macho_header_sz = sizeof(macho_header);
++  macho_header* head = ((macho_header*)bprm->buf);
++  struct file *linker_file = NULL;
++  int dylinker_load_addr;
++
++  size_t offset;
++  size_t oldoffset;
++  uint32_t ncmds;
++  uint8_t* addr;
++
++  int ret = 0;
++  
++  /* Top of the image data. This is needed to position the heap. */
++  int top_data = 0;
++  
++  /* First text segment where the mach header is. */
++  void* first_text = 0;
++  void* first_text_linker = 0;
++
++  /* Stack environment (grows down on ARM). */
++  uint32_t* stack = bprm->p;
++  uint32_t* argv_array;
++  uint32_t* argv;
++  uint32_t* envp_array;
++  uint32_t* envp;
++  uint32_t total_argv_size;
++  uint32_t total_env_size;
++
++  /* Arg stuff */
++  uint32_t argc;
++  uint32_t envc;
++  char* p;
++
++  linker_image_entry_t* ee;
++
++  /* have we got enough space? */
++  if (!head) {
++    retval = -ENOMEM;
++    goto out_ret;
++  }
++  
++  retval = macho_validate_image(bprm->file, head);
++  if (retval) {
++    printk(KERN_WARNING "load_macho_binary: image failed sanity checks, not loading \n");
++    goto out_ret;
++  }
++  
++  /*
++    XXX: this should be retrieved by macho_validate_image()
++  */
++  file_size = macho_get_file_size(bprm->file);
++  
++  /*
++    The file seems to be alright, so set up an environment for the 
++    new binary to run in. After this, the old image will no longer be 
++    usable. If some of the load commands are broken, this process is doomed.
++  */
++  retval = flush_old_exec(bprm);
++  if (retval) {
++    panic("load_macho_binary: flush_old_exec failed\n");
++  }
++  else {
++    unsigned int personality;
++
++    current->flags &= ~PF_FORKNOEXEC;
++    current->mm->def_flags = def_flags;
++    
++    setup_new_exec(bprm);
++    
++    /* set personality */
++    personality = current->personality & ~PER_MASK;
++    personality |= PER_LINUX;
++    
++    /*
++      This flag has to be set for 32x architectures (I think).
++    */
++    personality |= ADDR_LIMIT_32BIT;
++    
++    set_personality(personality);
++
++    /* set stuff */
++    current->mm->free_area_cache = current->mm->mmap_base;
++    current->mm->cached_hole_size = 0;
++    //retval = setup_arg_pages(bprm, randomize_stack_top(STACK_TOP), executable_stack);
++          
++    if (retval < 0) {
++      //send_sig(SIGKILL, current, 0);
++      //goto out_ret;
++    }
++    
++    /* stack */
++    current->mm->start_stack = bprm->p;
++  }
++  
++  
++  /*
++    Read the load commands from the file.
++  */
++  offset = 0;
++  ncmds = head->ncmds;
++  addr = kmalloc(head->sizeofcmds, GFP_KERNEL); /***/
++  retval = -EINVAL;
++  
++  /* read in load commands */
++  kernel_read(bprm->file, macho_header_sz, addr, head->sizeofcmds);
++  
++  while (ncmds--) {
++    /* LC pointer */
++    struct load_command *lcp = 
++    (struct load_command *)(addr + offset);
++    
++    oldoffset = offset;
++    offset += lcp->cmdsize;
++    
++    if (oldoffset > offset ||
++        lcp->cmdsize < sizeof(struct load_command) ||
++        offset > head->sizeofcmds + macho_header_sz)
++    {
++      printk(KERN_WARNING "load_macho_binary: malformed binary - lc overflow \n");
++      goto lc_ret;
++    }
++    
++    /*  Parse load commands.
++     
++      We only need a bare minimum to get the image up an running. Dyld will
++      take care of all the other stuff.
++     */
++    switch(lcp->cmd) {
++      case LC_SEGMENT:
++        ret = macho_load_segment(bprm, file_size, (struct segment_command*)lcp, &top_data, &first_text, 0);
++        if (ret != LOAD_SUCCESS) {
++          printk(KERN_WARNING "load_macho_binary: segment loading failure \n");
++          goto lc_ret;
++        }
++        break;
++      case LC_LOAD_DYLINKER:
++        ret = macho_get_dylinker(bprm, file_size, (struct dylinker_command*)lcp, &linker_file);
++        if (ret != LOAD_SUCCESS) {
++          printk(KERN_WARNING "load_macho_binary: dylinker loading failure \n");
++          goto lc_ret;
++        }
++        else {
++          /* done */
++        }
++        break;
++      case LC_UNIXTHREAD:
++        ret = macho_load_unix_thread(bprm, file_size, (struct arm_thread_command*)lcp, &entry_point);
++        if (ret != LOAD_SUCCESS) {
++          printk(KERN_WARNING "load_macho_binary: unix thread loading failure \n");
++          goto lc_ret;
++        }
++        break;
++      default: 
++        if (_verboseLog)
++          printk(KERN_WARNING "load_macho_binary: unsupported lc 0x%p \n", (void*)lcp->cmd);
++
++        break;
++    }
++  }
++  
++  /*
++    Bootstrap the dynamic linker if needed.
++  */
++  if (linker_file) {
++    dylinker_load_addr = top_data;
++    
++    macho_load_dylinker(linker_file,
++              &top_data,
++              &first_text_linker,
++              &entry_point);
++    
++    /* slide the entry point */
++    entry_point = entry_point + dylinker_load_addr;
++      
++    if (_verboseLog)        
++      printk(KERN_WARNING "load_macho_binary: dylinker's first text segment @ %d, new pc @ %d \n",
++          first_text_linker,
++          (int)entry_point);
++  }
++  
++  /*
++    Now, I don't know what these are used for, but I'm fairly sure
++    they're *very* important. So let's set them up. 
++    
++    See 'linux/mm_types.h':
++    unsigned long start_code, end_code, start_data, end_data;
++    unsigned long start_brk, brk, start_stack;
++  */  
++  current->mm->start_code = 0; /* IMP */
++  current->mm->end_code = top_data; /* IMP */
++  current->mm->start_data = 0;
++  current->mm->end_data = top_data;
++    
++  if (_verboseLog)
++    printk(KERN_WARNING "load_macho_binary: setting up heap ...\n");
++
++  /* Set up an empty heap. This will be grown as more memory is allocated.  */
++  int brkret = ml_setBrk(top_data, top_data);
++
++  if (_verboseLog)
++    printk(KERN_WARNING "load_macho_binary: setting up misc ...\n");
++
++  /* setup misc stuff */
++  set_binfmt(&macho_format);
++  install_exec_creds(bprm);
++
++  /* Construct envp array. */
++  envp = envp_array = stack = (uint32_t*)stack - ((bprm->envc+1));
++
++  /* Construct argv array. */
++  argv = argv_array = stack = (uint32_t*)stack - ((bprm->argc+1));
++
++  if (_verboseLog)
++    printk(KERN_WARNING "load_macho_binary: setting up stack @ %p ...\n", (uint32_t*)stack);
++
++  argc = bprm->argc;
++  envc = bprm->envc;
++  p = bprm->p;
++
++  /* Set up argv pointers */
++  current->mm->arg_start = (unsigned long)p;
++  while(argc--) {
++    char c;
++
++    put_user(p,argv++);
++    do {
++      get_user(c,p++);
++    } while (c);
++  }
++  put_user(NULL,argv);
++
++  /* Set up envp pointers */
++  current->mm->arg_end = current->mm->env_start = (unsigned long) p;
++  while(envc--) {
++    char c;
++
++    put_user(p,envp++);
++    do {
++      get_user(c,p++);
++    } while (c);
++  }
++  put_user(NULL,envp);
++  current->mm->env_end = (unsigned long) p;
++
++  /*
++    The actual stuff passed to the linker goes here.
++  */
++  stack = (uint32_t*)stack - (4);
++
++  stack[0] = (uint32_t)first_text; /* mach_header */
++  stack[1] = bprm->argc; /* argc */
++  stack[2] = argv_array; /* argv */
++  stack[3] = (uint32_t)first_text_linker; /* linker's mach_header */
++  
++  if (_verboseLog)
++    printk(KERN_WARNING "load_macho_binary: setting up main thread ...\n"); 
++  
++  /*
++    Set up the main thread
++  */
++  if (BAD_ADDR(entry_point)) {
++    /* entry point is not executable */
++    
++    printk(KERN_WARNING "load_macho_binary: bad entry point \n");
++    force_sig(SIGSEGV, current);
++    retval = -EINVAL;
++    goto lc_ret;
++  }
++  
++  if (_verboseLog)
++    printk(KERN_WARNING "load_macho_binary: setting up registers ...\n");
++
++  /* 
++    See 'start_thread' in 'processor.h'
++    'start_thread' provides an ELF implementation of this function.
++    This is for the Darwin ABI implementation which is used by iPhoneOS binaries.
++  */
++  unsigned long initial_pc = (unsigned long)entry_point;  
++  
++  /* exit supervisor and enter user */
++  set_fs(USER_DS);
++  memset(regs->uregs, 0, sizeof(regs->uregs));
++  regs->ARM_cpsr = USR_MODE;  
++
++  /* If the entry point is THUMB, set the thumb bit */
++  if (initial_pc & 1)
++    regs->ARM_cpsr |= PSR_T_BIT;
++    
++  /* set up control regs */ 
++  regs->ARM_cpsr |= PSR_ENDSTATE; 
++  regs->ARM_pc = initial_pc & ~1;   /* pc */
++  regs->ARM_sp = stack;   /* sp */
++
++  /* This is actually ignored, but set it anyway */
++  regs->ARM_r2 = stack[2];  /* r2 (envp) */ 
++  regs->ARM_r1 = stack[1];  /* r1 (argv) */
++  regs->ARM_r0 = stack[0];  /* r0 (argc) */ 
++  
++  /* ABI */
++  regs->ARM_r7 = stack; /* FP */
++
++  /* this will work for mmu and nonmmu */
++  nommu_start_thread(regs);
++  
++  wire_weird_pages(); 
++  macho_setup_link_table();
++
++  ee = (linker_image_entry_t*)(((char*)LINK_TABLE_ADDR) + sizeof(linker_image_entry_t));
++
++  /* main image */
++  __put_user(0, &ee->load_addr);
++  __put_user(dylinker_load_addr, &ee->size);
++
++  ee += 1;
++
++  __put_user(dylinker_load_addr, &ee->load_addr);
++  __put_user((uint32_t)top_data - (uint32_t)dylinker_load_addr, &ee->size);
++
++  /*
++    Binary is now loaded. Return 0 to signify success.
++  */
++  retval = 0;
++
++  if (_verboseLog)
++    printk(KERN_WARNING "load_macho_binary: complete, heap starts at %d, brkret %d \n", top_data, brkret);
++
++  /*
++    Teardown
++  */
++  lc_ret:
++    kfree(addr);
++  out_ret:
++    return retval;
++}
++
++#define MAX_UNWIND 20
++
++static int fucking_core_dumper(struct coredump_params *cprm)
++{
++  linker_image_table_header_t* tb = (linker_image_table_header_t*)LINK_TABLE_ADDR;
++  linker_image_entry_t* ee;
++  uint32_t count;
++  int i;
++  const char* pc_lib;
++  uint32_t* fp; /* frame pointer */
++  uint32_t call_stack[MAX_UNWIND];
++  uint32_t spos = 0;
++
++  printk(KERN_WARNING "----- Core Dump -----\n");
++
++  printk(KERN_WARNING "PID: %d\n", current->pid);
++
++  printk(KERN_WARNING "Received Signal: %ld\n", cprm->signr);
++
++  printk(KERN_WARNING "Register Dump:\n"
++  "\tpc @ %p (%d), sp @ %p \n"
++  "\tr0 @ %p, r1 @ %p, r2 @ %p, r3 @ %p, r4 @ %p \n"
++  "\tr5 @ %p, r6 @ %p, r7 @ %p, r8 @ %p, r9 @ %p \n"
++  "\tr10 @ %p, lr @ %p, cpsr @ %p (thumb: %d)\n",
++  (void*)cprm->regs->ARM_pc,
++  (int)cprm->regs->ARM_pc,
++  (void*)cprm->regs->ARM_sp,
++  (void*)cprm->regs->ARM_r0,
++  (void*)cprm->regs->ARM_r1,
++  (void*)cprm->regs->ARM_r2,
++  (void*)cprm->regs->ARM_r3,
++  (void*)cprm->regs->ARM_r4,
++  (void*)cprm->regs->ARM_r5,
++  (void*)cprm->regs->ARM_r6,
++  (void*)cprm->regs->ARM_r7,
++  (void*)cprm->regs->ARM_r8,
++  (void*)cprm->regs->ARM_r9,
++  (void*)cprm->regs->ARM_r10,
++  (void*)cprm->regs->ARM_lr,
++  (void*)cprm->regs->ARM_cpsr,
++  (int)(cprm->regs->ARM_cpsr & PSR_T_BIT));
++  
++  printk(KERN_WARNING "----- Call Stack -----\n");
++
++  /* unwind darwin stack */
++  fp = (uint32_t*)cprm->regs->ARM_r7;
++  while (spos < MAX_UNWIND)
++  {
++    uint32_t* new_fp;
++
++    /* Get saved LR and R7 */
++
++    if (get_user(call_stack[spos], &fp[1])) {
++      printk("\t*** Unwinding failed 0 (memory error @ %p)\n", &fp[1]);
++      break;
++    }
++
++    if (get_user(new_fp, &fp[0])) {
++      printk("\t*** Unwinding failed 1 (memory error @ %p)\n", &fp[0]);
++      break;
++    }
++
++    printk("\t%d: lr:%p r7:%p\n", spos, call_stack[spos], new_fp);
++
++    fp = new_fp;
++    spos++;
++  }
++
++  /* walk link table */
++  if (get_user(count, &tb->entry_count)) {
++    printk(" *** Unable to access link table in user memory!\n");
++    return 0;
++  }
++
++  ee = (linker_image_entry_t*)(((char*)tb) + sizeof(linker_image_entry_t));
++
++  printk(KERN_WARNING "----- Loaded Images -----\n");
++
++  if ((sizeof(linker_image_entry_t) * count) > LINK_TABLE_SIZE)
++  {
++    printk(" *** Link table corrupt!\n");
++  }
++  else
++  {
++    for (i = 0; i < count; i++)
++    {
++      int ii;
++      size_t sl;
++      const char* lname;
++      size_t image_size;
++      uintptr_t load_addr;
++      uint32_t loc = (uint32_t)cprm->regs->ARM_pc;
++      uint32_t lrr = (uint32_t)cprm->regs->ARM_lr;
++
++      linker_image_entry_t* t = &(ee[i]);
++
++      if (i > 1)
++      {
++        sl = strlen_user(t->name);
++
++        if (sl == 0)
++        {
++          lname = "<unknown>";
++        }
++        else
++        {
++          lname = (const char*)kmalloc(sl, GFP_KERNEL);
++          __copy_from_user(lname, t->name, sl);
++        }
++      }
++      else if (i == 0)
++      {
++        lname = "<main_image>";
++      }
++      else /*(i == 1)*/
++      {
++        lname = "<linker>";
++      }
++
++      __get_user(image_size, &t->size);
++      __get_user(load_addr, &t->load_addr);
++
++      printk("\t%s {%d - %d}\n", lname, load_addr, (uint32_t)load_addr + (uint32_t)image_size);
++
++      if (loc > load_addr && ((uint32_t)load_addr + (uint32_t)image_size) > loc)
++      {
++        uint32_t rel_pc = loc - (uint32_t)load_addr;
++
++        /* pc is in range */
++        printk("\t\t > [PC] in image @ %p (%d), abs: %p\n", (void*)rel_pc, rel_pc, (void*)loc);
++      }
++
++      if (lrr > load_addr && ((uint32_t)load_addr + (uint32_t)image_size) > lrr)
++      {
++        uint32_t rel_lr = lrr - (uint32_t)load_addr;
++
++        /* lr is in range */
++        printk("\t\t > [LR] in image @ %p (%d), abs: %p\n", (void*)rel_lr, rel_lr, (void*)lrr);
++      }
++
++      for (ii = 0; ii < spos; ii++)
++      {
++        uint32_t stack_pos = call_stack[ii];
++        if (stack_pos > load_addr && ((uint32_t)load_addr + (uint32_t)image_size) > stack_pos)
++        {
++          uint32_t rel_sp = stack_pos - (uint32_t)load_addr;
++
++          /* lr is in range */
++          printk("\t\t > [SP: %d] in image @ %p (%d), abs: %p\n", ii, (void*)rel_sp, rel_sp, (void*)stack_pos);
++        }
++      }
++    }
++  }
++
++  return 0;
++}
++
++static int load_macho_library(struct file *file)
++{
++  panic("load_macho_library: not implemented.");
++}
++
++int __init init_macho_binfmt(void)
++{
++  printk(KERN_WARNING "init_macho_binfmt: MachO binary loader initialized! (load: %p) \n", load_macho_binary);
++  
++  return register_binfmt(&macho_format);
++}
+diff -Naur ./old//magenta/mach_port_types.h ./kern//magenta/mach_port_types.h
+--- ./old//magenta/mach_port_types.h 1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/mach_port_types.h  2012-07-01 00:52:03.000000000 +0100
+@@ -0,0 +1,152 @@
++#ifndef _H_MG_MACH_PORT_TYPES_
++#define _H_MG_MACH_PORT_TYPES_
++
++#include <linux/kernel.h>
++#include <linux/kfifo.h>
++#include <linux/list.h>
++#include <linux/idr.h>
++#include <linux/wait.h>
++
++#include <DarwinTypes.h>
++#include <MachO.h>
++
++#include "kern_return.h"
++
++#define FALSE 0
++#define TRUE 1
++
++#define MAX_PORT_COUNT 4096
++
++typedef unsigned int natural_t;
++typedef int integer_t;
++typedef int boolean_t;
++
++typedef natural_t mach_port_t;
++typedef natural_t mach_port_right_t;
++typedef int mach_port_delta_t;
++
++typedef mach_port_t mach_port_name_t;
++
++typedef int kern_return_t;
++
++typedef unsigned int mach_msg_type_name_t;
++
++#define MACH_MSG_TYPE_MOVE_RECEIVE  16  /* Must hold receive rights */
++#define MACH_MSG_TYPE_MOVE_SEND   17  /* Must hold send rights */
++#define MACH_MSG_TYPE_MOVE_SEND_ONCE  18  /* Must hold sendonce rights */
++#define MACH_MSG_TYPE_COPY_SEND   19  /* Must hold send rights */
++#define MACH_MSG_TYPE_MAKE_SEND   20  /* Must hold receive rights */
++#define MACH_MSG_TYPE_MAKE_SEND_ONCE  21  /* Must hold receive rights */
++#define MACH_MSG_TYPE_COPY_RECEIVE  22  /* Must hold receive rights */
++
++
++#define MACH_PORT_RIGHT_SEND            ((mach_port_right_t) 0)
++#define MACH_PORT_RIGHT_RECEIVE         ((mach_port_right_t) 1)
++#define MACH_PORT_RIGHT_SEND_ONCE       ((mach_port_right_t) 2)
++#define MACH_PORT_RIGHT_PORT_SET        ((mach_port_right_t) 3)
++#define MACH_PORT_RIGHT_DEAD_NAME       ((mach_port_right_t) 4)
++#define MACH_PORT_RIGHT_NUMBER          ((mach_port_right_t) 5)
++
++#define KE_PORT_TYPE_FREE 0
++#define KE_PORT_TYPE_TASK 1
++#define KE_PORT_TYPE_IPC 2
++
++typedef enum {
++    kMachPortRightSend = 0x1,
++    kMachPortRightReceive = 0x2,
++    kMachPortRightSendOnce = 0x4,
++    /* 0x8, 0x10, 0x20, 0x40,*/
++    kMachPortRightKernel = 0x80,
++} ke_right_type_t;
++
++typedef struct __ke_port_t
++{
++  uint16_t type; /* port type */
++  atomic_t refs;
++  struct mutex mtx;
++  boolean_t active;
++
++  /*
++   * Message handler. If not NULL, it gets called whenever
++   * a port receives a message.
++   */
++  kern_return_t (*msg_handler)(void* payload, void* trap_data);
++} ke_port_t;
++
++typedef struct 
++{
++  ke_port_t port;
++
++  struct task_struct *task; /* task which owns the port */
++  
++  struct completion wait_for_enqueued_data;
++  wait_queue_head_t wait_queue;
++  struct kfifo queue; /* queue */
++
++  boolean_t dead;
++  boolean_t allocated; 
++} ipc_port;
++
++typedef struct
++{
++  ke_port_t* port;
++  mach_port_t name; /* port name */
++  int urefs;
++
++  atomic_t r_receive;
++  atomic_t r_send;
++  atomic_t r_send_once;
++  atomic_t r_port_set;
++
++  atomic_t r_kernel;
++
++  struct list_head list;
++} ke_port_right_t;
++
++/*
++ * This structure represents a task port as well
++ * the task's IPC space and other stuff.
++ */
++typedef struct 
++{
++  ke_port_t port;
++
++  struct task_struct *task; /* task which owns the port */
++
++  struct idr name_pool;
++  struct list_head port_rights; /* list of port rights for this task */
++} task_port_t;
++
++
++task_port_t* ke_get_current_task(void); /* [RetainPort] */
++ke_port_t* ke_port_find_named(mach_port_t name); /* [RetainPort] */
++ke_port_right_t* ke_right_find_named(mach_port_t name); /* [RetainPort][RetainRight] */
++task_port_t* ke_get_task_port(struct task_struct* task); /* [RetainPort] */
++
++/*
++ * [RetainRight]
++ * fprt must be a valid port.
++ */
++ke_port_right_t* ke_get_right_in_space(task_port_t* space, ke_port_t* fprt, boolean_t add); 
++
++mach_port_t ke_get_new_port_name_in_space(task_port_t* space);
++ke_port_right_t* ke_new_port(uint16_t type);
++void ke_add_right_to_space(task_port_t* space, ke_port_right_t* rr);
++
++boolean_t ke_port_active(ke_port_t* port);
++void ke_port_up(ke_port_t* port);
++boolean_t ke_port_down(ke_port_t* port);
++void ke_teardown_task(task_port_t* task);
++typedef task_port_t* ipc_space_t;
++
++#define PortLock(x) mutex_lock(&(((ke_port_t*)x)->mtx))
++#define PortUnlock(x) mutex_unlock(&(((ke_port_t*)x)->mtx))
++
++#define PortRetain(x) ke_port_down((ke_port_t*)x)
++#define PortRelease(x) ke_port_up((ke_port_t*)x)
++
++#define PortActive(x) ke_port_active((ke_port_t*)x)
++#define RightIncrementRefCount(x, y) atomic_inc(&(x->y))
++#define RightDecrementRefCount(x, y) atomic_dec(&(x->y))
++
++#endif 
+diff -Naur ./old//magenta/mach_syscall.S ./kern//magenta/mach_syscall.S
+--- ./old//magenta/mach_syscall.S  1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/mach_syscall.S 2012-06-30 12:53:47.000000000 +0100
+@@ -0,0 +1,75 @@
++/*
++ * mach_syscall.S
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Darwin traps.
++ *
++ * Syscall number is initally stored in r12, but the sleh
++ * will move it to r7 (scno) as needed.
++ * 
++ * At the point of entry in ke_darwin_syscall, lr is set to
++ * the syscall fast return function.
++ */
++
++#define check_call(nr, fn) cmp r7, nr; beq fn;
++
++.text
++.align 2
++
++__mach_timer_cancel_trampoline:
++  push {r4}
++  mov r4, r2
++  mov r2, r1
++  mov r3, r4
++  pop {r4}
++
++  b _user_mk_timer_cancel
++
++__mach_timer_arm_trampoline:
++  push {r4}
++  mov r4, r2
++  mov r2, r1
++  mov r3, r4
++  pop {r4}
++
++  b _user_mk_timer_arm
++
++.globl ke_darwin_syscall
++ke_darwin_syscall:
++  /* Normal BSD syscalls */
++  check_call(#4, sys_write);
++
++  /* Native */
++  check_call(#0x158, _user_getdirentries64);
++
++  /* Now try mach masked syscalls */
++  and r7, r7, #0xff
++
++  /* VM */
++  check_call(#0xf5, _user_vm_allocate);
++
++  /* Task */
++  check_call(#0xe4, _user_task_self);
++  check_call(#0xd3, _user_task_for_pid);
++  check_call(#0xd2, _user_pid_for_task);
++
++  /* IPC */
++  check_call(#0xe1, _user_mach_msg_trap);
++  check_call(#0xf0, _user_mach_port_allocate);
++  check_call(#0xeb, _user_mach_port_insert_right);
++  check_call(#0xed, _user_mach_port_mod_refs);
++  check_call(#0xef, _user_mach_port_destroy);
++  check_call(#0xee, _user_mach_port_deallocate);
++
++  /* Timers */
++  check_call(#0xa5, _user_mk_timer_create);
++  check_call(#0xa4, _user_mk_timer_destroy);
++  check_call(#0xa3, __mach_timer_arm_trampoline);
++  check_call(#0xa2, __mach_timer_cancel_trampoline);
++
++  /* Stuff */
++  check_call(#0xff, _user_load_kext);
++
++  /* error out */
++  mov r0, r7
++  b ke_darwin_syscall_error
+diff -Naur ./old//magenta/mach_user_port.c ./kern//magenta/mach_user_port.c
+--- ./old//magenta/mach_user_port.c  1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/mach_user_port.c 2012-07-01 02:38:40.000000000 +0100
+@@ -0,0 +1,502 @@
++/*
++ * mach_user_port.c
++ * Copyright (c) 2012 Christina Brooks
++ *
++ * Anything to do with ports that a user thing may create.
++ * This involves:
++ *     > IPC ports
++ *     > Port sets
++ */
++
++#include <linux/module.h>
++
++#include <linux/time.h>
++#include <linux/kernel.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/errno.h>
++#include <linux/signal.h>
++#include <linux/string.h>
++#include <linux/fs.h>
++#include <linux/file.h>
++#include <linux/stat.h>
++#include <linux/fcntl.h>
++#include <linux/ptrace.h>
++#include <linux/user.h>
++#include <linux/binfmts.h>
++#include <linux/personality.h>
++#include <linux/init.h>
++#include <linux/coredump.h>
++#include <linux/slab.h>
++#include <linux/namei.h>
++#include <linux/security.h>
++#include <linux/syscalls.h>
++#include <linux/kfifo.h>
++
++#include <asm/system.h>
++#include <asm/uaccess.h>
++#include <asm/cacheflush.h>
++#include <linux/linkage.h>
++
++#include "ipc_types.h"
++#include "mach_kmsg.h"
++#include "ke_runtime.h"
++
++/*
++ * This copies data to a userland buffer if the message is received from
++ * the userspace or to a kernel memory chunk if it is received from the 
++ * kernel.
++ */
++boolean_t ipc_copy_data_local(void* to, void* from, unsigned long size)
++{
++  if (current) {
++    if (copy_to_user(to, from, size)) {
++      return false;
++    }
++    else {
++      return true;
++    }
++  }
++  else {
++    memcpy(to, from, size);
++    return true;
++  }
++}
++/*
++ * Support for the mk_timer syscall familiy.
++ * This provides a nice mach port based timer interface.
++ */
++mach_port_name_t _user_mk_timer_create(void) 
++{
++  return 0;
++}
++
++kern_return_t _user_mk_timer_destroy(mach_port_name_t name)
++{
++  return KERN_FAILURE;
++}
++
++kern_return_t _user_mk_timer_arm(mach_port_name_t name, uint64_t expire_time)
++{
++  return KERN_FAILURE;
++}
++
++kern_return_t _user_mk_timer_cancel(mach_port_name_t name, uint64_t *result_time)
++{
++  return KERN_FAILURE;
++}
++
++/*
++ * IPC message dispatcher. Should be callable from both kernel and
++ * user space. This can be used in the kernel with some limitations.
++ */
++kern_return_t mach_msg_main(mach_msg_header_t* msg,
++              mach_msg_option_t option,
++              mach_msg_size_t send_size,
++              mach_msg_size_t receive_limit,
++              mach_port_t receive_name,
++              mach_msg_timeout_t timeout,
++              mach_port_t notify)
++{
++  ipc_message* im;
++  ipc_message* rm;
++  ipc_port* remote;
++  ipc_port* local;
++  int retval = 0;
++  mach_port_t sswp; /* for swaps */
++
++  if (msg->msgh_bits & MACH_MSGH_BITS_COMPLEX)
++  {
++    /* Complex messages are not supported yet */
++    printk("mach_msg(): complex messages not yet supported\n");
++    return KERN_FAILURE;
++  }
++
++  /*
++    *** IPC message send. ***
++  */
++  if (option & MACH_SEND_MSG &&
++    msg->msgh_remote_port != 0) 
++  {
++    /*
++      Caller wants to send a mach message.
++    */
++
++    /* 1). Find out where it wants to send it to. */
++    remote = (ipc_port*)ke_port_find_named(msg->msgh_remote_port);
++    if (!remote) {
++      printk("mach_msg(): nonexistent remote port\n");
++      /* baaad port */
++      kfree(msg);
++      return KERN_FAILURE;
++    }
++
++
++    /* Check the port type */
++    if (remote->port.type == KE_PORT_TYPE_TASK)
++    {
++      /* Task port, do special handling */
++      PortRelease(remote);
++      kfree(msg);
++      return 0;
++    }
++    else if (remote->port.type == KE_PORT_TYPE_IPC)
++    {
++      /* Do nothing for now */
++    }
++    else 
++    {
++      /* Can't send to this port type */
++      PortRelease(remote);
++      printk("mach_msg(): invalid remote port type\n");
++      kfree(msg);
++      return KERN_FAILURE;
++    }
++
++    /* 2). Prepare the message. */
++    im = (ipc_message*)kmalloc(sizeof(ipc_message), GFP_KERNEL);
++    im->sender = current;
++    im->msg = msg;
++    im->head = *(msg); /* inline header */
++    im->received = 0;
++    init_completion(&(im->send_block)); /* block */
++
++    /* 3). Enqueue a pointer to the message. */
++    kfifo_in((&remote->queue), &im, sizeof(im));
++    printk("enqueued message at %p\n", im);
++
++    /* 
++      4). If the receiver is waiting for queue writes, let it know.
++        that a new message just came in.
++    */
++    wake_up((&remote->wait_queue));
++
++    PortRelease(remote);
++  }
++
++
++  /*
++    *** IPC message receive. ***
++  */
++  if (option & MACH_RCV_MSG &&
++    msg->msgh_local_port != 0)
++  {
++    /*
++      Caller wants to receive a mach message.
++    */
++    local = (ipc_port*)ke_port_find_named(msg->msgh_local_port);
++    
++    if (!local || local->port.type != KE_PORT_TYPE_IPC) {
++      printk("mach_msg(): invalid local port\n");
++      /* baaad port */
++
++      retval = KERN_INVALID_NAME;
++      goto out;
++    }
++
++    if (!local->port.active) {
++      /*
++       * Port is dead!
++       */
++      retval = KERN_FAILURE;
++      goto out;
++    }
++
++    if (kfifo_is_empty((&local->queue))) {
++      int qr = 0;
++
++      /*
++        1). If the queue is empty, wait until something writes to it.
++      */
++      ke_log("mach_msg_receive(%p): waiting for enqueued data ...\n", local);
++      qr = wait_event_interruptible((local->wait_queue), !kfifo_is_empty(&(local->queue)));
++      
++
++      if (qr == -ERESTARTSYS)
++      {
++        ke_log("mach_msg_receive(%p): interrupted, returning KERN_FAILURE!\n", local);
++
++        PortRelease(local);
++        retval = KERN_FAILURE;
++        goto out;
++      }
++      else 
++      {
++        ke_log("mach_msg_receive(%p): receieved message!\n", local);
++      }
++    }
++
++    /* 2). Dequeue the message pointer. */
++    kfifo_out(&(local->queue), &rm, sizeof(rm));
++    ke_log("dequeued message at %p\n", rm);
++
++    /* 
++      3). Check if this is an internal (on the same thread) message.
++        If it is, don't wait for completion at the end.
++    */
++    if (im == rm) {
++      //internal_message = 1;
++    }
++
++    /* 
++      4). Fixup the message.
++        This involves reversing the ports and adding a trailer.
++    */
++
++    sswp = rm->msg->msgh_local_port;
++    rm->msg->msgh_local_port = rm->msg->msgh_remote_port;
++    rm->msg->msgh_remote_port = sswp;
++    /* XXX: trailer */
++    /* grow by the trailer size */
++    //rm->msg->msgh_size += LARGEST_TRAILER_SIZE;
++
++    /* Not touching the local port anymore */
++    PortRelease(local);
++
++    /* 5). Copy the message into the our space. */
++    if (ipc_copy_data_local(msg, rm->msg, rm->msg->msgh_size))
++    {
++      printk("can't write message %p\n", rm);
++      retval = KERN_FAILURE;
++      goto out;
++    }
++
++    rm->received = 1;
++
++    /* 6). If the receiver is waiting for completion, let it know that we're done */
++    complete(&(rm->send_block));
++  }
++
++  retval = KERN_SUCCESS;
++out:
++  if (option & MACH_SEND_MSG &&
++    msg->msgh_local_port != 0)
++  {
++    if (!im->received) {
++      /* Block this thread until the sent message is dequeued */
++      ke_log("mach_msg_send(%p): CONTENDED: waiting for message dequeue\n", im);
++      wait_for_completion(&(im->send_block));
++      ke_log("mach_msg_send(%p): DECONTENDED: waiting for message dequeue\n", im);
++    }
++
++    /* Destroy the copied message buffer */
++    kfree(im->msg);
++
++    /* Destroy the ipc_message */
++    kfree(im);
++  }
++
++  return retval;
++}
++
++/*
++ * Trampoline for user mach_msg calls to IPC ports.
++ */
++kern_return_t ipc_message_handle(void* payload, void* trap_data__)
++{
++  mach_msg_trap_data_t* trap_data = (mach_msg_trap_data_t*)trap_data__;
++  mach_msg_header_t* msg = (mach_msg_header_t*)payload;
++  kern_return_t retval;
++
++  retval = mach_msg_main(msg, trap_data->option,
++    trap_data->send_size,
++    trap_data->receive_limit,
++    trap_data->receive_name,
++    trap_data->timeout,
++    trap_data->notify);
++
++  if (retval != KERN_SUCCESS) {
++    ke_log("ipc_message_handle(): error %d\n", retval);
++  }
++
++  return retval;
++}
++
++ke_port_right_t* ipc_port_allocate(task_port_t* space) {
++  ipc_port* prt = NULL;
++  ke_port_right_t* rr = NULL;
++
++  rr = ke_new_port(KE_PORT_TYPE_IPC);
++  if (!rr || !rr->port) {
++    return NULL;
++  }
++  prt = (ipc_port*)rr->port;
++
++  prt->port.msg_handler = ipc_message_handle;
++
++
++  /* create a message queue */
++  if(kfifo_alloc(&(prt->queue), PAGE_SIZE, GFP_KERNEL)) {
++    panic("allocate_ipc_port(): can't create a message queue");
++  }
++
++  /* 
++   * create a completion variable to hang on if the
++   * queue is empty 
++   */
++  init_waitqueue_head(&(prt->wait_queue));
++
++
++  /* Add a receive right for the task */
++  RightIncrementRefCount(rr, r_receive);
++  rr->name = ke_get_new_port_name_in_space(space);
++  ke_add_right_to_space(space, rr);
++
++  return rr;
++}
++
++kern_return_t mach_port_allocate(ipc_space_t task, mach_port_right_t right, mach_port_name_t *name)
++{
++  if (!task->port.active) {
++    return KERN_FAILURE;
++  }
++
++  if (right == MACH_PORT_RIGHT_RECEIVE || right == MACH_PORT_RIGHT_PORT_SET)
++  {
++    if (right == MACH_PORT_RIGHT_PORT_SET) {
++      printk("mach_port_allocate(): MACH_PORT_RIGHT_PORT_SET not supported, returning regular port instead\n");
++    }
++
++    /*
++     * Ports created with 'MACH_PORT_RIGHT_RECEIVE' are IPC ports.
++     */
++    ke_port_right_t* rr = ipc_port_allocate(task);
++
++    if (rr) {
++      *name = rr->name;
++    }
++    else {
++      return KERN_FAILURE;
++    }
++    
++    return KERN_SUCCESS;
++  }
++  else
++  {
++    /* Unknown right type */
++    return KERN_FAILURE;
++  }
++}
++
++kern_return_t _user_mach_port_insert_right(mach_port_t task, mach_port_name_t in_name, mach_port_name_t in_right, mach_msg_type_name_t right_type)
++{
++  ke_port_right_t* name;
++  ke_port_right_t* right;
++  task_port_t* target_space;
++  kern_return_t ret;
++
++  if (right != name) {
++    printk("_user_mach_port_insert_right(): XXX (right != name)\n");
++    return KERN_FAILURE;
++  }
++
++  target_space = (task_port_t*)ke_port_find_named(task);
++  if (!target_space) {
++    return KERN_INVALID_NAME;
++  }
++
++  name = ke_right_find_named(in_name);
++  if (!name) {
++    return KERN_INVALID_NAME;
++  }
++  if (!name->port) {
++    PortRelease(target_space);
++    RightDecrementRefCount(name, r_kernel);
++    return KERN_FAILURE;
++  }
++
++  /* Insert the right into the target IPC space */
++  right = ke_get_right_in_space(target_space, name->port, true);
++  if (!right) {
++    panic("_user_mach_port_insert_right(): ke_get_right_in_space failed");
++  }
++
++  /*
++   * Now depending on the type of the right transferred, change stuff
++   * [XXX]: Check if we hold the valid right needed to perform the operation.
++   */
++  switch (right_type)
++  {
++    case MACH_MSG_TYPE_MAKE_SEND:
++    {
++      RightIncrementRefCount(right, r_send);
++      ret = KERN_SUCCESS;
++      break;
++    }
++    case MACH_MSG_TYPE_COPY_SEND:
++    {
++      RightIncrementRefCount(right, r_send);
++      ret = KERN_SUCCESS;
++      break;
++    }
++    case MACH_MSG_TYPE_MOVE_SEND:
++    {
++      RightIncrementRefCount(right, r_send);
++      RightDecrementRefCount(name, r_send);
++      ret = KERN_SUCCESS;
++      break;
++    }
++    case MACH_MSG_TYPE_MOVE_RECEIVE:
++    {
++      RightIncrementRefCount(right, r_receive);
++      RightDecrementRefCount(name, r_receive);
++      ret = KERN_SUCCESS;
++      break;
++    }
++    case MACH_MSG_TYPE_COPY_RECEIVE:
++    {
++      printk("_user_mach_port_insert_right(): invalid argument\n");
++      ret = KERN_FAILURE;
++      break;
++    }
++    default:
++    {
++      printk("_user_mach_port_insert_right(): unknown argument %d\n", right_type);
++      ret = KERN_FAILURE;
++      break;
++    }
++  }
++
++  PortRelease(name->port);
++  PortRelease(target_space);
++  RightDecrementRefCount(name, r_kernel);
++  RightDecrementRefCount(right, r_kernel);
++  return ret;
++}
++
++kern_return_t _user_mach_port_mod_refs(mach_port_t task, mach_port_name_t name, mach_port_right_t right, mach_port_delta_t delta)
++{
++  return KERN_FAILURE;
++}
++
++kern_return_t _user_mach_port_destroy(mach_port_t task,mach_port_name_t name)
++{
++  return KERN_FAILURE;
++}
++
++kern_return_t _user_mach_port_deallocate(mach_port_t task,mach_port_name_t name)
++{
++  return KERN_FAILURE;
++}
++
++kern_return_t _user_mach_port_allocate(mach_port_t task, mach_port_right_t right, mach_port_name_t *name)
++{
++  kern_return_t ret;
++  mach_port_name_t nn;
++  ipc_space_t port;
++
++  port = (task_port_t*)ke_port_find_named(task);
++  if (!port) {
++    return KERN_INVALID_NAME;
++  }
++
++  ret = mach_port_allocate(port, right, &nn);
++
++  __put_user(nn, name);
++
++  PortRelease(port);
++
++  return ret;
++}
++
++//mach_port_allocate(ke_get_current_task(), MACH_PORT_RIGHT_RECEIVE, &mp);
+diff -Naur ./old//magenta/Makefile ./kern//magenta/Makefile
+--- ./old//magenta/Makefile  1970-01-01 01:00:00.000000000 +0100
++++ ./kern//magenta/Makefile 2012-06-23 17:50:17.000000000 +0100
+@@ -0,0 +1,13 @@
++# Makefile for Magenta's Kernel Components
++# Copyright (c) 2012 Christina Brooks
++
++obj-y += macho_loader.o
++obj-y += mach.o
++obj-y += ke_array.o
++obj-y += ke_runtime.o
++obj-y += darwin_getdirentries.o
++obj-y += kext.o
++obj-y += mach_kmsg.o
++obj-y += mach_syscall.o
++obj-y += ke_task.o
++obj-y += mach_user_port.o
+diff -Naur ./old//Makefile ./kern//Makefile
+--- ./old//Makefile  2011-01-05 00:50:19.000000000 +0000
++++ ./kern//Makefile 2012-05-19 00:13:20.000000000 +0100
+@@ -680,7 +680,7 @@
+ 
+ 
+ ifeq ($(KBUILD_EXTMOD),)
+-core-y    += kernel/ mm/ fs/ ipc/ security/ crypto/ block/
++core-y    += kernel/ mm/ fs/ ipc/ security/ crypto/ block/ magenta/
+ 
+ vmlinux-dirs  := $(patsubst %/,%,$(filter %/, $(init-y) $(init-m) \
+          $(core-y) $(core-m) $(drivers-y) $(drivers-m) \
+diff -Naur ./old//mm/mmap.c ./kern//mm/mmap.c
+--- ./old//mm/mmap.c 2011-01-05 00:50:19.000000000 +0000
++++ ./kern//mm/mmap.c  2012-06-17 06:12:38.000000000 +0100
+@@ -1214,6 +1214,186 @@
+   return (vm_flags & (VM_NORESERVE | VM_SHARED | VM_WRITE)) == VM_WRITE;
+ }
+ 
++int make_pages_present_ex(unsigned long addr, unsigned long end, struct task_struct* tsk)
++{
++  int ret, len, write;
++  struct vm_area_struct * vma;
++
++  vma = find_vma(tsk->mm, addr);
++  if (!vma)
++    return -ENOMEM;
++
++  write = (vma->vm_flags & (VM_WRITE | VM_SHARED)) == VM_WRITE;
++  BUG_ON(addr >= end);
++  BUG_ON(end > vma->vm_end);
++  len = DIV_ROUND_UP(end, PAGE_SIZE) - addr/PAGE_SIZE;
++  ret = get_user_pages(tsk, tsk->mm, addr,
++            len, write, 0, NULL, NULL);
++  if (ret < 0)
++    return ret;
++
++  return ret == len ? 0 : -EFAULT;
++}
++
++unsigned long mmap_region_ex(struct file *file, unsigned long addr,
++        unsigned long len, unsigned long flags,
++        unsigned int vm_flags, unsigned long pgoff,
++        struct task_struct* tsk)
++{
++  struct mm_struct *mm = tsk->mm;
++  struct vm_area_struct *vma, *prev;
++  int correct_wcount = 0;
++  int error;
++  struct rb_node **rb_link, *rb_parent;
++  unsigned long charged = 0;
++  struct inode *inode =  file ? file->f_path.dentry->d_inode : NULL;
++
++  /* Clear old maps */
++  error = -ENOMEM;
++munmap_back:
++  vma = find_vma_prepare(mm, addr, &prev, &rb_link, &rb_parent);
++  if (vma && vma->vm_start < addr + len) {
++    if (do_munmap(mm, addr, len))
++      return -ENOMEM;
++    goto munmap_back;
++  }
++
++  /* Check against address space limit. */
++  if (!may_expand_vm(mm, len >> PAGE_SHIFT))
++    return -ENOMEM;
++
++  /*
++   * Set 'VM_NORESERVE' if we should not account for the
++   * memory use of this mapping.
++   */
++  if ((flags & MAP_NORESERVE)) {
++    /* We honor MAP_NORESERVE if allowed to overcommit */
++    if (sysctl_overcommit_memory != OVERCOMMIT_NEVER)
++      vm_flags |= VM_NORESERVE;
++
++    /* hugetlb applies strict overcommit unless MAP_NORESERVE */
++    if (file && is_file_hugepages(file))
++      vm_flags |= VM_NORESERVE;
++  }
++
++  /*
++   * Private writable mapping: check memory availability
++   */
++  if (accountable_mapping(file, vm_flags)) {
++    charged = len >> PAGE_SHIFT;
++    if (security_vm_enough_memory(charged))
++      return -ENOMEM;
++    vm_flags |= VM_ACCOUNT;
++  }
++
++  /*
++   * Can we just expand an old mapping?
++   */
++  vma = vma_merge(mm, prev, addr, addr + len, vm_flags, NULL, file, pgoff, NULL);
++  if (vma)
++    goto out;
++
++  /*
++   * Determine the object being mapped and call the appropriate
++   * specific mapper. the address has already been validated, but
++   * not unmapped, but the maps are removed from the list.
++   */
++  vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
++  if (!vma) {
++    error = -ENOMEM;
++    goto unacct_error;
++  }
++
++  vma->vm_mm = mm;
++  vma->vm_start = addr;
++  vma->vm_end = addr + len;
++  vma->vm_flags = vm_flags;
++  vma->vm_page_prot = vm_get_page_prot(vm_flags);
++  vma->vm_pgoff = pgoff;
++  INIT_LIST_HEAD(&vma->anon_vma_chain);
++
++  if (file) {
++    error = -EINVAL;
++    if (vm_flags & (VM_GROWSDOWN|VM_GROWSUP))
++      goto free_vma;
++    if (vm_flags & VM_DENYWRITE) {
++      error = deny_write_access(file);
++      if (error)
++        goto free_vma;
++      correct_wcount = 1;
++    }
++    vma->vm_file = file;
++    get_file(file);
++    error = file->f_op->mmap(file, vma);
++    if (error)
++      goto unmap_and_free_vma;
++    if (vm_flags & VM_EXECUTABLE)
++      added_exe_file_vma(mm);
++
++    /* Can addr have changed??
++     *
++     * Answer: Yes, several device drivers can do it in their
++     *         f_op->mmap method. -DaveM
++     */
++    addr = vma->vm_start;
++    pgoff = vma->vm_pgoff;
++    vm_flags = vma->vm_flags;
++  } else if (vm_flags & VM_SHARED) {
++    error = shmem_zero_setup(vma);
++    if (error)
++      goto free_vma;
++  }
++
++  if (vma_wants_writenotify(vma)) {
++    pgprot_t pprot = vma->vm_page_prot;
++
++    /* Can vma->vm_page_prot have changed??
++     *
++     * Answer: Yes, drivers may have changed it in their
++     *         f_op->mmap method.
++     *
++     * Ensures that vmas marked as uncached stay that way.
++     */
++    vma->vm_page_prot = vm_get_page_prot(vm_flags & ~VM_SHARED);
++    if (pgprot_val(pprot) == pgprot_val(pgprot_noncached(pprot)))
++      vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
++  }
++
++  vma_link(mm, vma, prev, rb_link, rb_parent);
++  file = vma->vm_file;
++
++  /* Once vma denies write, undo our temporary denial count */
++  if (correct_wcount)
++    atomic_inc(&inode->i_writecount);
++out:
++  perf_event_mmap(vma);
++
++  mm->total_vm += len >> PAGE_SHIFT;
++  vm_stat_account(mm, vm_flags, file, len >> PAGE_SHIFT);
++  if (vm_flags & VM_LOCKED) {
++    if (!mlock_vma_pages_range(vma, addr, addr + len))
++      mm->locked_vm += (len >> PAGE_SHIFT);
++  } else if ((flags & MAP_POPULATE) && !(flags & MAP_NONBLOCK))
++    make_pages_present_ex(addr, addr + len, tsk);
++  return addr;
++
++unmap_and_free_vma:
++  if (correct_wcount)
++    atomic_inc(&inode->i_writecount);
++  vma->vm_file = NULL;
++  fput(file);
++
++  /* Undo any partial mapping done by a device driver. */
++  unmap_region(mm, vma, prev, vma->vm_start, vma->vm_end);
++  charged = 0;
++free_vma:
++  kmem_cache_free(vm_area_cachep, vma);
++unacct_error:
++  if (charged)
++    vm_unacct_memory(charged);
++  return error;
++}
++
+ unsigned long mmap_region(struct file *file, unsigned long addr,
+         unsigned long len, unsigned long flags,
+         unsigned int vm_flags, unsigned long pgoff)
+
diff -Naur ./old//magenta/Makefile ./kern//magenta/Makefile
--- ./old//magenta/Makefile 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/Makefile  2012-08-06 10:01:37.000000000 -0400
@@ -0,0 +1,20 @@
+# Makefile for Magenta's Kernel Components
+# Copyright (c) 2012 Christina Brooks
+
+obj-y  += macho_loader.o
+obj-y  += mach_core.o
+obj-y  += ke_array.o
+obj-y  += ke_runtime.o
+obj-y  += darwin_getdirentries.o
+obj-y  += kext.o
+obj-y  += mach_kmsg.o
+obj-y  += Sleh_swi_darwin.o
+obj-y  += mach_task.o
+obj-y  += mach_user_port.o
+obj-y  += bsd_syscalls.o
+obj-y  += mach_host.o
+obj-y  += mach_semaphore.o
+obj-y  += libkern.o
+obj-y  += OSAtomic.o
+obj-y  += VM.o
+obj-y  += Log.o
diff -Naur ./old//magenta/OSAtomic.S ./kern//magenta/OSAtomic.S
--- ./old//magenta/OSAtomic.S 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/OSAtomic.S  2012-07-31 12:49:31.000000000 -0400
@@ -0,0 +1,200 @@
+/*
+ * Copyright (c) 2004 Apple Computer, Inc. All rights reserved.
+ *
+ * @APPLE_LICENSE_HEADER_START@
+ * 
+ * This file contains Original Code and/or Modifications of Original Code
+ * as defined in and that are subject to the Apple Public Source License
+ * Version 2.0 (the 'License'). You may not use this file except in
+ * compliance with the License. Please obtain a copy of the License at
+ * http://www.opensource.apple.com/apsl/ and read it before using this
+ * file.
+ * 
+ * The Original Code and all software distributed under the License are
+ * distributed on an 'AS IS' basis, WITHOUT WARRANTY OF ANY KIND, EITHER
+ * EXPRESS OR IMPLIED, AND APPLE HEREBY DISCLAIMS ALL SUCH WARRANTIES,
+ * INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE, QUIET ENJOYMENT OR NON-INFRINGEMENT.
+ * Please see the License for the specific language governing rights and
+ * limitations under the License.
+ * 
+ * @APPLE_LICENSE_HEADER_END@
+ */
+
+#define ENTRY_POINT(name)      \
+ .align 2            ;\
+ .globl  name          ;\
+ .text             ;\
+name:
+
+
+.text
+
+/*
+ * Use LDREX/STREX to perform atomic operations.
+ * Memory barriers are not needed on a UP system
+ */
+
+#if 1
+
+/* Implement a generic atomic arithmetic operation:
+ * operand is in R0, pointer is in R1.  Return new
+ * value into R0
+ */
+#define ATOMIC_ARITHMETIC(op) \
+1: ldrex r2, [r1]  /* load existing value and tag memory */      ;\
+ op  r3, r2, r0  /* compute new value */           ;\
+ strex ip, r3, [r1]  /* store new value if memory is still tagged */     ;\
+ cmp ip, #0    /* check if the store succeeded */        ;\
+ bne 1b    /* if not, try again */           ;\
+ mov r0, r3    /* return new value */
+
+#define ATOMIC_ARITHMETIC_ORIG(op) \
+1: ldrex r2, [r1]  /* load existing value and tag memory */      ;\
+ op  r3, r2, r0  /* compute new value */           ;\
+ strex ip, r3, [r1]  /* store new value if memory is still tagged */     ;\
+ cmp ip, #0    /* check if the store succeeded */        ;\
+ bne 1b    /* if not, try again */           ;\
+ mov r0, r2    /* return orig value */
+
+ENTRY_POINT(OSAtomicAdd32Barrier)
+ENTRY_POINT(OSAtomicAdd32)
+ ATOMIC_ARITHMETIC(add)
+ bx  lr
+
+ENTRY_POINT(OSAtomicOr32Barrier)
+ENTRY_POINT(OSAtomicOr32)
+ ATOMIC_ARITHMETIC(orr)
+ bx  lr
+
+ENTRY_POINT(OSAtomicOr32OrigBarrier)
+ENTRY_POINT(OSAtomicOr32Orig)
+ ATOMIC_ARITHMETIC_ORIG(orr)
+ bx  lr
+
+ENTRY_POINT(OSAtomicAnd32Barrier)
+ENTRY_POINT(OSAtomicAnd32)
+ ATOMIC_ARITHMETIC(and)
+ bx  lr
+
+ENTRY_POINT(OSAtomicAnd32OrigBarrier)
+ENTRY_POINT(OSAtomicAnd32Orig)
+ ATOMIC_ARITHMETIC_ORIG(and)
+ bx  lr
+
+ENTRY_POINT(OSAtomicXor32Barrier)
+ENTRY_POINT(OSAtomicXor32)
+ ATOMIC_ARITHMETIC(eor)
+ bx  lr
+
+ENTRY_POINT(OSAtomicXor32OrigBarrier)
+ENTRY_POINT(OSAtomicXor32Orig)
+ ATOMIC_ARITHMETIC_ORIG(eor)
+ bx  lr
+
+ENTRY_POINT(OSAtomicCompareAndSwap32Barrier)
+ENTRY_POINT(OSAtomicCompareAndSwap32)
+ENTRY_POINT(OSAtomicCompareAndSwapIntBarrier)
+ENTRY_POINT(OSAtomicCompareAndSwapInt)
+ENTRY_POINT(OSAtomicCompareAndSwapLongBarrier)
+ENTRY_POINT(OSAtomicCompareAndSwapLong)
+ENTRY_POINT(OSAtomicCompareAndSwapPtrBarrier)
+ENTRY_POINT(OSAtomicCompareAndSwapPtr)
+1: ldrex r3, [r2]  // load existing value and tag memory
+ teq r3, r0    // is it the same as oldValue?
+ movne r0, #0    // if not, return 0 immediately
+ bxne  lr      
+ strex r3, r1, [r2]  // otherwise, try to store new value
+ cmp r3, #0    // check if the store succeeded
+ bne 1b    // if not, try again
+ mov r0, #1    // return true
+ bx  lr
+
+
+/* Implement a generic test-and-bit-op operation:
+ * bit to set is in R0, base address is in R1.  Return
+ * previous value (0 or 1) of the bit in R0.
+ */
+#define ATOMIC_BITOP(op)    \
+ /* Adjust pointer to point at the correct word            ;\
+  * R1 = R1 + 4 * (R0 / 32)                ;\
+  */                     ;\
+        mov     r3, r0, lsr #5                 ;\
+        add     r1, r1, r3, asl #2               ;\
+ /* Generate a bit mask for the bit we want to test          ;\
+  * R0 = (0x80 >> (R0 & 7)) << (R0 & ~7 & 31)            ;\
+  */                     ;\
+        and     r2, r0, #7                 ;\
+        mov     r3, #0x80                  ;\
+        mov     r3, r3, asr r2                 ;\
+        and     r0, r0, #0x18                  ;\
+        mov     r0, r3, asl r0                 ;\
+1:                       ;\
+ ldrex r2, [r1]  /* load existing value and tag memory */      ;\
+ op  r3, r2, r0  /* compute new value */           ;\
+ strex ip, r3, [r1]  /* attempt to store new value */        ;\
+ cmp ip, #0    /* check if the store succeeded */        ;\
+ bne 1b    /* if so, try again */            ;\
+ ands  r0, r2, r0  /* mask off the bit from the old value */     ;\
+ movne r0, #1    /* if non-zero, return exactly 1 */
+ 
+ENTRY_POINT(OSAtomicTestAndSetBarrier)
+ENTRY_POINT(OSAtomicTestAndSet)
+ ATOMIC_BITOP(orr)
+ bx  lr
+
+ENTRY_POINT(OSAtomicTestAndClearBarrier)
+ENTRY_POINT(OSAtomicTestAndClear)
+ ATOMIC_BITOP(bic)
+ bx  lr
+
+ENTRY_POINT(OSMemoryBarrier)
+ bx  lr
+
+
+#if defined(_ARM_ARCH_6K)
+/* If we can use LDREXD/STREXD, then we can implement 64-bit atomic operations */
+
+ENTRY_POINT(OSAtomicAdd64Barrier)
+ENTRY_POINT(OSAtomicAdd64)
+ // R0,R1 contain the amount to add
+ // R2 contains the pointer
+ stmfd sp!, {r4, r5, r8, r9, lr}
+1: 
+ ldrexd  r4, r5, [r2]  // load existing value to R4/R5 and tag memory
+ adds  r8, r4, r0  // add lower half of new value into R6 and set carry bit
+ adc r9, r5, r1  // add upper half of new value into R8 with carry
+ strexd  r3, r8, r9, [r2]  // store new value if memory is still tagged
+ cmp r3, #0    // check if store succeeded
+ bne 1b    // if so, try again
+ mov r0, r8    // return new value
+ mov r1, r9
+ ldmfd sp!, {r4, r5, r8, r9, pc}
+ 
+ENTRY_POINT(OSAtomicCompareAndSwap64Barrier)
+ENTRY_POINT(OSAtomicCompareAndSwap64)
+ // R0,R1 contains the old value
+ // R2,R3 contains the new value
+ // the pointer is pushed onto the stack
+ ldr ip, [sp, #0]  // load pointer into IP
+ stmfd sp!, {r4, r5, lr}
+1: 
+ ldrexd  r4, [ip]  // load existing value into R4/R5 and tag memory
+ teq r0, r4    // check low word
+ teqeq r1, r5    // if low words match, check high word
+ movne r0, #0    // if either match fails, return 0
+ bne 2f
+ strexd  r4, r2, [ip]  // otherwise, try to store new values
+ cmp r3, #0    // check if store succeeded
+ bne 1b    // if so, try again
+ mov r0, #1    // return true
+2: 
+ ldmfd sp!, {r4, r5, pc}
+     
+#endif /* defined(_ARM_ARCH_6K) */
+
+#endif /* defined(_ARM_ARCH_6) */
+
+/*
+ * For OSSpinLock, see 'OSSpinLock.c'
+ */
diff -Naur ./old//magenta/Sleh_swi_darwin.S ./kern//magenta/Sleh_swi_darwin.S
--- ./old//magenta/Sleh_swi_darwin.S  1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/Sleh_swi_darwin.S 2012-08-06 09:43:48.000000000 -0400
@@ -0,0 +1,121 @@
+/*
+ * Sleh_swi_darwin.S
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Darwin traps.
+ *
+ * Syscall number is initally stored in r12, but the sleh
+ * will move it to r7 (scno) as needed.
+ * 
+ * At the point of entry in ke_darwin_syscall, lr is set to
+ * the syscall fast return function.
+ *
+ * XXX: use a table instead of beqs
+ * XXX: need to write my own fleh
+ */
+
+#define check_call(nr, fn) cmp r7, nr; beq fn;
+
+.text
+.align 2
+
+/* Not really needed anymore */
+__mach_timer_cancel_trampoline:
+ b _user_mk_timer_cancel
+__mach_timer_arm_trampoline:
+ b _user_mk_timer_arm
+
+/* Handler */
+.globl Sleh_swi_darwin
+Sleh_swi_darwin:
+ /* Normal BSD syscalls */
+ check_call(#4, sys_write);
+
+ /* Native */
+ check_call(#0x158, _user_getdirentries64);
+ check_call(#199, _user_bsd_lseek);
+
+
+
+ /**********************************************/
+
+ /* ... self */
+ check_call(#-29, _user_host_self);
+ check_call(#-27, _user_thread_self);
+
+
+ /**********************************************/
+
+
+ /* these are not meant to be traps, however, I dont
+    see why not, so I will make them traps and 
+    give them the reserved mach trap numbers */
+
+ /* Thread */
+ check_call(#-109, _user_thread_policy);
+ check_call(#-110, _user_bsdthread_register);
+ check_call(#-111, _user_thread_selfid);
+ check_call(#-112, _user_bsdthread_create);
+
+ check_call(#-115, _user__disable_threadsignal)
+ check_call(#-116, _user_syscall_thread_switch)
+ check_call(#-117, _user_bsdthread_terminate)
+ check_call(#-118, _user__pthread_canceled)
+ check_call(#-119, _user__pthread_kill)
+ check_call(#-120, _user__pthread_markcancel)
+ check_call(#-121, _user__workq_open)
+
+ check_call(#-122, _user_thread_switch)
+ check_call(#-123, _user_task_threads)
+ check_call(#-124, _user_thread_get_state)
+ check_call(#-125, _user_thread_suspend)
+ check_call(#-126, _user_thread_resume)
+
+ /* Host */
+ check_call(#-108, _user_host_info);
+
+ /* Semaphore */
+ check_call(#-33, _user_semaphore_signal)
+ check_call(#-34, _user_semaphore_signal_all)
+ check_call(#-35, _user_semaphore_signal_thread)
+ check_call(#-36, _user_semaphore_wait)
+ check_call(#-37, _user_semaphore_wait_signal)
+ check_call(#-38, _user_semaphore_timedwait)
+ check_call(#-39, _user_semaphore_timedwait_signal)
+
+ /* aaa */
+ check_call(#-113, _user_semaphore_create)
+
+ /*********************************************/
+ and r7, r7, #0xff
+
+ /* VM */
+ check_call(#0xf5, _user_vm_allocate);
+
+ /* Task */
+ check_call(#0xe4, _user_task_self);
+ check_call(#0xd3, _user_task_for_pid);
+ check_call(#0xd2, _user_pid_for_task);
+
+ /* IPC */
+ check_call(#0xe1, _user_mach_msg_trap);
+ check_call(#0xf0, _user_mach_port_allocate);
+ check_call(#0xeb, _user_mach_port_insert_right);
+ check_call(#0xed, _user_mach_port_mod_refs);
+ check_call(#0xef, _user_mach_port_destroy);
+ check_call(#0xee, _user_mach_port_deallocate);
+ check_call(#0xea, _user_mach_port_insert_member);
+ check_call(#0xe0, _user_mach_msg_overwrite_trap);
+
+ /* Timers */
+ check_call(#0xa5, _user_mk_timer_create);
+ check_call(#0xa4, _user_mk_timer_destroy);
+ check_call(#0xa3, __mach_timer_arm_trampoline);
+ check_call(#0xa2, __mach_timer_cancel_trampoline);
+
+ /* Stuff */
+ check_call(#0xff, _user_load_kext);
+
+ /* error out */
+ mov r0, r7
+ b ke_darwin_syscall_error
diff -Naur ./old//magenta/Standard.h ./kern//magenta/Standard.h
--- ./old//magenta/Standard.h 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/Standard.h  2012-08-04 13:44:41.000000000 -0400
@@ -0,0 +1,32 @@
+#include <linux/module.h>
+
+#include <linux/time.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/stat.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/binfmts.h>
+#include <linux/personality.h>
+#include <linux/init.h>
+#include <linux/coredump.h>
+#include <linux/slab.h>
+#include <linux/namei.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/kfifo.h>
+#include <linux/sched.h>
+#include <linux/freezer.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+#include <linux/linkage.h>
+#include <asm/thread_notify.h>
diff -Naur ./old//magenta/VM.c ./kern//magenta/VM.c
--- ./old//magenta/VM.c 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/VM.c  2012-08-04 14:33:19.000000000 -0400
@@ -0,0 +1,283 @@
+/*
+ * VM
+ * Copyright (c) 2012 Christina Brooks
+ *
+ * Back-end support for VM operations on specific tasks.
+ * I don't understand why these are not in Linux already.
+ */
+
+#include "VM.h"
+
+ /* Extended version that can map stuff in different tasks */
+extern
+unsigned long mmap_region_ex(struct file *file, unsigned long addr,
+       unsigned long len, unsigned long flags,
+       unsigned int vm_flags, unsigned long pgoff,
+       struct task_struct* tsk);
+
+/* BRING THE PAIN */
+unsigned long
+ARM_get_unmapped_area(struct mm_struct *mm, struct file *filp, unsigned long addr,
+   unsigned long len, unsigned long pgoff, unsigned long flags);
+
+unsigned long VM_get_unmapped(struct mm_struct* mm,
+ unsigned long addr,
+ unsigned long len,
+ unsigned long flags,
+ unsigned long pgoff)
+{
+ unsigned long error = arch_mmap_check(addr, len, flags);
+
+ /* arch specific checks */
+ if (error)
+   return error;
+
+ /* overflow checks */
+ if (len > TASK_SIZE)
+   return -ENOMEM;
+
+ /* PAAAAAAAAIN */
+ addr = ARM_get_unmapped_area(mm, NULL, addr, len, pgoff, flags);
+
+ if (IS_ERR_VALUE(addr))
+   return addr;
+
+ if (addr > TASK_SIZE - len)
+   return -ENOMEM;
+ if (addr & ~PAGE_MASK)
+   return -EINVAL;
+
+ /* arm only */
+ return addr;
+}
+
+kern_return_t VM_allocate(struct task_struct* ts,
+ uintptr_t* addr,
+ size_t size,
+ boolean_t anywhere)
+{
+ struct mm_struct* mm = ts->mm;
+ unsigned long flags = 0;
+ unsigned long pgoff = 0;
+ unsigned int vm_flags = 0;
+ unsigned int prot = PROT_READ | PROT_WRITE | PROT_EXEC;
+ unsigned long ret = 0;
+ uintptr_t iaddr = *addr;
+
+ if (!anywhere) {
+   flags |= MAP_FIXED;
+ }
+ else {
+   iaddr = 0;
+ }
+
+ pgoff = iaddr >> PAGE_SHIFT;
+
+ /* Careful about overflows.. */
+ size = PAGE_ALIGN(size);
+ if (!size)
+ {
+   ke_warn("VM_allocate(): alignment error!");
+   return KERN_FAILURE;
+ }
+
+ /* offset overflow? */
+ if ((pgoff + (size >> PAGE_SHIFT)) < pgoff)
+ {
+   ke_warn("VM_allocate(): offset overflow!");
+   return KERN_FAILURE;
+ }
+
+ /* Too many mappings? */
+ if (mm->map_count > sysctl_max_map_count)
+ {
+   ke_warn("VM_allocate(): too many mappings");
+   return KERN_FAILURE;
+ }
+
+ down_write(&mm->mmap_sem);
+
+ vm_flags = calc_vm_prot_bits(prot) | calc_vm_flag_bits(flags) |
+     mm->def_flags | VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC;
+
+ ret = 
+ VM_get_unmapped(mm,
+   (unsigned long)iaddr,
+   (unsigned long)size,
+   flags,
+   pgoff);
+
+ if (IS_ERR_VALUE(ret)) {
+   ke_warn("mmap_region_ex(): ke_mm_get_unmapped returned %ld \n", ret);
+   up_write(&mm->mmap_sem);
+   return KERN_FAILURE;
+ }
+ else {
+   iaddr = (uintptr_t)ret;
+ }
+
+ ret = 
+ mmap_region_ex(NULL, iaddr, (unsigned long)size, flags, vm_flags, pgoff, ts);
+
+ up_write(&mm->mmap_sem);
+
+ *addr = iaddr;
+
+ return KERN_SUCCESS;
+}
+
+boolean_t VM_kernel_copyin(void* to, void* from, unsigned long size, boolean_t user)
+{
+ if (user) {
+   if (copy_from_user(to, from, size)) {
+     return false;
+   }
+   else {
+     return true;
+   }
+ }
+ else {
+   memcpy(to, from, size);
+   return true;
+ }
+}
+
+boolean_t VM_kernel_copyout(void* to, void* from, unsigned long size, boolean_t user)
+{
+ if (user) {
+   if (copy_to_user(to, from, size)) {
+     return false;
+   }
+   else {
+     return true;
+   }
+ }
+ else {
+   memcpy(to, from, size);
+   return true;
+ }
+}
+
+kern_return_t VM_write(struct task_struct* task,
+ char* in_buffer,
+ size_t count,
+ unsigned long *ppos,
+ boolean_t user)
+{
+ int copied = KERN_FAILURE;
+ char *page;
+ unsigned long dst = *ppos;
+
+ copied = -ENOMEM;
+ page = (char *)__get_free_page(GFP_TEMPORARY);
+ if (!page)
+ {
+   ke_warn("VM_write: page alloc failed!\n");
+   goto out;
+ }
+
+ copied = KERN_SUCCESS;
+ while (count > 0) {
+   int this_len, retval;
+
+   this_len = (count > PAGE_SIZE) ? PAGE_SIZE : count;
+   if (VM_kernel_copyin(page, in_buffer, this_len, user)) {
+     ke_warn("VM_write: copyin failed!\n");
+     copied = KERN_PROTECTION_FAILURE;
+     break;
+   }
+
+   retval = access_process_vm(task, dst, page, this_len, 1);
+   if (!retval) {
+     ke_warn("VM_write: access failed!\n");
+     copied = KERN_PROTECTION_FAILURE;
+     break;
+   }
+
+   in_buffer += retval;
+   dst += retval;
+   count -= retval;      
+ }
+ *ppos = dst;
+
+ free_page((unsigned long) page);
+out:
+ return copied;
+}
+
+kern_return_t VM_read(struct task_struct* task,
+ char* out_buffer,
+ size_t count,
+ unsigned long *ppos,
+ boolean_t user)
+{
+ char *page;
+ unsigned long src = *ppos;
+ int ret = KERN_FAILURE;
+ struct mm_struct *mm;
+
+ BUG_ON(!task);
+
+ ret = KERN_FAILURE;
+ page = (char *)__get_free_page(GFP_TEMPORARY);
+ if (!page) {
+   ke_warn("VM_read: can't get page!\n");
+   goto out;
+ }
+
+ ret = 0;
+ 
+ mm = get_task_mm(task);
+ if (!mm)
+ {
+   ke_warn("VM_read: can't get VM!\n");
+   goto out_free;
+ }
+
+ ret = KERN_SUCCESS;
+ 
+ while (count > 0) {
+   int this_len, retval;
+
+   this_len = (count > PAGE_SIZE) ? PAGE_SIZE : count;
+   retval = access_process_vm(task, src, page, this_len, 0);
+   if (!retval)
+   {
+     ke_warn("VM_read: can't access vm!\n");
+     ret = KERN_INVALID_ADDRESS;
+     break;
+   }
+
+   if (!VM_kernel_copyout((void*)out_buffer, (void*)page, retval, user))
+   {
+     ke_warn("VM_read: can't copy buffer!\n");
+     ret = KERN_PROTECTION_FAILURE;
+     break;
+   }
+ 
+   src += retval;
+   out_buffer += retval;
+   count -= retval;
+ }
+ *ppos = src;
+
+ mmput(mm);
+out_free:
+ free_page((unsigned long) page);
+out:
+ return ret;
+}
+
+kern_return_t VM_deallocate(struct task_struct* ts,
+ uintptr_t addr,
+ size_t size)
+{
+ int ret = do_munmap(ts->mm, addr, size);
+ if (ret == 0) {
+   return KERN_SUCCESS;
+ }
+ else {
+   ke_warn("VM_deallocate: failed with %d\n", ret);
+   return KERN_FAILURE;
+ }
+}
diff -Naur ./old//magenta/VM.h ./kern//magenta/VM.h
--- ./old//magenta/VM.h 1969-12-31 19:00:00.000000000 -0500
+++ ./kern//magenta/VM.h  2012-08-04 14:18:02.000000000 -0400
@@ -0,0 +1,32 @@
+#ifndef _H_MG_VM_
+#define _H_MG_VM_
+
+#include "Standard.h"
+
+#include "ke_runtime.h"
+
+#include "ipc_types.h"
+#include "mach_kmsg.h"
+
+kern_return_t VM_allocate(struct task_struct* ts,
+ uintptr_t* addr,
+ size_t size,
+ boolean_t anywhere);
+
+kern_return_t VM_deallocate(struct task_struct* ts,
+ uintptr_t addr,
+ size_t size);
+
+kern_return_t VM_write(struct task_struct* task,
+ char* in_buffer,
+ size_t count,
+ unsigned long *ppos,
+ boolean_t user);
+
+kern_return_t VM_read(struct task_struct* task,
+ char* out_buffer,
+ size_t count,
+ unsigned long *ppos,
+ boolean_t user);
+
+#endif
diff -Naur ./old//Makefile ./kern//Makefile
--- ./old//Makefile 2011-01-04 19:50:19.000000000 -0500
+++ ./kern//Makefile  2012-05-18 19:13:20.000000000 -0400
@@ -680,7 +680,7 @@
 
 
 ifeq ($(KBUILD_EXTMOD),)
-core-y   += kernel/ mm/ fs/ ipc/ security/ crypto/ block/
+core-y   += kernel/ mm/ fs/ ipc/ security/ crypto/ block/ magenta/
 
 vmlinux-dirs := $(patsubst %/,%,$(filter %/, $(init-y) $(init-m) \
         $(core-y) $(core-m) $(drivers-y) $(drivers-m) \
diff -Naur ./old//mm/mmap.c ./kern//mm/mmap.c
--- ./old//mm/mmap.c  2011-01-04 19:50:19.000000000 -0500
+++ ./kern//mm/mmap.c 2012-08-04 10:30:44.000000000 -0400
@@ -1138,6 +1138,7 @@
 
  if (file)
    fput(file);
+
 out:
  return retval;
 }
@@ -1214,6 +1215,186 @@
  return (vm_flags & (VM_NORESERVE | VM_SHARED | VM_WRITE)) == VM_WRITE;
 }
 
+int make_pages_present_ex(unsigned long addr, unsigned long end, struct task_struct* tsk)
+{
+ int ret, len, write;
+ struct vm_area_struct * vma;
+
+ vma = find_vma(tsk->mm, addr);
+ if (!vma)
+   return -ENOMEM;
+
+ write = (vma->vm_flags & (VM_WRITE | VM_SHARED)) == VM_WRITE;
+ BUG_ON(addr >= end);
+ BUG_ON(end > vma->vm_end);
+ len = DIV_ROUND_UP(end, PAGE_SIZE) - addr/PAGE_SIZE;
+ ret = get_user_pages(tsk, tsk->mm, addr,
+           len, write, 0, NULL, NULL);
+ if (ret < 0)
+   return ret;
+
+ return ret == len ? 0 : -EFAULT;
+}
+
+unsigned long mmap_region_ex(struct file *file, unsigned long addr,
+       unsigned long len, unsigned long flags,
+       unsigned int vm_flags, unsigned long pgoff,
+       struct task_struct* tsk)
+{
+ struct mm_struct *mm = tsk->mm;
+ struct vm_area_struct *vma, *prev;
+ int correct_wcount = 0;
+ int error;
+ struct rb_node **rb_link, *rb_parent;
+ unsigned long charged = 0;
+ struct inode *inode =  file ? file->f_path.dentry->d_inode : NULL;
+
+ /* Clear old maps */
+ error = -ENOMEM;
+munmap_back:
+ vma = find_vma_prepare(mm, addr, &prev, &rb_link, &rb_parent);
+ if (vma && vma->vm_start < addr + len) {
+   if (do_munmap(mm, addr, len))
+     return -ENOMEM;
+   goto munmap_back;
+ }
+
+ /* Check against address space limit. */
+ if (!may_expand_vm(mm, len >> PAGE_SHIFT))
+   return -ENOMEM;
+
+ /*
+  * Set 'VM_NORESERVE' if we should not account for the
+  * memory use of this mapping.
+  */
+ if ((flags & MAP_NORESERVE)) {
+   /* We honor MAP_NORESERVE if allowed to overcommit */
+   if (sysctl_overcommit_memory != OVERCOMMIT_NEVER)
+     vm_flags |= VM_NORESERVE;
+
+   /* hugetlb applies strict overcommit unless MAP_NORESERVE */
+   if (file && is_file_hugepages(file))
+     vm_flags |= VM_NORESERVE;
+ }
+
+ /*
+  * Private writable mapping: check memory availability
+  */
+ if (accountable_mapping(file, vm_flags)) {
+   charged = len >> PAGE_SHIFT;
+   if (security_vm_enough_memory(charged))
+     return -ENOMEM;
+   vm_flags |= VM_ACCOUNT;
+ }
+
+ /*
+  * Can we just expand an old mapping?
+  */
+ vma = vma_merge(mm, prev, addr, addr + len, vm_flags, NULL, file, pgoff, NULL);
+ if (vma)
+   goto out;
+
+ /*
+  * Determine the object being mapped and call the appropriate
+  * specific mapper. the address has already been validated, but
+  * not unmapped, but the maps are removed from the list.
+  */
+ vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+ if (!vma) {
+   error = -ENOMEM;
+   goto unacct_error;
+ }
+
+ vma->vm_mm = mm;
+ vma->vm_start = addr;
+ vma->vm_end = addr + len;
+ vma->vm_flags = vm_flags;
+ vma->vm_page_prot = vm_get_page_prot(vm_flags);
+ vma->vm_pgoff = pgoff;
+ INIT_LIST_HEAD(&vma->anon_vma_chain);
+
+ if (file) {
+   error = -EINVAL;
+   if (vm_flags & (VM_GROWSDOWN|VM_GROWSUP))
+     goto free_vma;
+   if (vm_flags & VM_DENYWRITE) {
+     error = deny_write_access(file);
+     if (error)
+       goto free_vma;
+     correct_wcount = 1;
+   }
+   vma->vm_file = file;
+   get_file(file);
+   error = file->f_op->mmap(file, vma);
+   if (error)
+     goto unmap_and_free_vma;
+   if (vm_flags & VM_EXECUTABLE)
+     added_exe_file_vma(mm);
+
+   /* Can addr have changed??
+    *
+    * Answer: Yes, several device drivers can do it in their
+    *         f_op->mmap method. -DaveM
+    */
+   addr = vma->vm_start;
+   pgoff = vma->vm_pgoff;
+   vm_flags = vma->vm_flags;
+ } else if (vm_flags & VM_SHARED) {
+   error = shmem_zero_setup(vma);
+   if (error)
+     goto free_vma;
+ }
+
+ if (vma_wants_writenotify(vma)) {
+   pgprot_t pprot = vma->vm_page_prot;
+
+   /* Can vma->vm_page_prot have changed??
+    *
+    * Answer: Yes, drivers may have changed it in their
+    *         f_op->mmap method.
+    *
+    * Ensures that vmas marked as uncached stay that way.
+    */
+   vma->vm_page_prot = vm_get_page_prot(vm_flags & ~VM_SHARED);
+   if (pgprot_val(pprot) == pgprot_val(pgprot_noncached(pprot)))
+     vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
+ }
+
+ vma_link(mm, vma, prev, rb_link, rb_parent);
+ file = vma->vm_file;
+
+ /* Once vma denies write, undo our temporary denial count */
+ if (correct_wcount)
+   atomic_inc(&inode->i_writecount);
+out:
+ perf_event_mmap(vma);
+
+ mm->total_vm += len >> PAGE_SHIFT;
+ vm_stat_account(mm, vm_flags, file, len >> PAGE_SHIFT);
+ if (vm_flags & VM_LOCKED) {
+   if (!mlock_vma_pages_range(vma, addr, addr + len))
+     mm->locked_vm += (len >> PAGE_SHIFT);
+ } else if ((flags & MAP_POPULATE) && !(flags & MAP_NONBLOCK))
+   make_pages_present_ex(addr, addr + len, tsk);
+ return addr;
+
+unmap_and_free_vma:
+ if (correct_wcount)
+   atomic_inc(&inode->i_writecount);
+ vma->vm_file = NULL;
+ fput(file);
+
+ /* Undo any partial mapping done by a device driver. */
+ unmap_region(mm, vma, prev, vma->vm_start, vma->vm_end);
+ charged = 0;
+free_vma:
+ kmem_cache_free(vm_area_cachep, vma);
+unacct_error:
+ if (charged)
+   vm_unacct_memory(charged);
+ return error;
+}
+
 unsigned long mmap_region(struct file *file, unsigned long addr,
        unsigned long len, unsigned long flags,
        unsigned int vm_flags, unsigned long pgoff)
@@ -1388,6 +1569,8 @@
 arch_get_unmapped_area(struct file *filp, unsigned long addr,
    unsigned long len, unsigned long pgoff, unsigned long flags)
 {
+ panic("%s: shouldn't be used on this platform!", __FUNCTION__);
+
  struct mm_struct *mm = current->mm;
  struct vm_area_struct *vma;
  unsigned long start_addr;
@@ -1463,6 +1646,8 @@
        const unsigned long len, const unsigned long pgoff,
        const unsigned long flags)
 {
+ panic("%s: shouldn't be used on this platform!", __FUNCTION__);
+
  struct vm_area_struct *vma;
  struct mm_struct *mm = current->mm;
  unsigned long addr = addr0;
